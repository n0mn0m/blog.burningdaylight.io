{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>BurningDaylight</p> <p>Welcome to burningdaylight.io</p> <p>This is my little space on the web that I like to use to tinker with various tools. The site is currently on its 7th incarnation and a continual work in progress.</p> <p>Copyright Alexander Hagerman 2024</p> <p>Site Content/Posts Creative Commons CC0 1.0 Site Code Zero Clause BSD</p>"},{"location":"me/","title":"Me","text":"<p>Hi, I'm Alexander</p> <p>For more than a decade I have been fortunate to work across many domains with a lot of inventive individuals. I have learned a lot from those who have spent time introducing me to new ideas and philosophies, and I enjoy every opportunity I have to collaborate with others.</p> <p>Day to day I work on projects at the intersection of humans and computers. I enjoy the challenge of making applications understandable while seeing how the devices we use impact how we interpret the world around us.</p> <p>In my spare time I enjoy tinkering with hardware, swimming, cooking, playing music with Maris, and story telling with friends.</p> <p>If you want to chat you can message me, or a patch.</p> <p>My resume is available for review, and I maintain a project list here.</p>"},{"location":"blog/","title":"Index","text":""},{"location":"blog/2018/05/08/getting-started/","title":"Getting Started","text":"<p>I\u2019ve needed to start this for a while. I think most programmers, sys admins, dbas and others work on projects large and small where we quickly find out how to make x work with y or a produce b. Then we check into source control, walk away and forget until we need to remember a detail 6 weeks later. So that\u2019s what I plan to record here. Little notes and snippets of code, settings, whatever might have been on my mind or come across my keyboard in recent days or weeks. Often times it will have something to do with Python, SQL or clustered systems.</p> <p>The first few post will be on getting Pelican setup with GitHub Pages and Gandi. After that I\u2019ll probably jump into PySpark, HBase, Python and execution plans. Chances are if databases, Python or distributed systems are involved I\u2019m interested in learning and writing about it. If that sounds interesting definitely keep an eye out for more post here.</p> <p>A little bit about myself. I am currently a data engineer at Humana writing a lot of Python and SQL mixing software engineering practices with data science projects. Before that I worked at a few different companies focused on the Microsoft Data Stack mixing SQL Server, SSIS, SSAS and C# to build data intensive applications. There\u2019s more information on my LinkedIn and GitHub pages.</p> <p>That\u2019s all for now. More to come soon.</p>"},{"location":"blog/2018/05/17/publishing-with-pelican-on-windows/","title":"Publishing with Pelican on Windows","text":"<p>To get things started I thought it might be a good idea to document using Pelican on Windows with Github and Gandi for blog publishing. I\u2019ll start by configuring Pelican and Github. Once that\u2019s working I\u2019ll then talk about configuring Gandi so you can use a custom domain. If you\u2019re using a different domain provider you may need to use different settings, but Github has plenty of documentation around this that I\u2019ll provide links for. Using Pelican on Windows isn\u2019t that much different than macOS or Linux, but you won\u2019t find as many tutorials or be able to use the quickstart makefile.</p>"},{"location":"blog/2018/05/17/publishing-with-pelican-on-windows/#github-pages-setup","title":"Github Pages Setup","text":"<p>The first thing you should do is login to Github and then setup a Github pages repo. You can read more detailed istructions here: https://pages.github.com/ or create a repo that follows the pattern:</p> <p>I followed a pattern for User Github pages. This will be important when publishing with Pelican.</p> <p>https://help.github.com/articles/user-organization-and-project-pages/</p>"},{"location":"blog/2018/05/17/publishing-with-pelican-on-windows/#pelican-local","title":"Pelican Local","text":"<p>With that out of the way we want to move on to setting up our project on Windows. I\u2019m using Anaconda and I will be creating a new conda environment for this project.</p> <p>The main thing to pay attention to when you go through the quickstart prompts is that you won\u2019t need or be able to use the makefile with Windows. Once you have completed the quikstart there are a couple things to pay attention to.</p> <ol> <li>Your articles should be markdown documents in the content folder.</li> <li>pelicanconf.py contains various settings related to you blog.</li> <li>publishconf.py can be left alone because we are using ghp-import</li> </ol>"},{"location":"blog/2018/05/17/publishing-with-pelican-on-windows/#publishing","title":"Publishing","text":"<p>Go ahead and create a file under content. Something like gettingstarted.md and add some text. Once you\u2019ve done that switch back to the terminal prompt.</p>"},{"location":"blog/2018/05/17/publishing-with-pelican-on-windows/#custom-domain-url","title":"Custom Domain URL","text":"<p>Ok, now that we have Github setup and we can see our blog pages I want to look at the steps required to use my custom domain hosted by Gandi with the Github pages. With Gandi we want to modify our A Records to allow routing to Github. Logging into your Gandi dashboard, select domains from the menu and then DNS records. On this page you should be able to edit your DNS record and add the following:</p> <p>https://wiki.gandi.net/en/dns/zone/a-record</p> <p>Ok finally navigate back to your Github repo and go to the settings page. Under settings scroll down until you see Github pages. You should see a textbox allowing you to enter a custom domain. Add that, and if possible I recommend checking the enforce https box below this.</p>"},{"location":"blog/2018/05/17/publishing-with-pelican-on-windows/#wrapping-up","title":"Wrapping Up","text":"<p>With that done you should be good to go. Whenever you want to write a new article create a markdown document in the content folder and follow the same steps above for publishing. One last note if this doesn\u2019t work immediately you might want to wait before beginning to change settings since your A record changes can take some time to replicate.</p>"},{"location":"blog/2018/06/29/recursive-search-with-python/","title":"Recursive Search with Python","text":"<p>Recently I received from JSON like data that I needed to transform into a tabular dataset. As part of that there was a specific key that could occur as a child of different keys at different depths in the structure. Not only could the key I needed appear at different locations and depths, but when it was located it was possible that it would have N sibling occurrences I needed to retrieve at the same location. Finally for all of these there were a set of id and date keys at the top level of the structure that I was asked to include with each search key result.</p> <p>I took a couple different paths on my way to solving this. One of the first things I found was the total depth was inconsistent across the structures. Not only that, but it wasn\u2019t uncommon to find the key scattered across depths up to 5 or 6 levels deep. The function below is what I ended up using. It\u2019s a recursive search that relies on the fact that the data is JSON like. Instead of trying to pull the parent keys out as part of the search I have a function that parses out the id and date keys passing those into this function as base. Then a search is performed on the input object checking the dictionary collections for all instances of the search key and when located appending the search keys value to the base data, which is then added to a list of results which is returned when the entire collection has been searched.</p>"},{"location":"blog/2018/06/29/recursive-search-with-python/#gotchas","title":"Gotchas","text":"<ul> <li>This needed to be Python 2 and 3 compatible so pay attention to iterating dictionary keys and values when you have   this requirement. There are different ways to handle this. I used future.</li> <li>The way that Python appends to list can be tricky. This bit me when I found that results contained the right number of   results, but all of my results where the same and where based on the last hit. This is because I was calling append on   base which was creating bindings that I mutated on each search result. Luckily Python has acopy module in the standard   library to help with this scenario.</li> </ul>"},{"location":"blog/2018/06/29/recursive-search-with-python/#problem-solved","title":"Problem Solved","text":"<p>The function below represents my final result. This worked well on the sample data, and eventually was used on PySpark RDDs to process hundreds of millions of structures quickly.</p> <pre><code>import copy from future.utils   \nimport iteritems \n\ndef search ( input , rowbase , searchkey , results ):   \n     \"\"\" A search function to help transform nested JSON   \n     like objects into tabular rows. The function takes  \n     a JSON like object as input along with a search key   \n     and returns a row for each occurrence of the key in   \n     the object. rowbase is expected to be a list containing  \n     any base data you would like associated with the   \n     searchkey data.   \n     \"\"\"\n     if input :   \n         for i in input :   \n             # If input contains a list run it through search   \n             # again since it may contain dictionaries with   \n             # the key being searched   \n             if isinstance (i, list):   \n                 search (i, rowbase, searchkey, results)   \n             # If input contains a dictionary check if it   \n             # contains the searchkey. Also check if any of   \n             # the values are list or dictionaries that need   \n             # to be searched   \n             if isinstance (i, dict):   \n                 for k, v in iteritems (i):   \n                 # If the searchkey is located deepcopy   \n                 # rowbase to prevent changing rowbase   \n                 # on future hits. Create full row and   \n                 # append to results   \n                 if k == searchkey:   \n                     row = copy.deepcopy(rowbase)   \n                     row.append(i)  \n                     results.append(row)   \n                     continue  \n             elif isinstance(v, list):   \n                 search(v, rowbase, searchkey, results)  \n             elif isinstance(v, dict):   \n                 search(v, rowbase, searchkey, results)  \n         # Search has been exhausted return search  \n         # results to caller. Results will be a   \n         # list of list. \n         return results\n</code></pre>"},{"location":"blog/2018/06/29/recursive-search-with-python/#next-steps","title":"Next Steps","text":"<p>Since this works there are a couple of ideas I want to explore with it.</p> <ul> <li>This seems like a good place to gain experience with Python type annotations.</li> <li>Since this needs to work in a pure Python environment as well as a PySpark environment I want to do some profiling,   but I\u2019m not sure how tools like Cython or Numba will work/interact with the PySpark piece of this. That will be   interesting to explore.</li> <li>It would be interesting to add depth tracking and see if there are any levels where the search key never occurs so   that the function could potentially skip iteritems at that level.</li> </ul>"},{"location":"blog/2018/06/29/recursive-search-with-python/#docs","title":"Docs","text":"<p>For more information documentation on copy and future you can check out the documentation.</p> <p>I\u2019m sure others will have different ideas and approaches to something like this. Or you might have suggestions on something that could be done to make this faster or easier to read. If you have feedback or suggestion feel free to send them my way via up via email.</p>"},{"location":"blog/2018/10/09/derbypy-introduction-to-python-modules-and-packages/","title":"DerbyPy Introduction to Python Modules and Packages","text":"<p>Most programming languages offer ways to organize your code into namespaces. These namespaces are logical containers that group different names and behaviors together and isolate them to that namespace. By organizing your code with namespaces it makes it easier to structure your application without naming collisions and it can make it easier for you and others to maintain your code by adding some additional organization to your project.</p> <p>In Python we can use modules and packages to create namespaces that we can then reference in other modules as we build our application.</p> <p>A Python module is a .py file containing Python definitions and statements. The file name is the module name with the suffix.py appended.</p> <p>As with all things in Python when we import a module it is an object, and just like other objects it has dunder (double underscore) attributes that define additional data about that module. We can use that to learn more about the module before we ever start to use it.</p> <pre><code>import pprintext  \n\nprint(pprintext.doc)  \nprint(dir(pprintext))  \n A module providing extensions to pretty print structures that pprint may not handle well.  \n\n ['builtins', 'cached', 'doc', 'file', 'loader', 'name', 'package', 'spec', 'listdirectory', 'os']From the output of dir() we can see there is a function called listdirectory that is part of this module.\n\npprintext.listdirectory(\"plugins\")  \n\n plugins/  \n ipynb/  \n init.py  \n liquid.py  \n markup.py  \n requirements.txt  \n .git  \n README.md  \n ipynb.py  \n LICENSE  \n .gitignore  \n core.py  \n pycache/  \n core.cpython-36.pyc  \n init.cpython-36.pyc  \n markup.cpython-36.pyc  \n ipynb.cpython-36.pyc  \n tests/  \n pelican/  \n pelicanconfmarkup.py  \n pelicanconfliquid.py  \n theme/  \n templates/  \n base.html  \n content/  \n with-meta-file.ipynb-meta  \n with-liquid-tag.ipynb  \n with-metacell.ipynb  \n with-meta-file.ipynb  \n with-liquid-tag.md\n</code></pre> <p>Finally, we can see where we are importing this module from with .file and we see that this is a module local to our application.</p> <pre><code>pprintext.file '/home/alex/projects/alexhagerman.github.io/pprintext.py'### Packages\n</code></pre> <p>For the sake of brevity and simplicity tonight we can say that a Python package is a collection of Python modules. It is a folder that contains .py file and provides a parent namespace for the modules in the folder.</p> <p>Another way of saying this is:</p> <p>Just like we did with our module we can call dir() on our package to see associated attributes and objects.</p> <pre><code>import pprintextension  \ndir(pprintextension)  \n\n ['all',  \n 'builtins',  \n 'cached',  \n 'doc',  \n 'file',  \n 'loader',  \n 'name',  \n 'package',  \n 'path',  \n 'spec',  \n 'network',  \n 'pprintextension']\n</code></pre> <p>Additionally, we can call help which may provide more information about the package defined in init.py. You can think of init.py as a place to put initialization behavior and documentation for your package. In the way thatinit handles initializing your class init.py handles the initialization of your package during import.init.py used to be required to make a directory a package, but as of Python 3.3 thanks to pep-420 it is no longer required. More links and information are provided at the end of the notebook.</p> <pre><code>help(pprintextension)  \n\n Help on package pprintextension:  \n\n NAME  \n pprintextension  \n\n DESCRIPTION  \n A package providing functions to pretty print structures that may have alternative renderings from the standard  \n pprint package.  \n\n PACKAGE CONTENTS  \n filesystem  \n network  \n\n DATA  \n all = ['filesystem']  \n\n FILE  \n /home/alex/projects/modules-and-packages-into/pprintextension/init.pyAdditionally we can import modules from packages and refer to them directly instead of using the fully qualified namespacing syntax &lt;package&gt;.&lt;module&gt;.&lt;object&gt;\n\nfrom pprintextension import filesystem  \nfilesystem.listhiddendirectory()  \n\n ./  \n .ipynbcheckpoints/  \n .git/  \n .idea/Packages go way beyond what we have covered here. As you build packages you want to consider their structure relative to the public API you\u2019re creating. Publishing and distributing packages is a talk or series of talks on its own. For now what we have covered is how we can group modules together in a package and some basics for how to control the initialization behavior of a package.\n</code></pre>"},{"location":"blog/2018/10/09/derbypy-introduction-to-python-modules-and-packages/#finishing-up","title":"Finishing up","text":"<p>Now that we know what a Python module and package is next month we will look at the import statement. As a sneak peak I'll leave you with sys.path and you can begin exploring how this relates to our own packages and modules that make up our application as well as those we might install with tools such as pip or conda.</p> <pre><code>import sys  \nsys.path  \n\n ['',  \n '/home/alex/miniconda3/envs/blogging/lib/python36.zip',  \n '/home/alex/miniconda3/envs/blogging/lib/python3.6',  \n '/home/alex/miniconda3/envs/blogging/lib/python3.6/lib-dynload',  \n '/home/alex/miniconda3/envs/blogging/lib/python3.6/site-packages',  \n '/home/alex/miniconda3/envs/blogging/lib/python3.6/site-packages/IPython/extensions',  \n '/home/alex/.ipython']&lt;https://docs.python.org/3/library/sys.html#sys.path&gt;\n</code></pre>"},{"location":"blog/2018/10/09/derbypy-introduction-to-python-modules-and-packages/#additional-reading","title":"Additional Reading","text":""},{"location":"blog/2018/10/25/derbypy-intro-to-pyspark/","title":"DerbyPy Intro to PySpark","text":"<p>This month at DerbyPy I provided a high level introduction to PySpark. For this talk I went over the Spark execution model at a high level, talked about the difference between the PySpark Dataframe and RDD api, and provided some examples of how to use both. As part of this I put together a jupyter notebook and some scripts that can be used via spark-submit along with instructions on how to run PySpark locally.</p> <p>If you\u2019re interested in the material and presentation they can be found here.</p>"},{"location":"blog/2018/10/27/dealing-with-null-in-pyspark-transformations/","title":"Dealing with NULL in PySpark transformations","text":"<p>Lately I\u2019ve been dealing with nested data on a semi regular basis with PySpark. One of the scenarios that tends to come up a lot is to apply transformations to semi/unstructured data to generate a tabular dataset for consumption by data scientist. When processing and transforming data I\u2019ve previously found it beneficial to make use of the RDD data structure so that I have the ability to easily apply custom transformations the same way I would if I was interacting with normal Python data structures, but with the benefit of Spark and the functionality provided by the RDD API.</p> <p>With my most recent project though I decided to spend more time working with the Spark Dataframe data structure specifically for the potential performance gains from Catalyst and Tungeston. Along with this Spark offers a set of complex types for Spark Dataframe columns to make interaction with collection types a little bit easier.</p> <p>Diving in I immediately used the Databricks XML library to load some data into my dataframe which had a similar shape (although different contents) to this:</p> <pre><code>from pyspark.sql import Row  \nfrom pyspark.sql.functions import explode, first, col, monotonicallyincreasingid, when, array, lit  \nfrom pyspark.sql.column import Column, tojavacolumn  \n\ndf = spark.createDataFrame([  \n Row(dataCells=[Row(posx=0, posy=1, posz=.5, value=1.5, shape=[Row(type='square', len=1)]),  \n Row(posx=1, posy=3, posz=.5, value=4.5, shape=[]),  \n Row(posx=2, posy=5, posz=.5, value=7.5, shape=[Row(type='circle', len=.5)])  \n ])  \n])  \n\ndf.printSchema()  \n\n root  \n |-- dataCells: array (nullable = true)  \n | |-- element: struct (containsNull = true)  \n | | |-- posx: long (nullable = true)  \n | | |-- posy: long (nullable = true)  \n | | |-- posz: double (nullable = true)  \n | | |-- shape: array (nullable = true)  \n | | | |-- element: struct (containsNull = true)  \n | | | | |-- len: long (nullable = true)  \n | | | | |-- type: string (nullable = true)  \n | | |-- value: double (nullable = true)df.show()  \n\n +--------------------+  \n | dataCells|  \n +--------------------+  \n |[[0, 1, 0.5, [[1,...|  \n +--------------------+\n</code></pre> <p>Perfect. Nothing too crazy, but I wanted to transform the nested array of structs into column representing the members of each struct type. So I started by looking at the options available to flatten my array column and I came across which appeared to do exactly what I needed. Next I needed to take the member attributes of the structs and turn those into columns. I wasn\u2019t able to find a built in function for this, but using the select syntax available on dataframes along with the* wildcard available on structs I was able to write my own function to do this.</p> <pre><code>def flattenstructcols(df):  \n flatcols = [column[0] for column in df.dtypes if 'struct' not in column[1][:6]]  \n structcolumns = [column[0] for column in df.dtypes if 'struct' in column[1][:6]]  \n\n df = df.select(flatcols +  \n [col(sc + '.' + c).alias(sc + '' + c)  \n for sc in structcolumns  \n for c in df.select(sc + '.*').columns])  \n\n return dfAnd with that out of the way I\u2019m ready to go.\n\nflatdf = df.withColumn('dataCells', explode(col('dataCells')))  \nflatdf = flattenstructcols(flatdf)  \nflatdf.show(3)  \n\n +--------------|--------------|--------------|---------------|---------------+  \n |dataCellsposx|dataCellsposy|dataCellsposz|dataCellsshape|dataCellsvalue|  \n +--------------|--------------|--------------|---------------|---------------+  \n | 0| 1| 0.5| [[1, square]]| 1.5|  \n | 1| 3| 0.5| []| 4.5|  \n | 2| 5| 0.5| [[, circle]]| 7.5|  \n +--------------|--------------|--------------|---------------|---------------+\n flatdf.printSchema()  \n\n root  \n |-- dataCellsposx: long (nullable = true)  \n |-- dataCellsposy: long (nullable = true)  \n |-- dataCellsposz: double (nullable = true)  \n |-- dataCellsshape: array (nullable = true)  \n | |-- element: struct (containsNull = true)  \n | | |-- len: long (nullable = true)  \n | | |-- type: string (nullable = true)  \n |-- dataCellsvalue: double (nullable = true)So far so good. Let\u2019s try it again, and if all goes well we can throw this in a loop, flatten nested columns and be on our way.\n\nflatdf = flatdf.withColumn('dataCellsshape', explode(col('dataCellsshape')))  \nflatdf = flattenstructcols(flatdf)  \nflatdf.show(3)  \n\n +--------------|--------------|--------------|---------------|--------------------|---------------------+  \n |dataCellsposx|dataCellsposy|dataCellsposz|dataCellsvalue|dataCellsshapelen|dataCellsshapetype|  \n +--------------|--------------|--------------|---------------|--------------------|---------------------+  \n | 0| 1| 0.5| 1.5| 1| square|  \n | 2| 5| 0.5| 7.5| null| circle|  \n +--------------|--------------|--------------|---------------|--------------------|---------------------+\n</code></pre> <p>And now we have a problem. After back tracking I found that explode is silently dropping out my row with null in it. Let's check the docs. Interestingly I didn't see anything about this. So I checked the latest docs and just so happened to noticeexplodeouter listed right below this. It turns out in 2.2.0 a set ofouter functions where added that retain null for certain operations such as explode. Unfortunately some of these are not available in PySpark until 2.3 and I didn't have the option to migrate from 2.2.x to 2.3.x.</p> <p>StackOverflow to the rescue. After reviewing the PySpark tag I didn't find any solutions with accepted answers so I went ahead and wrote my own question. Thanks to that I learned a lot about PySpark/JVM interop and about some of the disparities between the JVM API and other language APIs.</p>"},{"location":"blog/2018/10/27/dealing-with-null-in-pyspark-transformations/#otherwise","title":"Otherwise()","text":"<pre><code>flatdf = df.withColumn('dataCells', explode(col('dataCells')))  \nflatdf = flattenstructcols(flatdf)  \nflatdf.withColumn('dataCellsshapetest', explode(when(col('dataCellsshape').isNotNull(), col('dataCellsshape'))  \n .otherwise(array(lit(None).cast(flatdf.select(col('dataCellsshape')  \n .getItem(0))  \n .dtypes[0][1]))))).show()  \n\n+--------------|--------------|--------------|---------------|---------------|--------------------+  \n|dataCellsposx|dataCellsposy|dataCellsposz|dataCellsshape|dataCellsvalue|dataCellsshapetest|  \n+--------------|--------------|--------------|---------------|---------------|--------------------+  \n| 0| 1| 0.5| [[1, square]]| 1.5| [1, square]|  \n| 2| 5| 0.5| [[, circle]]| 7.5| [, circle]|  \n+--------------|--------------|--------------|---------------|---------------|--------------------+\n</code></pre> <p>Based on some responses to my question I found another question that provided a scala solution involving .otherwise and casting the nested structure with a null literal. None in Python. This seemed like the more direct solution without making use of private functionality in the library, so I opted to try implementing the scala solution in PySpark first.</p> <p>But unfortunately it appears that the explode may have a precedence behind the scenes that drops the row before otherwise is evaluated. With a quickly approaching deadline I unfortunately did not have time to dig deep into why this was with other options on the table.</p>"},{"location":"blog/2018/10/27/dealing-with-null-in-pyspark-transformations/#into-the-jvm","title":"Into the JVM","text":"<pre><code>def explodeouter(col):  \n \"\"\"  \n Calling the explodeouter Java function from PySpark  \n \"\"\"  \n explodeouter = sc.jvm.org.apache.spark.sql.functions.explodeouter  \n return Column(explodeouter(tojavacolumn(col)))flatdfwithnull = df.withColumn('dataCells', explode(col('dataCells')))  \nflatdfwithnull = flattenstructcols(flatdfwithnull)  \nflatdfwithnull = flatdfwithnull.withColumn(\"dataCellsshape\", explodeouter(col(\"dataCellsshape\")))  \nflatdfwithnull.show()  \n\n +--------------|--------------|--------------|---------------|---------------+  \n |dataCellsposx|dataCellsposy|dataCellsposz|dataCellsshape|dataCellsvalue|  \n +--------------|--------------|--------------|---------------|---------------+  \n | 0| 1| 0.5| [1, square]| 1.5|  \n | 1| 3| 0.5| null| 4.5|  \n | 2| 5| 0.5| [, circle]| 7.5|  \n +--------------|--------------|--------------|---------------|---------------+\n flatdfwithnull = flattenstructcols(flatdfwithnull)  \nflatdfwithnull.show()  \n\n +--------------|--------------|--------------|---------------|--------------------|---------------------+  \n |dataCellsposx|dataCellsposy|dataCellsposz|dataCellsvalue|dataCellsshapelen|dataCellsshapetype|  \n +--------------|--------------|--------------|---------------|--------------------|---------------------+  \n | 0| 1| 0.5| 1.5| 1| square|  \n | 1| 3| 0.5| 4.5| null| null|  \n | 2| 5| 0.5| 7.5| null| circle|  \n +--------------|--------------|--------------|---------------|--------------------|---------------------+\n</code></pre> <p>While reviewing suggested solutions I found out that SparkContext has ajvm object that provides access to org.apache.* functionality. Along with this I also noticed that Databricks has an entire \"private\" api used with Python and Java. Part of this API istojavacolumn which makes it possible to transform a PySpark column to a Java column to match Java method signatures. Learning all of this, and knowing that the Java API already had <code>explodeouter</code> implemented I reviewed the Java explodeouter method to verify the type signature and built my own function in Python to call the Java function and return the column with null in place.</p> <p>And it works! With that I am able to flatten out arbitrarily nested collections in PySpark dataframes while retaining nulls when using Spark 2.2.x.</p>"},{"location":"blog/2018/10/27/dealing-with-null-in-pyspark-transformations/#wrapping-up","title":"Wrapping Up","text":"<p>A couple of things to note; if you have an array with more than one struct as a member this will fail, and if you have a deeply nested structure the growth of this transformation is typically not sustainable on a large dataset.</p> <p>I have questions that I hope to continue spending time on. For instance why are rows with null dropped at all? I wonder if the operation makes a new dataframe from the column to apply the operation to and then joins it back on an index and along the way that join loses nulls. Why are functions that are lossy not identified as such? Is there always a version lag between the JVM api and the PySpark api? I'm also curious how Catalyst handles denesting operations and adding new columns from the result of exploding arrays or flattening structs.</p> <p>Finally instead of adding new columns I want to try using the MapType to instead create a new column of key, value pairs that allows me to flatten out arbitrarily deep collections into a MapType so that I can use the same methodology on much deeper structures without adding a lot of columns that are mostly null.</p>"},{"location":"blog/2018/12/22/docker-airflow/","title":"docker-airflow","text":"<p>If you\u2019ve spent time using Python for ETL processes or working with data pipelines using tools from the Apache ecosystem then you\u2019ve probably heard about Apache Airflow. In this post I\u2019m going to briefly write about why I\u2019m using Airflow, show how you can get started with Airflow using docker and I will show how I customized this setup so that you can do the same. Finally at the end I\u2019ll talk about a couple of issues I ran into getting started with Airflow and docker.</p>"},{"location":"blog/2018/12/22/docker-airflow/#what-is-apache-airflow","title":"What is Apache Airflow","text":"<p>From the home page:</p> <ul> <li>Airflow is a platform to programmatically author, schedule and monitor workflows.   Programatically being a key part so that you can create and orchestrate worflows/data pipelines using the same   processes and tools that let you create reliable, scaling software.</li> </ul>"},{"location":"blog/2018/12/22/docker-airflow/#why-airflow","title":"Why Airflow","text":"<p>I don\u2019t plan to write much on this subject since it\u2019s been covered in depth else where, but at work and often times when talking about Airflow the question of why Airflow versus X traditional solution where X is something like:</p> <p>inevitably comes up. The primary reason I prefer a solution like Airflow to more traditional solutions is because my ETL is code. While there are numerous benefits to ETL as code my talking points are:</p> <ul> <li>Your data pipes/workflows go through the same processes that helps you create better products like TDD</li> <li>Your ETL development and production can be integrated with your CI/CD process</li> <li>Better debugging tools</li> <li>Flexibility</li> </ul> <p>That\u2019s not to say the traditional tools don\u2019t have their place, but my experience is that any significantly complex data pipeline ends up making use of that tools script task (C# for SSIS, Java for Informatica) and now you have an amalgamation of GUI product and untested, undocumented and non versioned code in production data pipelines.</p>"},{"location":"blog/2018/12/22/docker-airflow/#why-conda","title":"Why conda","text":"<p>By day I\u2019m a data engineer helping to build platforms, applications and pipelines to enable data scientist. Because of this conda is a tool I\u2019ve become familiar with and it let\u2019s me work across languages, but easily integrate those various languages into my Airflow dags.</p> <p>To get started with Airflow I highly recommend reading the homepage and tutorial to get an idea of the core concepts and pick up on the vocabulary used within the framework.</p> <p>After that there is a great project called docker-airflow that you can get started with. This provides a quick way to get started with Airflow in an environment with sane defaults making use of Postgres and Redis.</p> <p>This project provides an example dag and also allows you to load the Airflow example dags via the LOADEX environment variable. Additionally you might want to open up the Airflow dashboard and checkout the Connections tab where you can setup things such as SSH an SSH connection to reference in your dags.</p>"},{"location":"blog/2018/12/22/docker-airflow/#docker-airflow","title":"docker-airflow","text":"<p>To get started with Airflow I highly recommend reading the homepage and tutorial to get an idea of the core concepts and pick up on the vocabulary used within the framework.</p> <p>After that there is a great project called docker-airflow that you can get started with. This provides a quick way to get started with Airflow in an environment with sane defaults making use of Postgres and Redis.</p> <p>This project provides an example dag and also allows you to load the Airflow example dags via the LOADEXenvironment variable. Additionally you might want to open up the Airflow dashboard and checkout the Connections tab where you can setup things such as SSH an SSH connection to reference in your dags.</p>"},{"location":"blog/2018/12/22/docker-airflow/#customizing-the-setup","title":"Customizing the setup","text":"<p>The docker-airflow project is a great start, but it makes assumptions that may not be true of your environment such as which database you plan to use, use of environment variables, etc.</p> <p>If all you\u2019re needing to tweak is the behavior of the environment or Airflow your first stop should be airflow.cfg in the /config directory. This is a centralized location for Airflow settings and is checked after any settings from the environment are loaded. If you're trying to change settings related to work pools, ssl, kerberos, etc this is probably the best place to get started.</p> <p>If you\u2019re looking to change things related to your containers such as when to restart, dependencies, etc then your going to want to checkout either the LocalExecutor or CeleryExecutor docker-compose files.</p> <p>Finally you might want to make bigger changes like I did such as using a different database, base docker image etc. Doing this requires changing quite a few items. The changes I made were:</p> <ul> <li>switch to miniconda for my base image to use Intel Dist Python</li> <li>switch to Microsoft SQL Server for the database</li> <li>switch the task queue to RabbitMQ</li> </ul> <p>Most of this was driven by a desire to experiment and to learn more about tools that I use day to day. Since I work in a data engineering shop there are packages from conda-forge that I like to use driving the miniconda switch, I've used MS SQL for the last 8 years professionally and I've been working on scaling with RabbitMQ over the last year.</p> <p>The switch to miniconda was a one liner in the Dockfile:</p> <pre><code>FROM continuumio/miniconda3Then to use IDP (Intel Distribution of Python) within the container I added this towards the bottom:\n\nRUN conda config --add channels intel\\  \n &amp;&amp; conda config --add channels conda-forge \\  \n &amp;&amp; conda install -y -q intelpython3core=2019.1 python=3 \\  \n &amp;&amp; conda clean --all \\And with that I can make use of conda packages alongside traditional Python packages within my Airflow environment.\n</code></pre> <p>Next up I wanted to switch to MSSQL. Doing this was a matter of switching from Postgres in docker-compose and adding the MSSQL Linux drivers to the base docker-airflow Dockerfile.</p> <p>docker-compose</p> <pre><code>mssql:  \n image: microsoft/mssql-server-linux:latest  \n environment:  \n - ACCEPTEULA=Y  \n - SAPASSWORD=YourStrong!Passw0rd  \n ports:  \n - 1433:1433  \n volumes:  \n - /var/opt/mssqlYou may or may not want to preserver your database volume so keep that in mind.\n</code></pre> <p>Setting up the MSSQL Linux drivers is fairly straight forward following the documentation from Microsoft.</p> <p>Dockerfile</p> <pre><code>ENV ACCEPTEULA=Y\nRUN curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - \\  \n &amp;&amp; curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list | tee /etc/apt/sources.list.d/msprod.listRUN apt-get update -yqq \\  \n &amp;&amp; apt-get install -yqq mssql-tools unixodbc-dev\n</code></pre> <p>One thing to note if you\u2019re using a Debian based image is that Microsoft has a somewhat obscure dependency on libssl1.0.0. Without that installed you will get some obscure unixodbc error connecting to MSSQL with sql-alchemy. To remedy this add the below to your Dockerfile.</p> <pre><code>RUN echo 'export PATH=\"$PATH:/opt/mssql-tools/bin\"' &gt;&gt; ~/.bashprofile  \nRUN echo \"deb http://httpredir.debian.org/debian jessie main contrib non-free\\\n deb-src http://httpredir.debian.org/debian jessie main contrib non-free\\n\n deb http://security.debian.org/ jessie/updates main contrib non-free\\\n deb-src http://security.debian.org/ jessie/updates main contrib non-free\" &gt;&gt; /etc/apt/sources.list.d/jessie.listRUN apt update \\  \n &amp;&amp; apt install libssl1.0.0\n</code></pre> <p>Finally setup your connection string either in airflow.cfg or an Airflow environment variable . I like to use the Airflow environment variables and pass them in from a .env file with docker-compose.</p> <pre><code>environment:  \n - LOADEX=n  \n - FERNETKEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=  \n - EXECUTOR=Celery  \n - AIRFLOWCELERYBROKERURL=${CELERYRABBITBROKER}  \n - AIRFLOWCORESQLALCHEMYCONN=${SQLALCHEMYCONN}  \n - AIRFLOWCELERYRESULTBACKEND=${CELERYRESULTSBACKEND}And finally the last big change I implemented was the switch to RabbitMQ instead of Redis. Similar to the MSSQL switch this was just an update to the docker-compose file.\n\nrabbitmq:  \n image: rabbitmq:3-management  \n hostname: rabbitmq  \n environment:  \n - RABBITMQERLANGCOOKIE=${RABBITMQERLANGCOOKIE}  \n - RABBITMQDEFAULTUSER=${RABBITMQDEFAULTUSER}  \n - RABBITMQDEFAULTPASS=${RABBITMQDEFAULTPASS}  \n - RABBITMQDEFAULTVHOST=${RABBITMQDEFAULTVHOST}\n</code></pre> <p>And setting up the right connection string for Celery to talk with rabbitmq. Similar to the MSSQL connection string I put this in my .env file and reference it in my docker-compose file as seen above.</p> <pre><code>CELERYRABBITBROKER=amqp://user:pass@host:port/\n</code></pre> <p>One thing to note is anytime you are referencing the host and running with docker-compose you can reference the service id in this case rabbitmq as the host name. And with that I have a nice Airflow environment that lets me make use of the database I\u2019m familiar with, a durable queue and packages across the Python and Data Science ecosystems via conda.</p> <p>You can find these changes in my fork of the docker-airflow project. I\u2019ve also opened a GitHub issue with the goal of creating some way to track other community variations of docker-airflow with the hope of helping others discover setups specific to their need.</p>"},{"location":"blog/2018/12/22/docker-airflow/#issues-so-far","title":"Issues so far","text":"<p>I\u2019ve been using the setup above for a couple weeks now with pretty good results. I\u2019ve made use of some libraries like hdfs3 that have their latest releases in conda-forge and my familiarity with MSSQL has saved me some maintenance time. The experience hasn\u2019t been without it\u2019s issues. The highlights are:</p> <ul> <li>Airflow packages may not be what you want. See   librabbitmq and celery. It's best to manage a requirements.txt or conda.txt with your dependencies still.</li> <li>Dependency management across multiple dags. In short with a standard setup you need one package version and it needs   to be installed everywhere. For an interesting approach to this   read We\u2019re All Using Airflow Wrong and How to Fix It</li> <li>Silent failures. Be aware of all the reasons why a worker may provide exit code 0 especially with docker. This took a   minute to catch when an NFS mount stopped showing new files being available, but the exit code 0 made things seem ok.   This isn\u2019t Airflows fault, but just something to keep in mind when using Airflow in an environment with docker and   remote resources.</li> </ul>"},{"location":"blog/2018/12/22/docker-airflow/#reaching-out","title":"Reaching out","text":"<p>Hopefully this post helps you get started with docker-airflow. If you have questions or want to share something cool that you end up doing feel free to open up an issue on Sourcehut or reach out to me n0mn0m@burningdaylight.io.</p>"},{"location":"blog/2019/01/02/building-vim-with-anaconda-python-support/","title":"Building Vim with Anaconda Python Support","text":"<p>This morning I was setting up a RHEL 7 box for development using my normal dot files, but when I was ready to sit down and start working on my project I noticed I got an error from You Complete Me letting me know that the version of vim that was installed wasn't compatible. After checking EPEL for a more up to date install I decided to try pulling vim from source and building it myself.</p> <p>Luckily this wasn\u2019t too hard, but I did run into a small issue related to the vim .config --with-python* flags since I'm using conda as my Python environment manager. The short story is the vim needs some information from the Python config directory to enable python and python3 support. When you use Anaconda or Minionda to manage your environments these are in slightly different locations than the normal /usr or /lib64 paths you may find in vim build documentation. Instead they will be in your conda environment lib as seen below.</p> <p>Install additional build dependencies.</p> <pre><code>sudo yum install cmake gcc-c++ make ncurses-devel\n</code></pre> <p>Clone vim source, configure and build. Specifically pay attention to the \u2014 with-python* flags and the config directory they use in your conda environment.</p> <pre><code>git clone https://github.com/vim/vim.gitpushd ~/vim/src./configure --with-features=huge \\  \n--enable-multibyte \\  \n--enable-rubyinterp=yes \\  \n--enable-pythoninterp=yes \\  \n--with-python-config-dir=/work/alex/miniconda3/envs/py27/lib/python2.7/config \\  \n--enable-python3interp=yes \\  \n--with-python3-config-dir=/work/alex/miniconda3/lib/python3.6/config-3.6m-x8664-linux-gnu \\  \n--enable-perlinterp=yes \\  \n--enable-luainterp=yes \\  \n--enable-cscope \\  \n--prefix=/home/alex/.local/vim | grep -i pythonmake &amp;&amp; make installpopdFinally if you use a custom prefix as seen above (prevents system level changes and conflicts impacting others) you probably want to add the below to you .bashrc file.\n\nif [ -d \"$HOME/.local/vim/bin/\" ] ; then  \n PATH=\"$HOME/.local/vim/bin/:$PATH\"  \nfi\n</code></pre> <p>And that\u2019s it. You should now have an up to date vim install with Python.</p>"},{"location":"blog/2019/01/18/vim-and-rust-in-2019/","title":"Vim and Rust in 2019","text":"<p>I\u2019ve been using Vim as my primary editor for a few months now. Recently I wanted to revisit some project work in Rust, but I hadn\u2019t setup any tooling in Vim for rust yet. The first couple of hits I got on Google were great resources that I\u2019ll provide links to, but they were also over a year old, so while using them as a starting point I\u2019m documenting my setup since some things have changed from 2017.</p>"},{"location":"blog/2019/01/18/vim-and-rust-in-2019/#tooling","title":"Tooling","text":"<p>Core Installs:</p> <ul> <li>Rust with rustup</li> <li> <p>Racer   Autocomplete:</p> </li> <li> <p>YouCompleteMe   Language Server Protocol</p> </li> <li> <p>vim-lsp</p> </li> <li>RLS \u2014 Rust Language Server   So far this has been a fairly pain free experience. As I use this (and vim) more I will likely add some updates   related to packaging, compiling and debugging in Vim, but for now these are the tools that got me started. One thing   to note is that I recommend installing in the order above and following the install directions (especially for the   lsp) since those appear to have made some QoL changes in the last year.</li> </ul> <p>Source Articles: https://kadekillary.work/post/rust-ide/ https://ddrscott.github.io/blog/2018/getting-rusty-with-vim/</p>"},{"location":"blog/2019/02/10/subdomain-ssl-with-gitlab-pages/","title":"Subdomain SSL with Gitlab Pages","text":"<p>This is out of date, I have since switched to self hosting gitea and AWS.</p> <p>A few months ago I decided to migrate my Pelican site from Github to Gitlab. This was motivated largely by that fact that Gitlab has CI/CD built in by default. During this migration I also decided it was time to setup my own SSL certificate for burningdaylight.io. Since this was new I looked around to see if there was any documentation readily available , and I found this wonderful tutorial from Fedora Magazine.</p> <p>Between that and the Gitlab custom domain and ssl I was able to get up and running pretty quickly. I had accomplished my goals:</p> <ul> <li>migrate to Gitlab</li> <li>setup CI/CD of the Pelican site project</li> <li>setup ssl</li> </ul> <p>Good to go, done in an afternoon with plenty of time to work on a new post. I thought.</p> <p>About a week later I was on a different computer and instead of browsing to https://burningdaylight.io I went to https://www.burningdaylight.io and Firefox blocked my request citing an SSL certificate error. Wondering what I had done wrong I started tracing back through what I had done and realized that I had only setup SSL certificate for my primary domain. Luckily last year lets encrypt added support for wildcard certificates to certbot. Unfortunately that has not been included in a release so there\u2019s a couple steps that differ from the original Fedora article above.</p>"},{"location":"blog/2019/02/10/subdomain-ssl-with-gitlab-pages/#setup-instructions","title":"Setup Instructions","text":"<p>Below are the steps to use certbot, gitlab pages and your domain management console to setup SSL for your subdomains. This assumes you are using a Debian based OS (I\u2019m using Ubuntu 18.04) to install Certbot. If not swap out the certbot install steps for your OS and continue.</p> <p>If you read the Fedora article linked above you do not need another key in .well-known. Instead for your subdomain you will validate with certbot by a DNS record setup via your Domain Management Console.</p> <pre><code>sudo aptget install certbotcertbot certonly -a manual -d *.&lt;yourdomainhere&gt;.&lt;topleveldomainhere&gt; \\  \n--config-dir ~/letsencrypt/config --work-dir ~/letsencrypt/work \\  \n--logs-dir ~/letsencrypt/logs \\  \n--server &lt;https://acme-v02.api.letsencrypt.org/directory&gt;Follow the instructions entering your email, reviewing ToS, etc\n</code></pre> <p>You will then see this prompt:</p> <pre><code>Please deploy a DNS TXT record under the name  \nacme-challenge.burningdaylight.io with the following value:\n</code></pre> <p>Login to your domain management console and setup a txt record similar to:</p> <pre><code>NAMETYPETTLVALUEacme-challengeTXT1800your code from the terminal prompt above\n</code></pre> <p>Once you have this setup it\u2019s a good idea to wait a couple minutes since this record will populate via DNS and then return to your console and hit enter.</p> <p>Once certbot validates the TXT record is available as part of your domain it will provide you the new location of your fullchain.pem and privkey.pem files for use with Gitlab pages.</p> <p>With these files ready to go browse to your Gitlab page settings and setup your subdomains as documented here and here.</p> <p>I highly recommend reading the Gitlab documentation above, but to summarize:</p> <ul> <li>In your Gitlab pages project settings click add a new site</li> <li>Enter the url</li> <li>Add the data from your fullchain.pem and privkey.pem files generated via certbot</li> <li>Copy the gitlab-pages-verfication-code= section from the Gitlab validation record box</li> <li>Login to your domain management console</li> <li>Setup a new TXT record for your subdomain: NAMETYPETTLVALUEWWWTXT1800gitlab-pages-verification-code=</li> <li>Setup a new A record for</li> </ul> <p>Gitlab</p> <pre><code>NAMETYPETTLVALUEWWWA180035.185.44.232\n</code></pre> <ul> <li>Return to your Gitlab Pages settings console and click the verify button.</li> </ul>"},{"location":"blog/2019/02/10/subdomain-ssl-with-gitlab-pages/#wrapping-up","title":"Wrapping Up","text":"<p>With that you pages should show green and verified. If you browse to the different subdomains you setup then you should get through without any SSL problems.</p> <p>One thing to note is that you will need to renew your certbot certificate every 90 days. This is done via the certbot renew command. I've setup an Airflow dag to take care of this since I have Airflow managing various other things for me. You can see that here</p> <p>Hopefully you find the above helpful. If you run into issues I recommend:</p> <ul> <li>Make sure you used the * wildcard in the domain cert setup</li> <li>Setup your acme-challenge record correctly in your domain management console and left it there</li> <li>Setup the right TXT and A records for Gitlab</li> </ul>"},{"location":"blog/2019/03/31/what-is-odbc-part-1-of-3/","title":"What is ODBC Part 1 of 3","text":"<p>At my last job we used pyodbc to manage database interactions in a few different projects. We did this because we interacted with 5 different relational databases, and not all of them had native driver libraries for Python. In addition to this our use of pyodbc meant that we had a nice consistent database API for on-boarding, or when somebody needed to interact with a database that might be new to them for their project. Recently though I had somebody ask me what ODBC was, and to be honest I didn\u2019t have a good answer. I\u2019ve used ODBC libraries in multiple languages, but I hadn\u2019t really dug into the nuts and bolts of what it was because I hadn\u2019t needed to. I knew enough to use it, it worked well and there were bigger problems to solve. It\u2019s a good question though. What is ODBC?</p> <p>At a high level ODBC (Open Database Connectivity) is a specification for a database API creating a standard way for applications to interact with various databases via a series of translation and application layers. It is independent of any specific database, language or operating system. The specification lays out a series of functions that expose database functionality across systems. It\u2019s an interesting, and I would say fairly successful abstraction since many programmers know how to connect, query and process data (via ODBC) in their language, but maybe they have never read sql.h or the SQLBrowseConnect function. For the full API Reference check here.</p>"},{"location":"blog/2019/03/31/what-is-odbc-part-1-of-3/#api-vs-protocol","title":"API vs Protocol","text":"<p>Quick side note. You may have heard about wire protocols and databases. ODBC is not a protocol; it is an API. This is important because databases tend to define their own wire protocols (some share this now with things like the Postgres wire protocol being OSS) that dictate the sequence in which events or bytes must happen for communication to work. ODBC as an API doesn\u2019t dictate this kind of detail, instead it describes how to expose the database functionality to the programmer consistently independent of the database.</p> <p>API: describes all valid functionality and interactions Protocol: defines the sequence of operations and bytes.</p>"},{"location":"blog/2019/03/31/what-is-odbc-part-1-of-3/#why-odbc","title":"Why ODBC","text":"<p>If databases define their own protocols and have their own way of communicating why should we worry about ODBC? Turns out there are a lot of databases you can use. Factor in an explosion of languages and operating systems and suddenly you have as many developers writing low level wrappers for database drivers as you do building your actual product. Instead ODBC provides a standard for database developers to expose functionality without developers having to reinvent new bindings for each new language, database, operating system combination. You can read more here</p>"},{"location":"blog/2019/03/31/what-is-odbc-part-1-of-3/#next-up","title":"Next Up","text":"<p>Now that we know ODBC is an API I want to look at the architecture of ODBC. In my next post I will cover the driver manager, ODBC drivers and the ODBC API. After that I plan on exploring ODBC from the application layer through the driver layer with Python and pyodbc looking to trace internals and see exactly how and where different layers connect.</p>"},{"location":"blog/2019/03/31/what-is-odbc-part-1-of-3/#contact","title":"Contact","text":"<p>If you have experience with ODBC internals, want to correct something I\u2019ve written or just want to reach out feel free to follow up via email or on .</p> <p>I also have a repo with the material I used for a presentation on this at the Louisville DerbyPy meetup in March of 2019.</p>"},{"location":"blog/2019/05/18/what-is-odbc-part-2-of-3/","title":"What is ODBC Part 2 of 3","text":"<p>In the first article I mentioned that ODBC (Open Database Connectivity) is a specification for a database API creating a standard way for applications to interact with various databases via a series of translation and application layers. To create this standard abstraction ODBC has two components, the driver and the driver manager.</p>"},{"location":"blog/2019/05/18/what-is-odbc-part-2-of-3/#odbc-driver","title":"ODBC Driver","text":"<p>Within ODBC the driver encapsulates the functionality needed to map various functions to underlying system calls. This functionality spans calls to connect, query, disconnect and more depending on what the target data source provides. While almost all drivers provide the prior basic interactivity others many expose more advanced functionality like concurrent cursors, query translation, encryption and more. It\u2019s worth reviewing your ODBC driver docs to see what features you might use specific to your data source. While ODBC provides a useful abstraction for connecting to data sources it\u2019s worth using whatever additional functionality is available to make your application perform it\u2019s best and keep your data secure on the wire.</p>"},{"location":"blog/2019/05/18/what-is-odbc-part-2-of-3/#odbc-driver-manager","title":"ODBC Driver Manager","text":"<p>Ok so the ODBC driver encapsulates the functionality for interacting with our data source what do we need a driver manager for? First it\u2019s not uncommon that you may want your application to interact with various different data sources of the same type. When this happens the driver manager provides the management and concept of the DSN. The DSN (data source name) contains the information required to connect to the data source (host, port, user etc for more information checkout connection strings since the driver manager can save these to a name you specify. This way you can have one driver (for instance Postgres or Elasticsearch) that can be used to connect to various different data sources from the same vendor. In addition to this the driver manager is responsible for keeping up with what drivers are available on the system and exposing that information to applications. By knowing what drivers and DSNs are available the driver manager can sit in between your application and the ODBC driver making sure the connection information and data passed back and forth is mapped to the right system and that return calls from the driver get mapped back for use by applications.</p>"},{"location":"blog/2019/05/18/what-is-odbc-part-2-of-3/#next-up","title":"Next Up","text":"<p>Last up in post 3 I plan on exploring ODBC from the application layer to the driver layer with Python and pyodbc looking to trace internals and see exactly how and where different layers connect.</p>"},{"location":"blog/2019/05/18/what-is-odbc-part-2-of-3/#contact","title":"Contact","text":"<p>If you have experience with ODBC internals, want to correct something I\u2019ve written or just want to reach out feel free to follow up via email or on .</p> <p>I also have a repo with the material I used for a presentation on this at the Louisville DerbyPy meetup in March of 2019.</p>"},{"location":"blog/2019/05/24/what-is-odbc-part-3-of-3/","title":"What is ODBC Part 3 of 3","text":""},{"location":"blog/2019/05/24/what-is-odbc-part-3-of-3/#for-more-information-see-part-one-and-part-two","title":"For more information see part one and part two","text":""},{"location":"blog/2019/05/24/what-is-odbc-part-3-of-3/#setting-up","title":"Setting Up","text":"<p>Just like any other piece of software we can make use of debuggers to step through our application code and see what is happening with ODBC. To do this with Python you should be running a version with debug symbols included. You can do this via:</p> <pre><code>git clone git@github.com:python/cpython.git  \nmkdir debug  \ncd debug  \n../configure --with-pydebug  \nmake  \nmake testAdditionally you will want to clone pyodbc so that we can make use of symbols.\n\ngit clone git@github.com:mkleehammer/pyodbc.git  \nCFLAGS='-Wall -O0 -g' python setup.py build\n</code></pre> <p>Finally you\u2019ll need some code and a database to interact with. If you want I have an example repo which uses docker to start Postgres and/or MSSQL. It also contains some python example code and pyodbc in the repo for debugging.</p> <p>One final note, if you wish to explore code all the way into the driver manager and/or driver you will need a debug version of each. For Mac and Linux you can do this with unixodbc found here or here and specify debug with make similar to CPython above. For a debug driver build checkout Postgres psqlodbc.</p>"},{"location":"blog/2019/05/24/what-is-odbc-part-3-of-3/#stepping-through","title":"Stepping through","text":"<p>I\u2019m writing this on OSX, but the concepts are the same regardless of platform. On OSX you can use LLDB or GDB (I used LLDB as a learning exercise), on Linux GDB is probably your go to and on Windows you can use WinGDB or the debugger built into Visual Studio for C/C++.</p> <p>From the command line start your debugger, or if using GDB/LLDB call your tool with the -f flag specifying you want to load a file and call Python with your debugger so the Python interpreter will run the file inside your debugger.</p> <pre><code>lldb -f python -- -m pdb main.py\n</code></pre> <p>From here you can execute the application, use normal step, thread and frame functions to inspect the stack at different steps or get additional dump file information. Some breakpoints I found interesting can be set with:</p> <pre><code>breakpoint set --file connection.cpp --line 232  \nbreakpoint set --file connection.cpp --line 52  \nbreakpoint set --file cursor.cpp --line 1100  \nbreakpoint set --file getdata.cpp --line 776runIn case it is helpful you can find an lldb to gdb map [here](https://lldb.llvm.org/use/map.html).\n</code></pre>"},{"location":"blog/2019/05/24/what-is-odbc-part-3-of-3/#contact","title":"Contact","text":"<p>If you have experience with ODBC internals, want to correct something I\u2019ve written or just want to reach out feel free to follow up via email or on .</p> <p>I also have a repo with the material I used for a presentation on this at the Louisville DerbyPy meetup in March of 2019.</p>"},{"location":"blog/2019/06/23/using-dataclasses-for-configuration/","title":"Using Dataclasses for Configuration","text":"<p>Introduced in Python 3.7 dataclasses are normal Python classes with some extra features for carrying around data and state. If you find yourself writing a class that is mostly attributes it's a dataclass.</p> <p>Dataclasses have some other nifty features out of the box such as default double underscore methods, type hinting, and more.</p> <p>For more information checkout the docs.</p>"},{"location":"blog/2019/06/23/using-dataclasses-for-configuration/#dataclasses-as-configuration-objects","title":"Dataclasses as configuration objects","text":"<p>Recently I\u2019ve had the opportunity to work on a couple of Python 3.7 projects. In each of them I was interacting with many databases and API Endpoints. Towards the beginning of one of the projects I did something like this:</p> <pre><code>elasticconfig = {\"user\": os.environ[\"ESUSER\"],  \n \"endpoint\": os.environ[\"ESENDPOINT\"],  \n ...  \n }When I checked in the code I had been working on one of the reviewers commented that this pattern was normal, but since we were using 3.7 let\u2019s use a dataclass.\n\nimport os  \nfrom dataclasses import dataclass@dataclass  \nclass ElasticConfiguration:  \n user: str = os.environ[\"ESUSER\"]  \n endpoint: str = os.environ[\"ESENDPOINT\"]  \n</code></pre> <p>...Makes sense, but what\u2019s the practical benefit? Before I wasn\u2019t defining a class and carrying around the class model that I\u2019m not really using.</p> <ol> <li>Class attribute autocomplete. I can\u2019t tell you how many times I used to check if I had the right , casing,    abbreviation etc for the key I was calling. Now it's a class attribute, no more guessing.</li> <li>Hook up mypy and find some interesting errors.</li> <li>Above you\u2019ll notice I used os.environ[]. A lot of people like to use an alternative .get()pattern with    dictionaries. The problem is often times a default of None gets supplied and you're dealing with Optional[T], but    still acting like it's str everywhere in your code. <li>postinit</li> <li>Dataclasses have an interesting method    called postinit that gets called by init.    On configuration objects this is a handy place to put any validation function/method calls you might build around    attributes.</li> <li>Subjectively elastic.user is faster to type, and more appealing to the eyes than elastic[\"user\"].    So the next time you find yourself passing around configuration information remember dataclasses may be a useful and    productive alternative to passing around a dictionary.</li>"},{"location":"blog/2019/06/23/using-dataclasses-for-configuration/#additional-resources","title":"Additional Resources","text":"<p>Beyond the docs here are some links I found useful when learning about Python dataclasses.</p> <ul> <li>Real Python: Dataclasses</li> <li>Stack Overflow: What\u2019s the difference between a class and data class</li> <li>Hackernoon: Dataclasses tour</li> </ul>"},{"location":"blog/2019/07/14/creating-a-con-badge-with-pyportal/","title":"Creating a Con Badge with PyPortal","text":"<p>Recently I've heard about multiple people working on con badges and decided to try my hand at a simple take on the idea. Since I had just recently received my PyPortal Adabox I thought I would use that as my first platform to get started.</p> <p>From the product page the PyPortal is:</p> <p>An easy-to-use IoT device that allows you to create all the things for the \u201cInternet of Things\u201d in minutes. Make custom touch screen interface GUIs, all open-source, and Python-powered using tinyJSON / APIs to get news, stock, weather, cat photos, and more \u2013 all over Wi-Fi with the latest technologies. Create little pocket universes of joy that connect to something good. Rotate it 90 degrees, it\u2019s a web-connected conference badge #badgelife.Like many other CircuitPython powered devices the PyPortal has a great Explore and Learn page available that walks you through getting the right firmware installed as well as providing hardware breakdowns, code demos and FAQ.</p> <p>Once I had the PyPortal up to date and had gone through a couple demos I landed on having my first badge being a simple menu systems. While many badges will contain easter eggs or ways to interact with other badges I decided to keep it simple for this first run. I wanted my badge to be able to display a couple pieces of static data and have a couple interactive options.</p> <p>I landed on a Button menu that would show a couple maps, a photo of my badge, a countdown to Gen Con, and a simple D20 roller.</p> <p>Along the way I made extensive use of the docs and source code that Adafruit provides.</p> <p>I also found it easy to find documentation for the module I would pull in from the library modules by referencing the list of submodules on Read the Docs</p>"},{"location":"blog/2019/07/14/creating-a-con-badge-with-pyportal/#curiosities","title":"Curiosities","text":"<p>While building my badge I ran into some interesting edges that I hope to explore further. I'm sharing these here just in case somebody else reads this and can avoid similar pitfalls or suggest a different direction.</p> <ul> <li>Large buttons seem to lead to performance and OOM errors</li> <li>Originally my menu had 8 buttons (one with information about Adafruit, another with information about the project),   but that wasn't stable. After 3 or 4 clicks gc or something else couldn't keep up with the memory allocation and the   badge would crash with a MemoryError</li> <li>My schedule was also a menu of buttons originally. This let me setup a list of tuples I could manipulate in code, but   when I had 5 buttons span the screen render time was visibly slow, and lead to inconsistent OOM errors.</li> <li>Different fonts have different performance characteristics</li> <li>Looking back this makes sense. Different glyphs will have different structures. Depending on that a glyph can place   different loads on the system. I tried a few of the \"performance\" font from GoogleFonts, but ultimately landed on   Arial Bold for a font that looked consistent, rendered quickly and didn't have a large file size.</li> <li>Better ways to sleep?</li> <li>My badge spends a lot of time in the main super loop polling if a button has been pressed. At this time I don't think   CircuitPython supports interrupts. I hope in the future i can figure out a better was to let the device sleep, but   capture an interrupt type event such as the display being touched.</li> <li>PDB for CircuitPython</li> <li>I spent a lot of time running snippets in the REPL. This is a nice experience to have for an embedded device, but I do   miss having PDB or WebPDB to drop a breakpoint in my code, let it run and then inspect the stack, heap etc from a   given point in my program. I believe MicroPython contains this functionality so I'm guessing it's possible with   CircuitPython I just haven't dug in to make it happen yet.</li> </ul>"},{"location":"blog/2019/07/14/creating-a-con-badge-with-pyportal/#lessons-learned","title":"Lessons Learned","text":"<p>Similar to the interesting behaviors I found above I learned a bit about developing with CircuitPython and how it can differ from my day to day Python development along the way.</p> <ul> <li>Python data structure sizes</li> <li>Many code bases make liberal use of dictionaries. In fact some say that Python is built on top of the dict data   structure. It's incredibly useful to look items up by key, and provides some human readability over indexing into a   collection with no reference beyond position. That said Dictionaries are one of   the largest   builtin Python objects. One of the reasons for this is something called a load factor that I won't go into now, but   suffice to say as you add more objects to a dictionary and it approaches a given load factor it will automatically   grow in size. Because of this in a memory constrained environment I found myself removing dictionaries or list of   dicts and using more tuples and list of tuples.</li> <li>Take out the garbage</li> <li>Python Garbage Collection is handled via reference counting. Because of this it's important to think about when an   object (especially large objects ) you are using come in scope, and when they leave scope. In an environment like   CircuitPython you may also want to call gc.collect() when you leave scopes with large objects to make sure they are   garbage collected before you carry on. This can help avoid some OOM errors.</li> <li>Careful wih that indirection.</li> <li>I found myself removing helper functions and other pieces of code that helped keep things \"clean\". Often times I did   this because I was hitting performance of OOM errors that would go away when I put the functionality in the parent   scope. Because of this I have repeated code, and code that isn't what I would expect to pass code review day to day,   but it works, achieved stability and gave the performance I'm looking for on my badge.</li> <li>Testing and profiling for this environment is still a challenge for me.</li> <li>I would love to be able to write a test for my function and then profile that test to capture things like stack depth,   object sizes, timing, etc. And since I have a test I could do this N times to see what kind of behaviors emerge.   Instead right now I manually make a change and validate. Because of this I think I'm building an intuition of what is   happening, but I can't verify it which leads me to assume my understanding has gaps, and potentially wrong assumptions   today. Making this better can help me address the point above.</li> </ul>"},{"location":"blog/2019/07/14/creating-a-con-badge-with-pyportal/#next-steps","title":"Next Steps","text":"<p>So with v1 of the badge prepared and ready for Gen Con 2019 I'm going to step back and work on some other items in this space. While working on the project I found out that labels don't support an orientation flag. After mentioning this in discord I opened an issue on Github with some encouragement from @ladyada. Hopefully I can spend some cycles working on that.</p> <p>I also continue to think about how to write tests for CircuitPython. Since the runtime is tied to the boards it's not as simple as running the code in a CPython unittest environment. While there is a lot of overlap in the API and behavior it's not a one to one match. I think being able to test the code would lead to faster development cycles and would open the door to better profiling and understanding of my applications behavior.</p> <p>Finally I plan to back up and read Making Embdedded Systems by Elicia White and visit some other embedded getting started materials. While I had a lot of ideas for this project (and I'm happy with how it turned out) I realized that since I'm not as familiar with this type of hardware environment I struggled at times to get the functionality I was looking for with the performance I needed.</p>"},{"location":"blog/2019/07/14/creating-a-con-badge-with-pyportal/#acknowledgements","title":"Acknowledgements","text":"<p>Thanks to the team at Adafruit. The devices they build and the creation of CircuitPython has lead me to pick up a hobby that continues to be fun and encourages me to think in new ways about hardware and the programs I'm writing. Additionally Adafruit has a discord where many people have been incredibly patient and helpful as I learn and ask questions.</p>"},{"location":"blog/2019/07/14/creating-a-con-badge-with-pyportal/#contact","title":"Contact","text":"<p>I've really enjoyed working on this project. If you want to reach out feel free to follow up via email or on.</p> <p>You can find out more about the badge and source code in the repo</p>"},{"location":"blog/2019/07/14/creating-a-con-badge-with-pyportal/#more-photos","title":"More Photos","text":"<p>Some additional photos of the portal. I've ordered a case off thingiverse , but using the Adabox case while I wait.</p>"},{"location":"blog/2019/08/01/connected-roomba---possibilities/","title":"Connected Roomba - Possibilities","text":"<p>A couple years ago at PyCon I received a kit from Adafruit containing the Circuit Playground Express. After going through the Hello World examples I boxed it up I didn\u2019t have a project ready to go. Fast forward to the winter of 2018 when I decided I would like to be able to start our Roomba away from home because of the noise it makes, and suddenly I had the project I was looking for. Digging around I found out about the Roomba Open Interface and set out to start talking to my Roomba with CircuitPython.</p>"},{"location":"blog/2019/08/01/connected-roomba---possibilities/#will-this-work","title":"Will this work","text":"<p>After reading through the Open Interface spec I decided it should be possible for me to control the Roomba by using the Circuit Playground Express that I had waiting on the shelf. Getting the kit out and using the clips available I connected the Playground Express TX to the Roomba RX, opened a REPL and tried to wake the Roomba, but received no response.</p> <p>After some more searching I found out that certain series firmware will not respond to wake commands after 5 minutes without a signal. Knowing this, and pressing the power button once to wake the Roomba, I was able to START, STOP and DOCK the Roomba with controller code running on the Playground Express.</p> <p></p>"},{"location":"blog/2019/08/01/connected-roomba---possibilities/#next-steps","title":"Next steps","text":"<p>After spending some more time confirming command structures, documentation and behavior between CircuitPython and the Roomba Open Interface I decided to make things easier by building a package to abstract the interactions. With basic wiring and command functionality confirmed I decided it was time to start looking at making remote signalling covered in part 2.</p>"},{"location":"blog/2019/08/02/connected-roomba-remote---lora/","title":"Connected Roomba Remote - LoRa","text":"<p>With a basic setup working the next thing I wanted to do was make communication wireless. Thinking about my options I ruled out using WiFi pretty quick since I didn\u2019t want to worry about discovery and router issues. I thought about Bluetooth since I could send commands from my phone to the board on the Roomba, but decided against it due to my lack of mobile programming experience and not wanting to add yet another new thing to learn. (Side note I\u2019ve since learned about the Bluefruit app) Looking at the other Feather options I decided to make use of LoRa for my communication layer since it would be easy to use, my packets are tiny and I didn\u2019t have to worry about software beyond CircuitPython.</p>"},{"location":"blog/2019/08/02/connected-roomba-remote---lora/#the-boards","title":"The boards","text":"<p>With the protocol determined and sticking with CircuitPython I found a Feather with LoRa built in, and a Pi Zero Bonnet with some buttons and a small display that would make testing easier. After reading through thedocs and tutorials for both boards I began work on signalling the Roomba to start with the push of a button.</p> <p>One of the first road blocks I ran into was of my own creation. The Roomba library I wrote for prototyping was too big for the Feather. The good news was OpenInterface was still useful, and there was plenty of room for the base class after removing the debug and abstraction code, so I only compiled the commands I knew I was going to use for version 1 and continued moving forward.</p> <pre><code>class OpenInterface:  \n def init(self, txpin, rxpin, brcpin, baudrate=115200):  \n self.board = busio.UART(txpin, rxpin, baudrate=baudrate)  \n self.txpin = txpin  \n self.rxpin = rxpin  \n self.brcpin = brcpin  \n self.brcpin.direction = digitalio.Direction.OUTPUT  \n self.baudrate = baudrate  \n self.stopped = True def start(self):  \n if self.stopped:  \n self.wakeup() for command in (b\"\\x80\", b\"\\x83\", b\"\\x87\"):  \n self.board.write(command) def stop(self):  \n for command in (b\"\\x85\", b\"\\xAD\"):  \n self.board.write(command)  \n self.stopped = True def wakeup(self):  \n for i in range(3):  \n self.brcpin.value = False  \n time.sleep(0.5)  \n self.brcpin.value = True  \n time.sleep(0.5)  \n self.brcpin.value = False  \n time.sleep(0.5) self.stopped = False\n</code></pre> <p>After stripping things down and getting the Feather to start and stop the Roomba from the REPL I turned my attention to the Pi.</p> <p></p> <p>With the Pi Zero providing more resources installing the OS, setting up SSH and compiling Python 3.7 took more time then getting the Circuit Python libraries working. Blinka worked like a charm and following the docs from above I had a quick script to send start and stop packets via LoRa working in no time.</p> <pre><code>while True:  \n try:  \n if not startbutton.value:  \n msg = \"Starting Roomba.\"  \n logger.info(msg)  \n rfm9x.send(bytes(\"1\", \"ascii\"))  \n display.fill(0)  \n display.text(msg, 25, 15, 1)  \n elif not stopbutton.value:  \n msg = \"Stopping Roomba.\"  \n logger.info(msg)  \n rfm9x.send(bytes(\"0\", \"ascii\"))  \n display.fill(0)  \n display.text(msg, 25, 15, 1)\n</code></pre> <p>The display on the bonnet was a nice touch so that I could watch the Feather in a terminal while the Pi let me know immediately which button was pressed and which command I should expect the Feather to receive.</p> <p></p>"},{"location":"blog/2019/08/02/connected-roomba-remote---lora/#next-steps","title":"Next Steps","text":"<p>With the boards talking to each other and the ability to start/stop the Roomba with the press of a button the last thing to do was make this work when we are not at home. While LoRa has a pretty good range I wanted this to work for my wife and I without having to worry about where we are. In part 3 I look at making this work with SMS.</p>"},{"location":"blog/2019/08/03/connected-roomba---sms/","title":"Connected Roomba - SMS","text":"<p>As I mentioned before one of the primary reasons for starting this project was to let my wife and I start the Roomba when we are not at home. One device that most of us take everywhere is our phone. An easy way to to send information from your phone without a custom app, stack and hassle is SMS. While it\u2019s easy to broadcast receiving that message can take a little work.</p>"},{"location":"blog/2019/08/03/connected-roomba---sms/#twilio","title":"Twilio","text":"<p>Luckily monitoring a number for messages is pretty much a solved problem. Twilio offers an easy way to setup number with an attached webhook for receiving and sending messages. They also have a nice Python tutorialthat had me up and running in about 10 minutes. Since I was already using the Pi Zero to send commands to the Roomba setting up a script to watch for an SMS message and pass on the new command was simple enough.</p> <pre><code>import busio  \nimport board  \nimport adafruitrfm9x  \nfrom digitalio import DigitalInOut  \nfrom flask import Flask, request  \nfrom twilio.twiml.messagingresponse import MessagingResponseCS = DigitalInOut(board.CE1)  \n\nRESET = DigitalInOut(board.D25)  \nspi = busio.SPI(board.SCK, MOSI=board.MOSI, MISO=board.MISO)  \nrfm9x = adafruitrfm9x.RFM9x(spi, CS, RESET, 433.0)  \nrfm9x.txpower = 23app = Flask(name)  \n\n@app.route(\"/sms\", methods=[\"GET\", \"POST\"])  \ndef smsstartroomba():  \n  \"\"\"  \n  When a message is received determine which  \n  signal to send the Roomba and reply  \n  to the sender.  \n  \"\"\"** *txt = request.values.get(\"Body\").lower() if txt == \"start\":  \n  msg = \"Starting the Roomba.\"  \n  cmd = bytes(\"1\", \"ascii\")  \n  elif txt == \"halt\":  \n  msg = \"Stopping the Roomba.\"  \n  cmd = bytes(\"0\", \"ascii\")  \n  elif txt == \"dock\":  \n  msg = \"Roomba beginning to dock.\"  \n  cmd = bytes(\"2\", \"ascii\")  \n  else:  \n  msg = \"Unknown command. Continuing.\"  \n  cmd = None if cmd:  \n  rfm9x.send(cmd) resp = MessagingResponse()  \n  resp.message(msg) return str(resp)  \n\nif name == \"main\":  \n app.run(debug=False)\n</code></pre> <p>And with that the same board I had used to test sending messages in response to button clicks can now receive SMS payloads and translate that into a command that the Feather will use to start, stop or dock the Roomba.</p>"},{"location":"blog/2019/08/03/connected-roomba---sms/#next-steps","title":"Next Steps","text":"<p>With all the pieces assembled and working the last thing to do for version 1 was setup some redundancy, restart everything and make sure it all worked as expected without my intervention.</p>"},{"location":"blog/2019/08/04/connected-roomba---wrapping-up/","title":"Connected Roomba - Wrapping Up","text":"<p>With everything working I wanted to make sure I didn\u2019t have to reset everything anytime an odd decode error occurs, something loses and regains power, etc. For the Feather attached to the Roomba handling this is pretty straight forward. Everything is already running in a super loop, so all I need to add is a try/exceptblock to the while loop and discard errors. Doing the same thing for the Pi was again straight forward, but since it is running Linux I needed to make sure the applications handled failures, and that the scripts restart if the board restarts, the OS bounces, etc.</p> <p>Similar to the Feather code I wrapped everything in a while loop, added exception handlers, but I also added logging so that I could understand if errors are created by the OS, the code or something else:</p> <pre><code>import logging  \n\nLOGFORMAT = \"%(asctime)s:%(levelname)s:%(message)s\"  \n\nlogging.basicConfig(  \n filename=\"/home/pi/logs/button.log\",  \n level=logging.INFO,  \n format=LOGFORMAT,  \n datefmt=\"%m/%d/%Y %I:%M:%S %p\",  \n)  \n\nlogger = logging.getLogger(name)...if name == \"main\":  \nwhile True:  \n try:  \n ...  \n except BaseException as e:  \n  logger.exception(e)  \n pass\n</code></pre> <p>And since this is running on Linux setting up cron to handle starting the applications after reboot was one command away.</p> <pre><code>sudo crontab -e@reboot cd /home/pi/ &amp;&amp; /home/pi/.virtualenvs/lora-pi/bin/python /home/pi/projects/roombasupervisor/buttonlistener.py 2&gt;&amp;1 &gt;&gt; /home/pi/logs/button.log  \n@reboot cd /home/pi/ &amp;&amp; /home/pi/.virtualenvs/lora-pi/bin/python /home/pi/projects/roombasupervisor/smslistener.py 2&gt;&amp;1 &gt;&gt; /home/pi/logs/sms.log  \n@reboot sleep 10 &amp;&amp; cd /home/pi/ &amp;&amp; /home/pi/ngrok http 5000 2&gt;&amp;1 &gt;&gt; /home/pi/logs/ngrok.log  \n@reboot sleep 20 &amp;&amp; curl http://127.0.0.1:4040/api/tunnels 2&gt;&amp;1 &gt; /home/pi/logs/ngrokdetails.log\n</code></pre> <p></p>"},{"location":"blog/2019/08/04/connected-roomba---wrapping-up/#wrapping-up","title":"Wrapping Up","text":"<p>Since this was my first project interacting with an embedded system I learned quite a bit along the way. Abstractions are something that are useful, but can add bloat and load that won\u2019t work in constrained environments. I wasn\u2019t able to use the Roomba library I built with the Circuit Playground on the Feather that I connected to the Roomba. CircuitPython made learning and prototyping easy with a REPL and constant connection to the Open Interface. It also allowed me to focus on learning more about the boards and data interactions since I wasn\u2019t busy rebuilding my software toolchain for a new environment. That said it has also inspired me to learn more and dig deeper into the embedded world since there are a lot of things I can\u2019t user (interupts). There is a lot that I don\u2019t know or understand yet, but with the help of some books and boards I am sure I will be busy expanding my understanding for the next few years.</p>"},{"location":"blog/2019/08/04/connected-roomba---wrapping-up/#contact","title":"Contact","text":"<p>I really enjoyed working on this project. If you want to reach out feel free to follow up via email or on .</p>"},{"location":"blog/2019/08/08/postgres-advisory-locks-with-asyncio/","title":"Postgres Advisory Locks with Asyncio","text":"<p>Recently, here on the Cloud team at Elastic we started working on building a new service in Python 3.7. This service fetches data from a Postgres database, transforms it, and then submits that data to another service. Like many cloud-based services, ours runs in an orchestrated container environment where N instances can be running at any time. Often that\u2019s a good thing, but our service has a few critical sections where only one instance should be able to process data. Since we are retrieving data from Postgres, we decided to go ahead and make use of advisory locks to control these critical sections. In this article I want to explain what advisory locks are, provide an implementation, and test to verify functionality.</p>"},{"location":"blog/2019/08/08/postgres-advisory-locks-with-asyncio/#advisory-locks","title":"Advisory locks","text":"<p>Postgres provides the ability to create locks that only have meaning within the context of your application. These are advisory locks. You use advisory locks to control an application\u2019s ability to process data. Anytime your application is about to enter a critical path, you attempt to acquire the lock. When you acquire the lock, you can safely continue processing.</p> <p>async with AdvisoryLock(\"goldleader\", dbconfig) as connection:If it fails, then your application may retry, wait, or exit. Since this lock is external to the application, this allows for multiple instances of the application to run while providing safe critical path concurrency.</p>"},{"location":"blog/2019/08/08/postgres-advisory-locks-with-asyncio/#building-the-lock","title":"Building the lock","text":"<p>As part of our work, we wanted to make using advisory locks easy. To do this, we created the PostgresAdvisoryLock context manager. Since this is meant to be used with asyncio and asyncpg, we control the acquisition and release of the lock via aenter and aexit.</p> <pre><code>class AdvisoryLock:  \n async def aenter(self) -&gt; asyncpg.connection.Connection:  \n self.lockedconnection = await asyncpg.connect(...)  \n await self.setlock()  \n if self.gotlock:  \n return self.lockedconnection  \n else:  \n if self.lockedconnection:  \n await self.lockedconnection.close()  \n raise AdvisoryLockException async def aexit(self, exctype, excval, exctb):  \n await self.release()Now this can be called like any other async context manager.\n\nasync with AdvisoryLock(config, \"appname\") as connection:  \n val = await connection.fetchrow(\"SELECT 1\")\n</code></pre>"},{"location":"blog/2019/08/08/postgres-advisory-locks-with-asyncio/#testing-the-lock","title":"Testing the lock","text":"<p>Now that the PostgresAdvisoryLock class is implemented, we need to test it. To start we verify the base functionality by acquiring the lock, running a query, and validating we can't get the lock inside the same scope. I recommend using the asynctest library to help work with asyncio inside unittest.</p> <pre><code>async def testgetresultswithlock(self):  \n async with AdvisoryLock(\"goldleader\", dbconfig) as connection:  \n val = await connection.fetchrow(\"SELECT 1;\")  \n self.assertEqual(val[0], 1) async def testlockpreventssecondlock(self):  \n with self.assertRaises(AdvisoryLockException):  \n async with AdvisoryLock(\"goldleader\", dbconfig) as connection:  \n await connection.fetchrow(\"SELECT 1;\")  \n async with AdvisoryLock(\"goldleader\", dbconfig) as secondconnection:  \n await secondconnection.fetchrow(\"SELECT 1;\")\n</code></pre> <p>Since we are going to use this to control the execution of code across many processes, we also need to verify external process behavior. To do this we use the asyncio subprocess.createsubprocessexec function to create a new process. This process attempts to get the lock our main process already has, and it should fail.</p> <pre><code>async def testadvisorylockpreventsaccessfromseparateprocess(self):  \n with self.assertRaises(AdvisoryLockException):  \n async with AdvisoryLock(\"goldleader\", dbconfig) as connection:  \n proc = await asyncio.subprocess.createsubprocessexec(  \n sys.executable,  \n \"-c\",  \n executable,  \n stderr=asyncio.subprocess.PIPE,  \n )\n</code></pre>"},{"location":"blog/2019/08/08/postgres-advisory-locks-with-asyncio/#wrapping-up","title":"Wrapping up","text":"<p>When we started to build our new application, we knew we would be waiting on the network and database. Since we also had work that could happen during the wait, we decided to use asyncio. Additionally we identified a critical path where we used Postgres to achieve concurrency control. To make critical path control easier we created a module and a series of tests. Once finished we realized this might be helpful to others looking for the same control, or as a reference for those learning to test with asyncio.</p> <p>You can find the full implementation and Docker setup on Sourcehut.</p>"},{"location":"blog/2019/09/27/hackaday-connected-world-follow-up/","title":"Hackaday Connected World Follow Up","text":"<p>Recently Hackaday announced the results of the Connected World contest. It made my day when I read Sophi\u2019s email telling me that ConnectedRoomba was one of the OSHPark certificate recipients. What may have seemed like a small announcement meant a lot to me. I\u2019m still fairly new to this area of computing, and without formal training. Instead I spend a lot of time reading, listening and building to learn everything I can. Validation and success no matter how big or small help us all stay motivated to continue in our pursuits. Thank you to everybody at Hackaday for setting up a community and contest for us all to continue learning, sharing and hacking together.</p>"},{"location":"blog/2019/09/27/hackaday-connected-world-follow-up/#whats-next","title":"Whats next","text":"<p>Everybody starts somewhere and the contest pushed me to get started on my first homebrew project. As part of this I found a lot of new areas to study up on. I\u2019ve enrolled in the edX Embedded Systems course. If you\u2019re taking that too reach out as I\u2019d love to have a group to work with. Additionally I want to migrate the ngrok setup in my project to a route on my own domain, understand secure LoRa transmission and expand my electronics knowledge.</p> <p>On the board front I found this interesting Feather PCB from @tannewt while debating what to do with the OSHPark certificate. I recently backed the FOMU and learned of FuPy so this seems like an interesting PCB to pick up, order some components and start learning electronics at a whole new level.</p> <p>Congrats to everybody that participated in the Connected World contest. Have fun hacking on whatever comes next! Thank you Hackaday, DigiKey and OSHPark for kick starting this new learning path :).</p>"},{"location":"blog/2019/09/27/hackaday-connected-world-follow-up/#contact","title":"Contact","text":"<p>If you want to chat feel free to follow up via email or on Sourcehut.</p>"},{"location":"blog/2019/10/18/edgerouter-x-ddns-with-gandi/","title":"EdgeRouter X DDNS with Gandi","text":"<p>I recently setup a VPN for my home network. To make use of it from remote networks I need to be able to resolve the public IP of my router. Instead of hard coding the IP I setup an domain with Gandi and created an A Record that I update from my router.</p>"},{"location":"blog/2019/10/18/edgerouter-x-ddns-with-gandi/#fetching-and-reporting-your-ip","title":"Fetching and reporting your IP","text":"<p>This part was fairly easy. With a quick search I found that somebody else had already solved the problem of reporting the public IP from an Ubiquiti router to Gandi! Checkout their work here. Their README provides a nice easy walk through of the setup.</p>"},{"location":"blog/2019/10/18/edgerouter-x-ddns-with-gandi/#scheduling-it","title":"Scheduling it","text":"<p>With the above script updated and working on my router the next thing to do was schedule it.</p> <p>Quick note only specific directories persist between firmware updates on the EdgeRouter. Because of this I suggest putting the script above in config/scripts/ or config/user-data.The EdgeRouter OS provides a helper utility called task-scheduler which wraps cron. The benefit of task-schedule is that is saves our commands to config so they persist through upgrades. ssh into your router:</p> <pre><code>ssh &lt;user&gt;@&lt;router&gt;  \nconfigure  \nset system task-scheduler task ddnsupdate  \nset system task-scheduler task ddnsupdate crontab-spec '0 5 * * 0'  \nset system task-scheduler task ddnsupdate executable path '/config/user-data/'  \ncommit  \nsave  \ncat /etc/cron.d/vyatta-crontab\n</code></pre>"},{"location":"blog/2019/10/18/edgerouter-x-home-vpn-setup-pt-1/","title":"EdgeRouter X Home VPN Setup Pt 1","text":"<p>Recently I got the itch to setup a VPN for my home network to access my device lab on the go, or share with others. My home setup isn\u2019t too complicated, but it\u2019s a bit different from other setups I found when I started down this path.</p> <p>Network Components: Arris Surfboard SB6141, Ubiquiti EdgeRouter X, Ubiquiti AmplifiHD</p> <p>I am not a network or sysadmin by day. This is something I\u2019m actively learning on and figuring out. If you see something wrong or have suggestions I would love to hear about it. Reach out.</p>"},{"location":"blog/2019/10/18/edgerouter-x-home-vpn-setup-pt-1/#preparing-the-network","title":"Preparing the network","text":"<p>As my starting point I had used the EdgeRouter wizard for initial setup way back when. The default places the network in the 192.168.1.0/24 range which should be changed to prevent a conflict for devices on remote networks. To add a new dhcp server handing out address in a new range we will use the ubiquiti ui.</p> <p>To start login to the ubiquiti ui and navigate to the Services tab.</p> <p></p> <p>From here you can see + Add DHCP Server on the left side of the screen.</p> <p></p> <p>Select Add and configure a new DHCP server leasing addresses in a new range ( 192.168..0). <p></p> <p>With this setup the next thing to do is test it works before removing the old DHCP server settings.</p> <p>Return to your Dashboard, and locate the switch0 interface. To the far right you should see an actions button.</p> <p></p> <p>Click, select config, and add a manually configured IP for the dhcp server you just configured (192.168.x.1). With switch0 talking to our new network range return to the Services tab. Click actions on the original DHCP server, select disable, and then logout.</p> <p>Now you can log back in on the new network range 192.168.x.1. Login, select switch0 from the Dashboardtab as we did earlier, and remove the original DHCP server. For any devices on your network that were active you will need to do a dhclient -r; dhclient to refresh your device (on *nix) ip and lease in the new range.</p>"},{"location":"blog/2019/10/18/edgerouter-x-home-vpn-setup-pt-1/#next-steps","title":"Next Steps","text":"<p>With the network configured we are now ready to install and setup wireguard Since this has already ran a bit long in the tooth part 2 can be found here.</p>"},{"location":"blog/2019/10/18/edgerouter-x-home-vpn-setup-pt-2/","title":"EdgeRouter X Home VPN Setup Pt 2","text":"<p>I am not a network or sysadmin by day. This is something I\u2019m actively learning on and figuring out. If you see something wrong or have suggestions I would love to hear about it.</p> <p>In part one we configured the network. Now we are ready to install Wireguard and create our interface. Before I jumped into doing this I referenced these post and docs.</p> <ul> <li>Wireguard</li> <li>Charles R. Portwood || Wireguard on Ubiquity OS</li> <li>David Wireguard Home Network</li> </ul> <p>To get started ssh into the EdgeRouter device.</p> <pre><code>ssh &lt;user&gt;@&lt;edgerouterip&gt;Once logged in we need to pull, install the Wireguard .deb.\n\ncd /tmp*# Download the appropriate version, pay special attention here, if you are using the Ubiquity v2 firmware  \n# you will need the wireguard-v2-*  \n*curl -qLs https://github.com/Lochnair/vyatta-wireguard/releases/download/0.0.20190913-1/wireguard-v2.0-e50-0.0.20190913-1.debsudo dpkg -i wireguard.debAn important note from the source repo\n</code></pre> <p>Note that since Wireguard is not software bundled with the EdgeOS firmware, firmware upgrades necessitate re-installing the Wireguard debian package. Once the wireguard package is re-installed re-applying the existing Vyatta config file, or rebooting will restore your interfaces.</p> <p>First things first we need to generate a private key for the router, and a public key to share with clients.</p> <pre><code>$ wg genkey | tee /dev/tty | wg pubkey  \n123ddgqeqe123123\n</code></pre> <p>This will output two lines. The first is your private key, the second is your public key. Keep these secure, but ready since you will need to provide the public key to all clients.</p> <p>With our keys generated we can now configure the Wireguard interface. Ours will be wg0. In the terminal:</p> <pre><code>configureset interfaces wireguard wg0 address 192.168.55.1/24  \nset interfaces wireguard wg0 listen-port 51820  \nset interfaces wireguard wg0 route-allowed-ips true  \nset interfaces wireguard wg0 private-key &lt;private-key-from above-output&gt;commit  \nsaveThis created a new wireguard network on 192.168.55.1/24; listening to port 51820 and will route all the traffic through wg0.\n</code></pre> <p>Now keeping our public key ready we can configure a client.</p>"},{"location":"blog/2019/10/18/edgerouter-x-home-vpn-setup-pt-2/#configuring-wireguard-on-ubuntu","title":"Configuring Wireguard on Ubuntu","text":"<p>If you\u2019re using Ubuntu 19.10 wireguard should be available from apt by default:</p> <pre><code>sudo apt-get update  \nsudo apt-get install wireguardWith prior versions:\n\nsudo add-apt-repository ppa:wireguard/wireguard  \nsudo apt-get update  \nsudo apt-get install wireguardOnce again we need to generate our keys, now on the client:\n\nwg genkey | tee /dev/tty | wg pubkeyNow, create the wireguard interface, still on the client.\n\ntouch /etc/wireguard/wg0.conf  \nchown root:root /etc/wireguard/wg0.conf  \nchmod 600 /etc/wireguard/wg0.confsudo vim /etc/wireguard/wg0.conf&lt;--------wg0.conf--------&gt;  \n</code></pre> <pre><code>[Interface]  \nAddress = 192.168.55.5/32  \nPrivateKey = &lt;client-private-key&gt;[Peer]  \nPublicKey = &lt;router-public-key&gt;  \nAllowedIPs = 192.168.55.0/24  \nEndpoint = publicipofrouter:51820\n</code></pre>"},{"location":"blog/2019/10/18/edgerouter-x-home-vpn-setup-pt-2/#peering-the-router-and-client","title":"Peering the router and client","text":"<p>With the client configured and keeping the public key it generated, return to the router. ssh and run:</p> <p>set interfaces wireguard wg0 peer  allowed-ips 192.168.55.5/32 commit save"},{"location":"blog/2019/10/18/edgerouter-x-home-vpn-setup-pt-2/#starting-your-client-vpn","title":"Starting your client VPN","text":"<p>With wg0 configured and ready bring up the VPN on our client.</p> <pre><code>sudo wg-quick up wg0\n</code></pre> <p>And verify connectivity by running sudo wg on the client, and router.</p>"},{"location":"blog/2019/10/18/edgerouter-x-home-vpn-setup-pt-2/#next-steps","title":"Next Steps","text":"<p>With VPN setup I\u2019m now able to access and provide access to my device lab. This also keeps devices using this router that are not part of the lab separated.</p> <p>Finally if you\u2019re doing this for the first time some next steps you might want to take include:</p> <ul> <li>Switch devices to only allowing ssh via keys.</li> <li>Switch to a non default ssh port.</li> <li>Setup fail2ban.</li> <li>Pickup from here</li> </ul>"},{"location":"blog/2019/10/18/edgerouter-x-pihole-setup/","title":"EdgeRouter X PiHole Setup","text":"<p>I\u2019ve seen a few post from people asking for help adding a PiHole to their network with an EdgeRouter. One solution I\u2019ve seen is to use brittanics black-list. This is nice for those wanting to run software on their router, but I didn\u2019t want the load, and I want the functionality that the PiHole provides. Hopefully this guide help those looking to add a PiHole in the future.</p>"},{"location":"blog/2019/10/18/edgerouter-x-pihole-setup/#setting-up-the-pihole","title":"Setting up the PiHole","text":"<p>I\u2019m going to assume you\u2019ve already installed PiHole on your device. If not the docs are a great place to start. If you set this up on a Raspberry Pi I encourage you to disable autologin, add a new user, add the user to the sudo group and enable ssh. For more information checkout the RaspberryPi docs.</p>"},{"location":"blog/2019/10/18/edgerouter-x-pihole-setup/#configuring-edgerouter-to-use-the-pihole","title":"Configuring EdgeRouter to use the PiHole","text":"<p>I\u2019m assuming your edgerouter is the DHCP server on your network.</p> <p>With PiHole installed, connect the device to your network (preferably wired) and login to the Ubiquity web ui. Click on the Services tab.</p> <p></p> <p>On this tab you should see an action button on the right side of the screen across from your DHCP information. Click it, and select configure. In the pop up window select Leases, and you should see the device your PiHole is on. Click the Static MAC/IP Mapping tab and give this device a static IP.</p> <p>While we are here click the details tab and add the IP as DNS 1.</p> <p></p> <p>Return to the main web ui Dashboard. At the bottom of the screen you should see a system tab with an arrow on the far right.</p> <p></p> <p>Click it and on the right side of the pop up add the IP you just assigned the PiHole as your Name Server.</p> <p></p> <p>With this in place login to your PiHole, navigate to network and you should see your router listed. The device should be highlighted green with a query count indicating that traffic is flowing through the PiHole as expected.</p>"},{"location":"blog/2019/12/01/cleaning-airflow-logs/","title":"Cleaning Airflow Logs","text":"<p>At home and work I make use of Airflow to automate various batch/time based task. I\u2019ve even setup a container based Airflow environment to make it easy to bring this up and down.</p> <p>One of the things you quickly find with Airflow is that while it doesn\u2019t need a lot of resources to run, it can quickly eat up whatever disk space you provide it with logs. When this happens the first knobs to look at turning are your log level and your schedulers dag bag refresh rate. While you may not be refreshing dags often your may want to keep your log level low to capture more data and use your log store to put a TTL on things at the INFO level. Unfortunately you can't completely turn off Airflows disk logging without building in some custom functionality today. To help manage this I wrote a small Python script that handles cleaning up the local logs on a given interval. Note if you're running Airflow in a setup other than LocalExecutor you will want to handle this with something like Cron instead of a dag since you need to clean logs up on the Scheduler, Worker and Webserver.</p> <pre><code>def truncateprocessmanagerlog(logbasepath):  \n \"\"\"  \n The scheduler records all acitivty related to dag processing in the same file.  \n This file can grow large fast, and is actively in use. Intead of unlinking the  \n file and pulling it out from under the scheduler truncate.  \n \"\"\"  \n dagprocessmanagerlog = os.path.join(  \n logbasepath, \"dagprocessormanager\", \"dagprocessormanager.log\"  \n )  \n open(dagprocessmanagerlog, \"w\").close()  \n\ndef traverseandunlink(fobject):  \n \"\"\"  \n Traverse the log directory on the given airflow instance (webserver, scheduler,  \n worker, etc) and remove any logs not modified in the last hour.  \n \"\"\"  \n for entry in os.scandir(fobject):  \n  newfobject = os.path.join(fobject, entry)  \n  if os.path.isfile(newfobject):  \n   lastmodified = os.stat(newfobject).stmtime  \n   delta = datetime.utcnow().timestamp() - lastmodified  \n  if delta &gt; HOURSINMILLISECONDS:  \n   print(  \n    f\"{newfobject} has not been used in the last hour. \\  \n   \\nCleaning up.\"  \n   )  \n   os.unlink(newfobject)  \n  elif os.path.isdir(newfobject):  \n   traverseandunlink(newfobject)\n</code></pre> <p>The full script is available here.</p>"},{"location":"blog/2019/12/01/review-edx-ut601-embedded-systems/","title":"Review EdX UT601 Embedded Systems","text":"<p>I recently completed my first EdX course Embedded Systems Shape the World and wanted to share a little bit about the experience.</p> <p>For a while now I\u2019ve been exploring various venues for continuing education. The longer I\u2019m in my field the more I learn and then that leads to me realizing how much more I want to learn in new areas. That said I\u2019ve never been great at taking courses that are not self paced partially because week to week my schedule can change dramatically between work and family. Because of this over time I\u2019ve tried out multiple platforms of learning such as Pluralsight, Khan Academy, formal online masters programs etc. All of them have their pros and cons ranging of cost to quality to engaging content.</p> <p>Last year I started learning more about SoC type hardware via Circuit Playground. This has lead me on an adventure to learn more and more about embedded systems, C and hardware. Most of this has been stitched together from various sources and ad hoc as the need arose in a personal project. Towards the end of summer I decided I wanted to formalize this learning and started to look around. There are online programs from universities like TESU, and individuals offering classes, but I stumbled across the UT 601 class on EdX and realized the setup would be a good fit for me. Additionally EdX offers verified courses with certificates which I thought might be nice in the future.</p> <p>Signing up and getting verified with EdX was easy. I was able to use my laptop and phone to complete all the task in under 30 minutes. The layout of EdX is very similar to other online learning platforms that I\u2019ve used.</p>"},{"location":"blog/2019/12/01/review-edx-ut601-embedded-systems/#ut-601","title":"UT 601","text":"<p>Once I started UT 601 I started to run into a few more barriers. The course requires the purchase of a Texas Instruments kit for use throughout, which makes sense this is an embedded systems course. What I wasn\u2019t expecting was the use of Keil. To complete the course I needed to be able to install Keil 4.2, and a simulator DLL (which was pretty neat) on a Windows platform. A couple annoyances there. This is an online course with the goal of global education opportunities, but immediately I'm locked into a platform, and additionally Arm places Keil behind a personal information collection form. I was happy that Microsoft provides a Windows 10 ISO that I could use within a VM to work on the course. After downloading that though I found that VirtualBox didn't pass through the board USB connection so that I could make use of the Stellaris Debugging software/firmware that I would need. After some time fiddling with it I ended up switching to VMWare, and after switching the USB connection to pass through as 2.0 was able to get everything packaged up into a Windows VM with Keil, the Stellaris software, the simulator DLL and the appropriate Keil registry edits. In case it would ever help anybody my VMWare config file is here.</p> <p>After spending a couple days getting the IDE, hardware and VM all setup and playing well together I dove into the course. Overall I enjoyed it. It exposed me to PIN programming and doing a lot of GPIO work that I haven\u2019t done in the past. Additionally it was a good refresh on concepts at the beginning like pipelining. One thing I did notice is there was a big jump from lab 5 to 6. We went from editing template projects to writing most of the project from the ground. Each section provded a different amount of direction (not gradually declining, but instead seemingly random) on how to complete the lab. New concepts were quickly introduced and some lacking explination such as using the Keil Oscilliscope and Analyzer. Overall it was a good course, but I would suggest dedicating a couple weeks and doing it all at once due to how much it ramps up half way through. The accompanying book is made available in each section and I highly recommend reading it as the videos act more as highlights than covering the material at a level that prepares you for the labs.</p> <p>The one thing that was a minor annoyance throughout was the reliance on Keil (IDE\u2019s have a place but often hide what the compiler and tools are doing creating a gap in knowing how stuff works) and the problems experienced by taking this course in a VM. Other than that the course was interesting and challenging.</p>"},{"location":"blog/2019/12/01/review-edx-ut601-embedded-systems/#wrapping-up","title":"Wrapping up","text":"<p>Overall I\u2019m glad I took and completed UT601. I learned a fair amount, and look forward to taking part 2 after the the new year. EdX is a platform I see myself continuing to use as it\u2019s been super simple, has a range of interesting content, and the course facilitators are really responsive.</p>"},{"location":"blog/2020/01/23/parsing-time-with-python/","title":"Parsing Time with Python","text":"<p>I recently had the need to measure time and performance on an application that interacted with a lot of on disk files. Most of the time when talking about timing and measurement in Python we see the use of timeitand various built in timing techniques. For this work I wanted a little more information about how the application was interacting with the system, and what the performance looked like from outside the application. Getting a rough view of this is pretty easy on a nix using /usr/bin/time.</p>"},{"location":"blog/2020/01/23/parsing-time-with-python/#parsing-time","title":"Parsing Time","text":"<p>To make use of time you simply call it with your application as an argument. You can find the time args with man time, but on useful one is the -v flag for more system information in the output, and an --output file path. Doing this you get a fair amount of page, time and system information in your output packaged up in a file that you can parse. In my script I'm also including some information in the file name so I can know what source file my application was parsing relating to that time information.</p> <pre><code>#!/bin/bash\n\nSRCDIRPATH=/data  \nRESULTS=/profilefor file in $SRDDIRFILES; do  \n filename=$(basename -- \"$file\")  \n filebase=\"${filename%.*}\"  \n echo $filebase  \n /usr/bin/time -v --output=$PROFILERESULTSDIR$filebase.txt cmd args  \n echo \"done\"  \ndonels -1sh $SRCDIRPATH &amp;&gt; profileddirectory.size\n</code></pre> <p>Once the application has ran you can see the output of time in your file, but you will also probably notice that it\u2019s just a text blob not ready for aggregation. Overall parsing time is relatively straight forward with one gotcha. I use the below to translate the blob into rows and columns:</p> <pre><code>import os  \nfrom typing import Tuple, List, Any, Union  \n\ndef formattimeprofileoutput(fpath, fobject) -&gt; List[Any]:  \n \"\"\"  \n Takes a directory of files containing the output of /usr/bin/time  \n and transforms the time blob data to a series of rows and columns.  \n \"\"\"  \n f = os.path.join(fpath, fobject)  \n timemetrics = [fobject] with open(f, \"r\") as tfile:  \n for line in tfile:  \n  if \"Elapsed\" not in line:  \n   cleanline = line.lstrip()  \n   metric, sep, value = cleanline.rpartition(\":\")  \n   timemetrics.append(value.strip())  \n  else:  \n   # Handling the special case of the Elapsed time  \n   # format using : in the time formatting.  \n   cleanline = line.lstrip()  \n   metric, sep, seconds = cleanline.rpartition(\":\")  \n   # we now have something like val = 43.45  \n   # metric = Elapsed (Wall Clock) time (H:MM:SS or M:ss) 1  \n   # partition again on metric, then combine back our time.  \n   metric, sep, minutes = metric.rpartition(\":\")  \n   # put time back into metrics  \n   value = f\"{min}:{secs}\"  \n   timemetrics.append(value.strip())  \n   # setup tool second metric for easier evaluation of  \n   # time metrics  \n   minutes = float(int(minutes) * 60)  \n   seconds = float(seconds)  \n   seconds += minutes  \n   timemetrics.append(seconds)  \n return timemetrics\n</code></pre> <p>Notice the one edge case in Elapsed (wall clock) time...). All other rows end with \\n and seperate the metric name from the value with :. Elapsed wall clock time however throws in a couple extra colons for fun. Overall not a big deal, but a little gotcha waiting in the details when going from a string to another object/format.</p> <p>Using the script above you end up with a collection of rows and columns that you can then use to find out how your application performed for that run instance.</p> <p>A quick bonus script, since my application was reading in and writing out new files I wanted to include the size of the input files so I could begin to understand the impact of the input file size on the applications time metrics.</p> <pre><code>import osdef formatsizeoutput(fpath, fobject) -&gt; List[List[str]]:  \n f = os.path.join(fpath, fobject)  \n sizemetrics = [] with open(f, \"r\") as sfile:  \n for line in sfile:  \n metric, sep, filename = line.rpartition(\" \")  \n sizemetrics.append([metric.strip(), filename.strip()])  \n return sizemetrics[1:]\n</code></pre> <p>With this and the above time parsing we have the input file size, name, application command, page and time information. More than enough to begin looking at what our application is doing from the outside.</p>"},{"location":"blog/2020/01/23/providing-context-with-mocks/","title":"Providing Context with Mocks","text":"<p>Day to day I spend a lot of time interacting with database systems. While this is super useful it can also create issues with testing that have been covered many many times in many other articles.</p> <p>In some languages isolating database interactions comes from dependency injection and swapping out the interface while testing. I\u2019ve seen this approach when working with C# for instance, but in Python I typically see code bases mocking out these interface points rather than passing in interfaces to functions and classes.</p>"},{"location":"blog/2020/01/23/providing-context-with-mocks/#mocking-context","title":"Mocking context","text":"<p>One of my favorite constructs in Python is the context manager. These are incredibly useful objects for defining what the creation and destruction of different interfaces should do viaenter and exit. (Append a for async context managers)</p> <p>While useful they can be a bit tricky for mocking out in your test, and recently when I started doing just that I couldn\u2019t find any good examples for accomplishing this. Below I\u2019ve provided an example of mocking out a context manager in your test, showing when you are interacting with different parts of your mock and the mocked context manager API.</p> <pre><code>def updateentity(k, v):  \n with pyodbc.connect(cnxnstr, autocommit=True): as cnxn:  \n  with cnxn.cursor() as crsr:  \n   crsr.execute()  \n</code></pre> <pre><code>from unittest import TestCase  \nfrom unittest.mock import patchclass InterfaceTest(TestCase):  \n @patch(\"mod.pyodbc.connect\")  \n def testupdateentity(self, mockcnxn):  \n # result of pyodbc.connect  \n mockcnxncontextmanager = mockcnxn.returnvalue  \n # object assigned to in with ... as con  \n mockcm = mockcnxncontextmanager.enter.returnvalue  \n # result of with ... as crsr, note the extra enter.returnvalue  \n # from the context manager  \n mockcrsr = mockcm.cursor.returnvalue.enter.returnvalue  \n mockcrsr.fetchone.returnvalue = (1,)  \n</code></pre> <p>Or if you want to test a sideeffect:</p> <pre><code>mockcrsr.fetchone.sideeffect** \n*self.assertEqueal(....)\n</code></pre> <p>Good luck mocking, context is what you make it.</p>"},{"location":"blog/2020/01/23/providing-context-with-mocks/#additional-reading","title":"Additional Reading","text":"<p>If you want to know more about context managers in Python checkout:</p> <ul> <li>PEP 343</li> <li>contextlib</li> </ul>"},{"location":"blog/2020/01/24/connected-roomba---managing-state/","title":"Connected Roomba - Managing State","text":"<p>Last year I started work and completed the first prototype for managing a roomba via sms and radio. Overall the prototype was a successful, but over time highly unreliable in the face of failure. Most of this came down to state management for the API endpoint and the Roomba OI (Open Interface) code running on the Feather. This week I had the opportunity to sit down and fix some of that.</p> <p>The latest version of the project can be found here.</p>"},{"location":"blog/2020/01/24/connected-roomba---managing-state/#roomba","title":"Roomba","text":"<p>In previous version of the application that ran on the Feather listening for messages over radio I had managed the application state in this class:</p> <pre><code>class OpenInterface:  \n def init(self, txpin, rxpin, brcpin, baudrate=115200):  \n self.board = busio.UART(txpin, rxpin, baudrate=baudrate)  \n self.txpin = txpin  \n self.rxpin = rxpin  \n self.brcpin = brcpin  \n self.brcpin.direction = digitalio.Direction.OUTPUT  \n self.baudrate = baudrate  \n self.stopped = True\n</code></pre> <p>I had done this so that I couldn\u2019t send the Roomba signals that were invalid for a given state based on the Open Interface documentation. The circuitroomba project were I originally implemented this actually did a lot more state management. Overall maybe this would be helpful during application development, but I found it made code on the board unreliable due to the size of the class object in memory and other work going on causing the board to eventually crash over an extended period of time.</p> <p>The more I thought about this I also realized I had caused an even larger issue. The Roomba itself manages state internally. It has all of the logic laid out in the OI document impelmented internally keeping things \u201csafe\u201d and tracking if a given signal is valid or not. By adding my own state management layer on top of this I opened the door for all kinds of trouble. First if the internal Roomba logic differed from the OI documentation, or I implemented the OI logic incorrectly I would be sending the application developer down all kinds of paths trying to figure out why state transistion and command signals were not exhibiting the expected behavior. Why setup 2 FSMs when one will do, and only one ends up being the true dispatch? If we did this at the sms API layer we could have 3, all with the potential for bugs, unexpected behavior, logic mismatches, timing issues etc. It\u2019s a combinatorial explosion of state management issues.</p> <p>So stepping back, considering the separation of concerns I determined all the board needed to do was listen for a given signal flag and pass that on to the Roomba. From there the Roomba can determine if the signal should be acted on based on it\u2019s internal state.</p> <p>The new implementation discards the class object and instead just uses a super loop and signal functions.</p> <pre><code>while True:  \n try:  \n packet = rfm9x.receive(1) if packet is not None:  \n packettxt = str(packet, \"ascii\")  \n print(packettxt) if packettxt == \"0\":  \n commandreceived(led)  \n led.value = True  \n stop(bot)  \n led.value = False  \n elif packettxt == \"1\":  \n commandreceived(led)  \n wakeup(brc)  \n start(bot)  \n led.value = True  \n else:  \n print(\"\\nUnknown packet: {}\\n\".format(packettxt))  \n except:  \n pass\n</code></pre> <p>Additionally from time to time signals can have issues that previously caused hanging in the application. Now the logic inside the super loop is wrapped in a try/except to prevent corrupt date from completely crashing the application. Instead failures are ignored and we keep listening for the next signal. While this isn't always a viable solution in the case of signaling the Roomba the stakes are low and this is something I'm comfortable with.</p>"},{"location":"blog/2020/01/24/connected-roomba---managing-state/#pi-zero","title":"Pi Zero","text":"<p>After fixing up the Feather board code I moved onto the Pi applications. Previously I had setup a Flask application to act as the SMS webhook for Twilio. This worked pretty well and was consistent over time, but there was the occasional hang running on the Zero that led me to look into managing the Python and Ngrok application with systemd. Converting from crontab was fairly easy. I created a few *.service files and placed them in /etc/systemd/system.</p> <pre><code>[Unit]  \nDescription=sms listener  \nAfter=ngrok.service[Service]  \nType=simple  \nUser=pi  \nWorkingDirectory=/home/pi  \nExecStart=/home/pi/.virtualenvs/lora-pi/bin/python /home/pi/projects/roombasupervisor/smslistener.py  \nRestart=on-failure[Install]  \nWantedBy=multi-user.target\n</code></pre> <p>Once the files were created I ran the following commands:</p> <pre><code>systemctl enable smslistener.service  \nsystemctl start smslistener.service\n</code></pre> <p>And now all of the required applications (ngrok, sms listener, button listener) are managed by systemd. This controls their startup better than the previous crontab setup and has the added benefit of restarting the service if it fails our.</p>"},{"location":"blog/2020/01/24/connected-roomba---managing-state/#wrapping-up","title":"Wrapping up","text":"<p>By observing and understanding the ways in which the prototyped system failed I was able to identify areas where behavior and functionality could be simplified resulting in an overall more reliable system. If you have any other tips to share reach out and good luck hacking.</p>"},{"location":"blog/2020/02/01/kicking-off-hardware-happy-hour-2020/","title":"Kicking off Hardware Happy Hour 2020","text":"<p>Last year we kicked off the first Hardware Happy Hour in Louisville Kentucky, USA. We had a lot of fun sharing our projects with each other and hearing about all the things being built in our own back yard. If you\u2019re building something you should try looking for an event in your area as more and more are popping up around the world.</p>"},{"location":"blog/2020/02/01/kicking-off-hardware-happy-hour-2020/#circuit-playground-workshop","title":"Circuit Playground Workshop","text":"<p>This year we wanted to start things off by inviting everybody to build and learn together with the Circuit Playground Express. On January 29th we got together 15 makers and hackers to have some fun with Arduino and Circuit Python making LEDs blink and speakers buzz. To kick things off Auystn introduced the group to the Arduino IDE, getting it to recognize your board setup, and receiving feedback via the serial console. As with any workshop we had plenty of fun figuring out why this and that didn\u2019t work on whatever OS, but in many ways I think that was exposure for those new to working with the boards and tools that unexpected behavior may occur, but we can find a solution.</p> <p>Once everybody had a board up and working Austyn spent some time getting everybody comfortable with the Arduino syntax and constructs. That turned into showing how to make some noise followed by a quick on/off switch demo. With a couple more code demos and showing off the Arduino code library we decided to switch gears and look at Circuit Python before having some general open make time.</p> <p>With Circuit Python we had the same demos with a different approach. Instead of using an IDE and editor we showed how you could put the board into bootloader mode and drag and drop the UF2 and code files directly on the board for loading. Along with that we demo\u2019d the ability to use REPL driven development on the boards for quick prototyping and feedback.</p> <p>Armed with Arduino and Circuit Python we decided it was time for us to step back and let people hack. Some had fun with accelerometer libraries while others scanned colors and lit up LEDs. By the end of the night I was rick rolled by a Circuit Playground.</p> <p></p> <p></p> <p></p> <p>More photos from the event here</p>"},{"location":"blog/2020/02/01/kicking-off-hardware-happy-hour-2020/#louisville-hardware-happy-hour-2020","title":"Louisville Hardware Happy Hour 2020","text":"<p>As 2020 continues we have 3 more H3 events planned in Louisville. Similar to our 2019 event we are planning to have a Q2 and Q4 social. If you\u2019re in the area we would love to see or hear about your project over some food and drink at Great Flood. In Q3 we are hoping to acquire some scopes to run a scope tutorial making use of the Circuit Playground boards and teaching attendees how they can see their programs in a new way.</p>"},{"location":"blog/2020/02/01/kicking-off-hardware-happy-hour-2020/#sponsors","title":"Sponsors","text":"<p>We (Austyn, Brad and I) want to give a huge shout out and thank you to the Louisville Civic Data Alliance. Without their support and sponsorship we would not be able to provide boards for all of the attendees to use. They have helped us kickstart a set of hardware that we can use to drive future workshops and education experiences. Thank you for providing us with the Code.org Circuit Playground Express Educators\u2019 Pack.</p> <p>Thank you to LVL1 for hosting. LVL1 is an amazing local resource in the area. If you haven\u2019t checked it out you should definitely try to make it to one of the Open Meeting and Making events on Tuesday nights.</p> <p>Thanks to Tindie for some awesome stickers and swag.</p> <p>And thank you to the various code.org donors who made the Adafruit Educators Pack possible for us to purchase and use.</p>"},{"location":"blog/2020/02/01/kicking-off-hardware-happy-hour-2020/#sponsorship-assistance","title":"Sponsorship Assistance","text":"<p>As I previously mentioned we are looking to run a scopes workshop this fall. If you or an organization you know is interested in sponsoring this event we are looking for help in acquiring digital scopes to provide attendees with. If you are interested in helping please reach out.</p>"},{"location":"blog/2020/02/01/kicking-off-hardware-happy-hour-2020/#where-to-follow","title":"Where to follow","text":"<p>To keep up with future H3 Louisville events we have a group setup on gettogether.community and we are active in the #hardware channel for Louisville Slack.</p> <p>Events will also be published to the Louisville Tech and H3 Louisville calendars.</p> <p>You can find our code and presentations on Github.</p>"},{"location":"blog/2020/02/02/the-structure-and-interpretation-of-computer-programs-in-2020/","title":"The Structure and Interpretation of Computer Programs in 2020","text":"<p>Last week I had the opportunity to attend a course by David Beazley on SICP (The Structure and Interpretation of Computer Programs). SICP is a book that was first published in 1985 and has grown to have a bit of a reputation in various circles of software engineering. The book itself explores many areas of computer science with a language called Scheme ( a lisp). For the course we made use of Racket and Python to explore those same concepts working through the book with an eye to it\u2019s impact on modern language and design.</p> <p>A quick note. This course was unlike any other I have been in so far. David is really good at giving learners the time and space to think as he lays out really dense material and like a tour guide provides interesting insights about the landscape. Another great part of the class was the size and how Dave gives people time to engage each other. Each morning we shared ideas, experiences and other stories over breakfast before throwing ourselves into the material breaking for lunch to contemplate what we had just built or discovered rounded off with an afternoon coffee. Overall this was a fantastic educational experience and I hope I get the opportunity to repeat it with some of Dave\u2019s other courses in the future.</p> <p>Throughout the week we engaged with various problems in the book such as evaluation models, abstraction, symbolic data and more. Each time we approached a problem we were encouraged to think as language designers and implementors rather than language users. In doing so we put ourselves in a different state approaching problem solving by extending the features of our language. This led us to implementing object hierarchy and evaluation models, dispatching state handling and creating custom interpreters with domain specific features to solve problems.</p> <p>One part of SICP book that stood out was the use of \u2018wishful thinking\u2019 as our programming model. We would look at a problem (for instance a constraints issue for assigning tenants to floors) and ask ourselves what a procedure or feature would look like for accepting the data and solving said problem. We would then implement this procedure and even mock calling other procedures that did not exist yet to model what we felt like an optimal interface might look like. From there we would build down implementing each new layer with wishful thinking. This came in contrast to a lot of my day to day experience approaching problems bottom up implementing low level details and data processing logic on our way to an isolated solution. In some ways it felt similar to TDD if you mock out all the functionality you don\u2019t have yet, but again with the top down mindset of I want the langauge to do X for me.</p> <p>Many other topics are covered throughout SICP. The book itself is very top down starting with the language and going all the way down to implementing a VM/register machine by the end of the book. Over time I may write some more about those topics. All in all the course was incredibly interesting. The conversations around lunch about the nature and philosophy of computing were a lot of fun and spawned by the material being covered as well as the various backgrounds we all had in our day to day work. You don\u2019t leave the course with a new package or framework in your toolbelt. Instead you\u2019ve examined of of the underlying fundamentals of languages, computing and software. This equips you with new models for thinking that will hopefully impact any future computing that you take part in. While the material is dense I think anybody that truly enjoys engaging with our craft would benefit from engaging with the SICP material in this setting.</p> <p>If anybody has questions about the course I\u2019d be more than happy to talk about the material. For those of you who don\u2019t know David Beazley I would encourage you to visit his site or search his name on YouTube as he has a lot of interesting material that encourages the learner to engage the material.</p>"},{"location":"blog/2020/02/03/define-zero/","title":"(define zero(\u2026.))","text":"<p>A couple weeks ago I had the opportunity to attend the SICP course taught by David Beazley. I\u2019ve written a short summary of my experience here (tldr; take the course if you get the chance). While the course as a whole was challenging and an interesting a couple of the exercises stood out to me, and I wanted to take a moment to share them here.</p>"},{"location":"blog/2020/02/03/define-zero/#true","title":"TRUE","text":"<p>At a deep level our computer is operating super fast on a state of ON/OFF with gates that define logic. Because of this it's an area of interest for me in how we express similar logic in our languages and the statement/operator capabilities we can build from that. Towards the beginning of day two we kicked things off by defining our own boolean logic in Racket. Our first step? Defining TRUE and FALSE.</p> <pre><code>(define (TRUE x y) x)  \n(define (FALSE x y) y)(define t (TRUE 0 1))  \n't  \n(define f (FALSE 0 1))  \n'fTake a minute and reread that block, because the first time I did it threw me for a loop. We just passed in the same arguments and got TRUE and FALSE. In Racket, and in this scenario we have defined the behavior of our basic TRUE and FALSE operators. The next challenge we were provided was to implement all boolean logic operators.\n\n(define (NOT x) (x FALSE TRUE))(NOT TRUE)  \n'f  \n(NOT FALSE)  \n't  \n\n(define (AND x y) (x y x))  \n(AND TRUE FALSE)  \n't(define (OR x y) (x x y))  \n(OR FALSE FALSE)  \n'f  \n(OR TRUE FALSE)  \n't  \n(OR FALSE TRUE)  \n't*;;\n</code></pre> <p>Hint: x is not just TRUE/FLASE above. It is a procedure, it takes two arguments. And we now have our own set of truth tables.</p>"},{"location":"blog/2020/02/03/define-zero/#defining-zero","title":"Defining Zero","text":"<p>Before working on boolean logic we had been discussing the substitution model of evaluation and what you could express with it. After our truth searching exercise it seemed like looking at how numbers could work might be fun.</p> <pre><code>(define zero (lambda (f) (lambda (x) x)))  \n(define two (lambda (f) (lambda (x) (f (f x)))))  \n(define three (lambda (f) (lambda (x) (f (f (f x))))))\n</code></pre> <p>Defining numbers as symbols for the application of a function N times then let us implement addition:</p> <pre><code>(define (plus a b)  \n (lambda (f) (lambda (x) ((a f) ((b f) x))))  \n )(define five (plus two three))\n</code></pre> <p>Or to make it concrete</p> <pre><code>(define (inc x) (+ x 1))((five inc) 0)  \n'5\n</code></pre> <p>Numbers are weird and amazing. Ever since I realized that anything we can express in a program (that I\u2019m writing in letters and symbols) can be boiled down to a series of 0s and 1s that were ultimately symbols that could be swapped out I\u2019ve been captivated by the question of what numbers are. We did other interesting and exercises (mutation, building an interpreter, a register machine VM, and generic types), but something about the above left me considering the nature of logic and programming. It\u2019s easy to get lost in the day to day problem solving, but when we get the chance to step back and look at the strangeness of what we are interacting with it can be a lot of fun. Here\u2019s one last thought to have some fun with:</p> <p>Always returns false, except for zero, because zero says don't do the function so we get back true</p> <pre><code>(define (zero? n) ((n (lambda (x) #f)) #t))\n</code></pre>"},{"location":"blog/2020/02/04/create-and-apply-a-git-patch/","title":"Create and Apply a Git Patch","text":"<p>I\u2019ve been using Source Hut as my primary host for source control and builds for a few months. I really enjoy it, but one of the main things I had to learn up front was how to apply a patch in git. Unlike Github and many other git host Source Hut makes use of the git patch work flow instead of PRs. At first I found this to be a bit frustrating, but I\u2019ve actually come to see the value in the email and patch workflow that is different from the IM and PR work flow that many of us are used to. Hopefully this helps somebody else that is learning to use patches in the future.</p> <p>Build your feature or modify your code on a separate branch:</p> <pre><code>git checkout -b ...  \ngit add ...  \ngit commit  \ngit push\n</code></pre> <p>Prepare a patchset:</p> <pre><code>git format-patch main\n</code></pre> <p>Alternative for a patch directory</p> <pre><code>git format-patch main -o patches\n</code></pre> <p>Or login and find the link to download the patch:</p> <pre><code>curl -O https://github.com/n0mn0m/circuitroomba/commit/ae635ce6533e33ff5277a0428a59c736a98649d6.patchls | grep \".patch\"  \n</code></pre> <p>Switch back to main:</p> <pre><code>git checkout main\n</code></pre> <p>Check the patchset changes</p> <pre><code>git apply --stat ae635ce6533e33ff5277a0428a59c736a98649d6.patch\n</code></pre> <p>Check for errors</p> <pre><code>git apply --check ae635ce6533e33ff5277a0428a59c736a98649d6.patch\n</code></pre> <p>Assuming the above command doesn\u2019t generate any errors you are ready to apply a clean patch. The git amcommand below includes the --signoff flag for others to view.</p> <pre><code>git am --signoff &lt; ae635ce6533e33ff5277a0428a59c736a98649d6.patch\n</code></pre> <p>And with that the patch has been applied to your main branch. Run your test again for sanity sake and push main.</p>"},{"location":"blog/2020/02/08/train-all-the-things---planning/","title":"Train All the Things - Planning","text":"<p>Earlier this year Hackaday announced the Train all the Things contest. I immediately knew I wanted to submit something, but figuring out what to build took me a little bit. For my side projects I like to make something that is useful to me, or somebody I know; while also learning something new. A few days after the contest was announced my daughter was in the basement playing outside my office/homelab when I remembered my wife had asked me if there was a way for her to know when I was working with somebody so that they could avoid coming down in the basement. I thought a voice driven display could be a fun solution.</p>"},{"location":"blog/2020/02/08/train-all-the-things---planning/#choosing-tools","title":"Choosing Tools","text":"<p>After deciding on the project the next thing I wanted to figure out was what new boards I would need (if any) and how I would build my model. After doing some research I landed on Tensorflow as my path forward for deploying a model to a microcontroller. Having used Tensorflow the barrier for model creation is a bit lower, but I am really curious about Tensorflow Lite and the potential it provides. Additionally a relatively new book TinyML looks like a good resource to use along the way.</p> <p>After settling on TF Lite the next thing was picking a board. Most of my embedded experience has been with CircuitPython and Rust. For this project I thought it would be fun to learn something new. The Espressif ESP-EYE caught my eye as an interesting board known to work with TF Lite. I\u2019ve seen the ESP32 and 8266 in a lot of other projects, so learning the ESP toolchain seems valuable. Additionally a lot of the Espressif ecosystem seems to be built around FreeRTOS which provides a whole other avenue of learning and hacking.</p> <p>Finally I will need a way to let somebody know when the model has picked up voice activity, to signal that I\u2019m currently busy in the lab. The ESP32 has a WiFi chip providing the ability to send and receive signals via TCP if we want. The ESP-EYE has that built in, and I happend to have a PyPortal (with an ESP32) that could make a great display checking for a status using WiFi too. To signal from one to the other I decided to have some fun and use Cloudflare Workers K/V to set a bit from the ESP-EYE that would be read by the PyPortal at a given time interval to set the display.</p> <p>Putting it all together the initial idea looks something like this:</p> <p></p> <p>Which allows me to have a small board in my homelab listening and the display above the stairwell where somebody can get a status update before they ever come down.</p> <p>The code, docs, images etc for the project can be found here and I\u2019ll be posting updates as I continue along to HackadayIO and this blog. If you have any questions or ideas reach out.</p>"},{"location":"blog/2020/02/18/a-simple-status-page/","title":"A Simple Status Page","text":""},{"location":"blog/2020/02/18/a-simple-status-page/#i-have-a-bad-habit-of-creating-side-projects-for-my-side-projects","title":"I have a bad habit of creating side projects for my side projects.","text":"<p>A couple months ago I switched from running my blog with Pelican and Gitlab Pages to Zola and Cloudflare Workers. I didn\u2019t do a write up on it, but if you\u2019re interested there\u2019s a good post by Steve Klabnik to get you started. It was a surprisingly easy switch, and gaps between writing haven\u2019t been as difficult with the better tools. After getting that setup I read about Cloudflare Workers KV , thought it sounded really neat and started to think about what I might build.</p> <p>On another project I need to signal between different systems a simple status. Naturally that lead to me building a status page. I setup a Cloudflare Worker that receives POST from N systems, stores the date of the last POST uses that to provide a status when asked.</p> <pre><code>const setCache = (key, data) =&gt; LOCALSTATUS.put(key, data);  \nconst getCache = key =&gt; LOCALSTATUS.get(key);function sleep(ms) {  \n  return new Promise(resolve =&gt; setTimeout(resolve, ms));  \n}\n\nfunction dateToStatus(dateTime) {  \n var isoDateNow = Date.now();  \n var dateDiff = (isoDateNow - dateTime);  \n if (dateDiff &lt; 180000) {  \n  return 1  \n } else {  \n  return 0  \n }  \n}\n\nasync function getStatuses() {  \n const cacheKeys = await LOCALSTATUS.list();  \n while (!(cacheKeys.listcomplete === true)) {  \n  sleep(5)  \n } \n\n const numKeys = cacheKeys.keys.length;  \n\n var statuses = []; for (var i = 0; i &lt; numKeys; i++) {  \n  var c = cacheKeys.keys[i];  \n  var epcDate = await getCache(c.name);  \n  var data = {date: Number(epcDate), name: c.name};  \n  data.strDate = new Date(data.date).toISOString();  \n  data.status = dateToStatus(data.date);  \n  data.statusIndicator = getStatusIndicator(data.status);  \n  statuses.push(data);  \n }\n\n const body = html(JSON.stringify(statuses || [])); return new Response(body, {  \n  headers: { 'Content-Type': 'text/html' },  \n });  \n}\n\nasync function getStatus(cacheKey) {  \n  var cacheDate = await getCache(cacheKey); if (!cacheDate) {  \n    return new Response('invalid status key', { status: 500 });  \n  } else {  \n   var status = dateToStatus(cacheDate);  \n   return new Response(status, {status: 200});  \n  }  \n}\n\nasync function updateStatus(cacheKey) {  \n  try {  \n   var isoDate = Date.now();  \n   await setCache(cacheKey, isoDate);  \n   var strDate = new Date(isoDate).toISOString();  \n   return new Response((cacheKey + \" set at \" + strDate + \"\\n\"), { status: 200 });  \n  } catch (err) {  \n   return new Response(err, { status: 500 });  \n  }  \n}\n\nasync function handleRequest(request) {  \n  let statusKey = new URL(request.url).searchParams.get('service');  \n  let queryType = new URL(request.url).searchParams.get('query'); \n  if (request.method === 'POST') {  \n   return updateStatus(statusKey);  \n  } else if (queryType === 'simple') {  \n   return getStatus(statusKey);  \n  } else {  \n   return getStatuses();  \n  }  \n}\naddEventListener('fetch', event =&gt; {  \n event.respondWith(handleRequest(event.request))  \n})\n</code></pre> <p>With that anything that can POST can \"check in\" with the endpoint. You can see it working here. I also went ahead and wrote a simple systemd service that I can drop on to different machines I want to have report in to the endpoint.</p> <pre><code>[Unit]  \nDescription=Regular check in  \nWants=check-in.timer[Service]  \nType=oneshot  \nExecStart=/usr/bin/curl -X POST https://status.burningdaylight.io/?service=JETSON[Install]  \nWantedBy=multi-user.targetAnd a timer for the service.\n\n[Unit]  \nDescription=Run checkin every 2 minutes  \nRequires=check-in.service[Timer]  \nUnit=check-in.service  \nOnUnitInactiveSec=1m[Install]  \nWantedBy=timers.target\n</code></pre> <p>This was a fun \u201cServerless/FaaS\u201d experiment that actually let me know my ISP was having an outage one morning before work. I\u2019ve used other Functions as a service on other cloud platforms and while they all provide slightly different functionality (For instance Cloudflare being a CDN and the V8 isolate setup) Cloudflare Workers has been really easy to work with and a lot of fun to build experiments on. They even have a web playground that you can start with.</p> <p>Two things I do wish were easier are interacting with K/V from Rust. This is probably partially related to how new I am to Rust, but working with K/V from JS is super easy, while this thread documents another experience with Workers and Rust in more detail. Another mild annoyance is working with different workers from the same machine and how API keys are handled. There are some suggestions for this, but non of them feel ergonomic at this time. Other than that my experience with Workers and K/V has been great and I\u2019ve already got more ideas for future experiments.</p> <p>The code, docs, etc for the project can be found here. If you have any questions or ideas reach out.</p>"},{"location":"blog/2020/03/01/train-all-the-things--signaling/","title":"Train All the Things \u2014 Signaling","text":"<p>After figuring out what I was going to use for my project I started work with things I know. I already had some experience with Cloudflare workers building a home system status page, and Workers K/V makes storing and fetching data quick and easy. I ended up with a simple endpoint that I POST to set a bit after keyword detection, and the PyPortal retrieves that status to determine what to display:</p> <pre><code>const setCache = (key, data) =&gt; SIGNALS.put(key, data);  \nconst getCache = key =&gt; SIGNALS.get(key);async function getStatus(cacheKey) {  \n var serviceStat = await getCache(cacheKey); if (!serviceStat) {  \n  return new Response('invalid status key', { status: 500 });  \n } else {  \n  return new Response(serviceStat, {status: 200});  \n }  \n}\n\nasync function setStatus(cacheKey, cacheValue) {  \n try {  \n  await setCache(cacheKey, cacheValue);  \n  return new Response((cacheKey + \" set to \" + cacheValue + \"\\n\"), { status: 200 });  \n } catch (err) {  \n  return new Response(err, { status: 500 });  \n }  \n}\n\nasync function handleRequest(request) {  \n  var psk = await getCache(\"PSK\")  \n  let presharedKey = new URL(request.url).searchParams.get('psk');  \n  let statusKey = new URL(request.url).searchParams.get('service');  \n  let statusValue = new URL(request.url).searchParams.get('status'); if (presharedKey === psk) {  \n  if (request.method === 'POST') {  \n   return setStatus(statusKey, statusValue);  \n  } else if (request.method === 'GET' &amp;&amp; statusKey) {  \n   return getStatus(statusKey);  \n  } else {  \n   return new Response(\"\\n\", { status: 418 });  \n  }  \n  } else {  \n   return new Response(\"Hello\")  \n  }  \n}  \n\naddEventListener('fetch', event =&gt; {  \n event.respondWith(handleRequest(event.request))  \n})\n</code></pre> <p>Nothing tricky happening above, just checking the request, and calling the appropriate function to store or fetch the status bit. With the function deployed to my Cloudflare Worker and verified with some GET and POST calls I was ready to move on to the display.</p> <p>The code, docs, images etc for the project can be found here and I\u2019ll be posting updates as I continue along to HackadayIO and this blog. If you have any questions or ideas reach out.</p>"},{"location":"blog/2020/03/05/train-all-the-things--display/","title":"Train All the Things \u2014 Display","text":"<p>Continuing my project with things I know the PyPortal display was up next. Last year I spent a few weeks playing with the portal to make a badge at Gen Con and had a lot of fun with it. Since that time CircuitPython 5 has been released and the portal now expects a few new modules which were easy enough to download and send to the board. The PyPortal makes it incredibly easy to point at an endpoint to fetch data:</p> <pre><code>import board  \nfrom adafruit import PyPortalpyportal\n\npyportal = PyPortal(  \n url=&lt;your url here&gt;,  \n default=\"green.bmp\"  \n)\n\nstatus = pyportal.fetch()  \nprint(status)\n</code></pre> <p>With that small snippet we have our status, and all we need to do is put that in a loop to set the background depending on the bit returned.</p> <pre><code>import board  \nfrom time import sleep  \nfrom adafruitpyportal import PyPortaltry:  \nfrom secrets import secrets * # noqa  \n\nexcept ImportError:  \n print(\"WiFi secrets are kept in secrets.py, please add them there!\")  \n\nraisepyportal = PyPortal(  \n url=secrets[\"signal\"],  \n defaultbg=\"green.bmp\"  \n)\n\ncurrent = 0\n\nwhile True:  \n status = int(pyportal.fetch())  \n if status == 0 and status == current:  \n     pass  \n elif status == 0 and status != current:  \n     pyportal.setbackground(\"green.bmp\")  \n current = 0  \n     elif status == 1 and status != current:  \n pyportal.setbackground(\"red.bmp\")  \n     current = 1  \n elif status == 1 and status == current:  \n     pass  \n sleep(30)\n</code></pre> <p>Even though it\u2019s a small snippet I want to point out a couple things. First I\u2019m wrapping the return from fetch in a cast to int. If you use Python, but you are new to CircuitPython this may seem odd. If you don't do this and try to compare a string to an int you're probably not going to get the result you expect. Try it out in a repl and then follow up with CircuitPython Essentials . Also I'm only changing the background if the status we fetch is different than the current status. While repainting the screen is fast, it's noticeable and there's no reason to do it every 30 seconds if nothing is different.</p> <p>That\u2019s it. Now whenever the endpoint receives an update the portal will see that status change and update the display.</p> <p></p> <p></p> <p>Thanks to Adafruit for publishing the case above. The logo on display is the Jolly Wrencher of Hackaday.</p> <p>With the endpoint and display done I\u2019m off into the unknown. I\u2019ll be setting up the ESP-EYE to update the endpoint, training the voice model and finally running it all with FreeRTOS.</p> <p>The code, docs, images etc for the project can be found here and I\u2019ll be posting updates as I continue along to HackadayIO and this blog. If you have any questions or ideas reach out.</p>"},{"location":"blog/2020/03/19/train-all-the-things--synthetic-generation/","title":"Train All the Things \u2014 Synthetic Generation","text":"<p>After getting the display and worker up and running I started down the path of training my model for keyword recognition. Right now I\u2019ve settled on the wake words Hi Smalltalk. After the wake word is detected the model will then detect silence, on, off, or unknown.</p> <p>My starting point for training the model was the microspeech and speechcommands tutorials that are part of the Tensorflow project. One of the first things I noticed while planning out this step was the lack of good wake words in the speech command dataset. There are many voice datasets available online, but many are unlabeled or conversational. Since digging didn't turn up much in the way of open labeled word datasets I decided to use on and off from the speech commands dataset since that gave me a baseline for comparison with my custom words. After recording myself saying hi and smalltalk less then ten times I knew I did not want to generate my own samples at the scale of the other labeled keywords.</p> <p>Instead of giving up on my wake word combination I started digging around for options and found an interesting project where somebody had started down the path of generating labeled words with text to speech. After reading through the repo I ended up using espeak and sox to generate my labeled dataset.</p> <p>The first step was to generate the phonemes for the wake words:</p> <pre><code>$ espeak -v en -X smalltalk  \n</code></pre> <p>then stored the phoneme in a word file that will be used by generate.sh.</p> <pre><code>$ cat words  \nhi 001 \nbusy 002 \nfree 003\nsmalltalk 004\n</code></pre> <p>After modifying generate.sh from the spoken command repo (eliminating some extra commands and extending the loop to generating more samples) I had everything I needed to synthetically generate a new labeled word dataset.</p> <pre><code>#!/bin/bash  \n# For the various loops the variable stored in the index variable  \n# is used to attenuate the voices being created from espeak.*lastwordid=\"\"cat words | while read word wordid phonemedo  \necho $word  \nmkdir -p db/$word \n\nif [[ $word != $lastword ]]; then  \n versionid=0  \n fi \n\nlastword=$word \n\n# Generate voices with various dialects  \nfor i in english english-north en-scottish englishrp englishwmids english-us en-westindies  \ndo  \n    # Loop changing the pitch in each iteration  \n    for k in $(seq 1 99); do  \n        # Change the speed of words per minute  \n        for j in 80 100 120 140 160; do  \n            echo $versionid \"$phoneme\" $i $j $k  \n            echo \"$phoneme\" | espeak -p $k -s $j -v $i -w db/$word/$versionid.wav  \n            # Set sox options for Tensorflow  \n            sox db/$word/$versionid.wav -b 16 --endian little db/$word/tf$versionid.wav rate 16k  \n            ((versionid++))  \n        done  \n     done  \ndone\n</code></pre> <p>After the run I have samples and labels with a volume comparable to the other words provided by Google. The pitch, speed and tone of voice changes with each loop which will hopefully provide enough variety to make this dataset useful in training. Even if this doesn\u2019t work out learning about espeak and sox was interesting. I've already got some future ideas on how to use those. If it does work the ability to generate training data on demand seems incredibly useful.</p> <p>Next up, training the model and loading to the ESP-EYE. The code, docs, images etc for the project can be found here and I\u2019ll be posting updates as I continue along to HackadayIO and this blog. If you have any questions or ideas reach out.</p>"},{"location":"blog/2020/03/24/train-all-the-things--model-training/","title":"Train All the Things \u2014 Model Training","text":"<p>Recently I spent some time learning how to generate synthetic voices using espeak. After working with the tools to aligning with the Tensorflow keyword models expectations I was ready for training, and to see how well the synthetic data performed. TLDR: not well :)</p> <p>I started by training using the keywords hi, smalltalk and on. This let me have a known working word while testing two synthetic words. Although training went well:</p> <pre><code>INFO:tensorflow:Saving to \"/Users/n0mn0m/projects/on-air/voice-assistant/train/model/speechcommandstrain/tinyconv.ckpt-18000\"  \nI0330 10:34:28.514455 4629171648 train.py:297] Saving to \"/Users/n0mn0m/projects/on-air/voice-assistant/train/model/speechcommandstrain/tinyconv.ckpt-18000\"  \nINFO:tensorflow:setsize=1445  \nI0330 10:34:28.570324 4629171648 train.py:301] setsize=1445  \nWARNING:tensorflow:Confusion Matrix:  \n [[231 3 3 0 4]  \n [ 2 178 6 29 26]  \n [ 3 12 146 2 2]  \n [ 4 17 2 352 21]  \n [ 2 16 7 16 361]]  \nW0330 10:34:32.116044 4629171648 train.py:320] Confusion Matrix:  \n [[231 3 3 0 4]  \n [ 2 178 6 29 26]  \n [ 3 12 146 2 2]  \n [ 4 17 2 352 21]  \n [ 2 16 7 16 361]]  \nWARNING:tensorflow:Final test accuracy = 87.8% (N=1445)  \nW0330 10:34:32.116887 4629171648 train.py:322] Final test accuracy = 87.8% (N=1445)The model didn\u2019t respond well once it was loaded onto the ESP-EYE. I tried a couple more rounds with other keywords and spectrogram samples with similar results.\n</code></pre> <p>Because of the brute force nature that I used to generate audio the synthetic training data isn\u2019t very representative of real human voices. While the experiment didn\u2019t work out, I do think that generating data this way could be useful with the right amount of time and research. Instead of scaling parameters in a loop I think researching the characteristic of various human voices and using those to tune the data generated via espeak could actually work out well. That said it\u2019s possible the model may pick up on characteristics of the espeak program too. Regardless, voice data that is ready for training is still a hard problem in need of more open solutions.</p> <p>Along with the way I scaled the espeak parameters another monkey wrench is that the microspeech model makes use of a CNN and spectrogram of the input audio instead of full signal processing. This means it\u2019s highly likely the model will work with voices around the comparison spectrogram well, but not generalize. This makes picking the right spectrogram relative to the user another key task.</p> <p>Because of these results and bigger issues I ended up tweaking my approach and used visual as my wake word followed by on/off. All of these are available in the TF command words dataset, and visual seems like an ok wake word when controlling a display. For somebody working on a generic voice assistant you will want to work on audio segmentation since many datasets are sentences, or consider using something like Skainet. All of this was less fun than running my own model from synthtetic data, but I needed to continue forward. After a final round of training with all three words I followed the TF docs to represent the model as a C array and then flashed it onto the board with the rest of the program. Using idf monitor I was able to observe the model working as expected:</p> <pre><code>I (31) boot: ESP-IDF v4.1  \nI (31) boot: compile time 13:35:43  \nI (704) wifi: config NVS flash: enabled  \nI (734) WIFI STATION: Setting WiFi configuration SSID Hallow...  \nI (824) WIFI STATION: wifiinitsta finished.  \nI (1014) TFLITEAUDIOPROVIDER: Audio Recording started  \nWaking up  \nRecognized on  \nI (20434) HTTPSHANDLING: HTTPS Status = 200, contentlength = 1  \nI (20434) HTTPSHANDLING: HTTPEVENTDISCONNECTED  \nI (20444) HTTPSHANDLING: HTTPEVENTDISCONNECTED  \nGoing back to sleep.  \nWaking up  \nRecognized off  \nI (45624) HTTPSHANDLING: HTTPS Status = 200, contentlength = 1  \nI (45624) HTTPSHANDLING: HTTPEVENTDISCONNECTED  \nI (45634) HTTPSHANDLING: HTTPEVENTDISCONNECTEDThis was an educational experiment. It helped me put some new tools in my belt while thinking further about the problem of voice and audio processing. I developed some [scripts](https://github.com/n0mn0m/on-air/tree/main/voice-assistant/train) to run through the full data generation, train and export cycle. Training will need to be done based on the architecture somebody is using, but hopefully it\u2019s useful.\n</code></pre> <p>The code, docs, images etc for the project can be found here and I\u2019ll be posting updates as I continue along to HackadayIO and this blog. If you have any questions or ideas reach out.</p>"},{"location":"blog/2020/03/28/train-all-the-things--version-01/","title":"Train All the Things \u2014 Version 0.1","text":"<p>My first commit to on-air shows March 3, 2020. I know that the weeks leading up to that commit I spent some time reading through the TF Lite documentation, playing with Cloudflare Workers K/V and getting my first setup of esp-idf squared away. After that it was off to the races. I outlined my original goal in the planning post. I didn't quite get to that goal. The project currently doesn't have a VAD to handle the scenario where I forget to activate the display before starting a call or hangout. Additionally I wasn't able to train a custom keyword as highlighted in the custom model post. I was however able to get a functional implementation of the concept. I am able to hang the display up, and then in my lab with the ESP-EYEplugged in I can use the wake word visual followed by on/off to toggle the display status.</p> <p></p> <p></p> <p>While it\u2019s not quite what I had planned it\u2019s a foundation. I\u2019ve got a lot more tools and knowledge under my belt. Round 2 will probably involved Skainet just due to the limitations in voice data that\u2019s readily available. Keep an eye out for a couple more post highlighting some bumps along the way and summary of lessons learned.</p> <p>The code, docs, images etc for the project can be found here and I\u2019ll be posting any further updates to HackadayIO. For anybody that might be interested in building this the instructions below provide a brief outline. Updated versions will be hosted in the repo. If you have any questions or ideas reach out.</p> <p>Required Hardware:</p> <ol> <li>ESP-EYE</li> <li>Optional ESP-EYE case</li> <li>PyPortal</li> <li>Optional PyPortal case</li> <li>Two 3.3v usb to outler adapters and two usb to usb mini cables</li> </ol> <p>OR</p> <ol> <li>Two 3.3v micro usb wall outlet chargers</li> </ol> <p>Build Steps:</p> <ol> <li>Clone the on-air repo.</li> </ol> <p>Cloudflare Worker:</p> <ol> <li>Setup Cloudflare DNS records for your domain and endpoint, or setup a    new domain with Cloudflare if you don\u2019t have one to resolve the    endpoint.</li> <li>Setup a Cloudflare workers account with worker K/V.</li> <li>Setup the Wrangler CLI tool.</li> <li>cd into the on-air/sighandler directory.</li> <li>Update toml</li> <li>Run wrangler preview</li> <li>wrangler publish</li> <li>Update Makefile with your domain and test calling.</li> </ol> <p>PyPortal:</p> <ol> <li>Setup CircuitPython 5.x on the PyPortal.</li> <li>If you\u2019re new to CircuitPython you    should read this first.</li> <li>Go to the directory where you cloned on-air.</li> <li>cd into display.</li> <li>Update secrets.py` with your wifi information and    status URL endpoint.</li> <li>Copy code.py, secrets.py and the bitmap files in screens/ to the root of the PyPortal.</li> <li>The display is now good to go.</li> </ol> <p>ESP-EYE:</p> <ol> <li>Setup esp-idf using the 4.1 release    branch.</li> <li>Install espeak and sox.</li> <li>Setup a Python 3.7 virtual environment and install Tensorflow 1.15.</li> <li>cd into on-air/voice-assistant/train</li> <li>chmod +x orchestrate.sh and ./orchestrate.sh</li> <li>Once training completes cd ../smalltalk</li> <li>Activate the esp-idf tooling so that $IDFPATH is set correctly and all requirements are met.</li> <li>idf.py menuconfig and set your wifi settings.</li> <li>Update the URL    in toggle\\status.cc</li> <li>This should match the host and endpoint you deployed the Cloudflare worker to above</li> <li>idf.py build</li> <li>idf.py --port \\&lt;device port&gt; flash monitor</li> <li>You should see the device start, attach to WiFi and begin listening for the wake word \u201cvisual\u201d followed by \u201con\u201d or     \u201coff\u201d.</li> </ol>"},{"location":"blog/2020/03/30/train-all-the-things--speed-bumps/","title":"Train All the Things \u2014 Speed Bumps","text":"<p>As part of getting started on my project a couple months back I took a look at what boards were supported byTensorflow lite . Seeing an esp board I went that route since I\u2019ve heard alot from the maker/hacker community and thought it would be a good opportunity to learn more. Additionally it\u2019s been quite a while since I had a project that was primarily C/C++ so that was exciting. Like any good project I ran into multiple unexpected bumps, bugs and issues. Some were minor, others were frustrating. I'm capturing some of those here for anybody else that may be starting down the path of using Tensorflow Lite and an ESP32 board.</p>"},{"location":"blog/2020/03/30/train-all-the-things--speed-bumps/#tensorflow-speed-bumps","title":"Tensorflow speed bumps","text":"<p>Getting started with TF Lite is easy enough, but something I noticed as I continued to work on the project is just how little things are designed specific to the platform. Instead the examples are setup with Arduino as a default, and then work is done to make that run on X target. In the case of the ESP-EYE this looks like packing everything into an Arduino compatible loop, and handling that in a single FreeRTOS task. I get the reason for this, but it's also a bit of a headache later on as it feels like an anti pattern when addin in new task and event handlers.</p> <p>Another bump you are likely to notice is that the TF Lite examples rely on functionality present in the TF 1.xbranch for training, but require TF &gt;= 2.2 for micro libs. Not the end of the world, but it means your going to manage multiple environts. If managing this using venv/virtualenv keep in mind you're going to need the esp-idf requirements in the 2.x environment, or just install in both as you may find yourself switching back and forth. In addition to python lib versions the examples note esp-idf 4.0, but you will want to use &gt; =4.0with this commit or you will run into compiler failures. I ended up using 4.1 eventually, but something to note.</p> <p>Finally interaction with the model feels flaky. It\u2019s an example so this kind of makes sense, but I found that while the word detected was pretty accurate the newcommand and some of the attributes of the keyword being provided by the model weren't matching my expectation/use. I ended up using the score value and monitoring the model to setup the conditionals for responding to commands in my application.</p> <p>Overall the examples are great to have, and walking you through the train, test and load cycle is really helpful. The main thing I wish I had known was that the TF Arduino path for ESP was pretty much the same as the ESP native path with regards to utility and functionality just using the esp-idf toolchain.</p>"},{"location":"blog/2020/03/30/train-all-the-things--speed-bumps/#esp-speed-bumps","title":"ESP speed bumps","text":"<p>From the ESP side of things the core idf tooling is nice. I like how open it is and how much I can understand the different pieces. This helped a few times when I ran into unexpected behavior. One thing to note is if you follow the documented path of cloning esp-idf you will want to consider how you manage the release branch you use and when you merge updates. Updates are not pushed into minor/bug fix branches instead they go into the release branch targeted on merge.</p> <p>Being new to the esp platform something I didn\u2019t know when I got started was that esp-idf 4.x released in February of 2020. Because of this alot of the documentation and examples such as ESP-WHO and esp-skainetare still based on 3.x which has a variety of differences and changes in things like the TCP/network stack. Because of this checking the version used in various docs, examples etc is (as usual) important. Since the TF examples reference version 4 that's where I started, but a lot of what's out there is based on v3.</p> <p>One other bump somebody may run into is struct initialization in a modern toolchain when calling the underlying esp C libraries from C++. I spent some time digging around after transitioning the http request example into the TF C++ commandresponder code and the compiler told me I was missing uninitialized struct fields and their order made them required.</p> <p>The example code:</p> <pre><code>esphttpclientconfigt config = {  \n .url = \"http://httpbin.org/get\",  \n .eventhandler = httpeventhandler,  \n .userdata = localresponsebuffer,  \n};  \nesphttpclienthandlet client = esphttpclientinit(&amp;config);  \nesperrt err = esphttpclientperform(client);\n</code></pre> <p>And how I had to do it in C++:</p> <pre><code>esphttpclientconfigt* config = (esphttpclientconfigt*)calloc(sizeof(esphttpclientconfigt), 1);  \nconfig-&gt;url = URL;  \nconfig-&gt;certpem = burningdaylightiorootcertpemstart;  \nconfig-&gt;eventhandler = httpeventhandler;esphttpclienthandlet client = esphttpclientinit(config);  \nesphttpclientsetmethod(client, HTTPMETHODPUT);  \nesperrt err = esphttpclientperform(client);\n</code></pre> <p>I had a similar issue with wifi and you can see the solution here.</p> <p>I really enjoyed my lite trip into idf. It's an interesting set of components and followed a workflow that I use and appreciate. I wrote a couple aliases that somebody might find useful:</p> <pre><code>alias adf=\"export ADFPATH=$HOME/projects/esp-adf\"  \nalias idf-refresh=\"rm -rf $HOME/projects/esp-idf &amp;&amp; git clone --recursive git@github.com:espressif/esp-idf.git $HOME/projects/esp-idf &amp;&amp; $HOME/projects/esp-idf/install.sh\"  \nalias idf=\". $HOME/projects/esp-idf/export.sh\"  \nalias idf3=\"pushd $HOME/projects/esp-idf &amp;&amp; git checkout release/v3.3 &amp;&amp; popd &amp;&amp; . $HOME/projects/esp-idf/export.sh\"  \nalias idf4x=\"pushd $HOME/projects/esp-idf &amp;&amp; git checkout release/v4.0 &amp;&amp; popd &amp;&amp; . $HOME/projects/esp-idf/export.sh\"  \nalias idf4=\"pushd $HOME/projects/esp-idf &amp;&amp; git checkout release/v4.1 &amp;&amp; popd &amp;&amp; . $HOME/projects/esp-idf/export.sh\"  \nalias idf-test=\"idf.py --port /dev/cu.SLABUSBtoUART flash monitor\"And I look forward to writing more about esp as I continue to use it in new projects.\n</code></pre> <p>Approaching the end of this project it\u2019s been a larger undertaking than I expected, but I\u2019ve learned a lot. It\u2019s definitely generated a few new project ideas. The code, docs, images etc for the project can be found here and I\u2019ll be posting updates as I continue along to HackadayIO and this blog. If you have any questions or ideas reach out.</p>"},{"location":"blog/2020/03/30/train-all-the-things--wrapping-up/","title":"Train All the Things \u2014 Wrapping Up","text":"<p>And now I\u2019m at v0.1 of the on-air project. I was able to achieve what I was hoping to along the way. I learned more about model development, tensorflow and esp. While this version has some distinct differences from what I outlined for the logic flow (keywords, VAD) it achieves the functional goal. The code, docs, images etc for the project can be found in this repo, and the project details live on HackadayIO. When I get back to this project and work on v1.x I'll make updates available to each.</p> <p> </p> <p>A couple thoughts having worked through this in the evening for a couple months:</p> <ul> <li>I really should have outlined the states that the esp program was going to cycle through, and then mapped those into   task on the FreeRTOS event loop. While the high level flow captures the external systems behavior the esp has the most   moving parts at the applications level, and is where most of the state is influenced.</li> <li>I want to spend some more time with C++ 14/17 understanding the gotchas of interfacing with C99. I ran into a few   different struct init issues and found a few ways to solve them. I\u2019m sure there is a good reason for different   solutions, but it\u2019s not something I\u2019ve spent a lot of time dealing with so I need to learn.</li> <li>While continuing to learn about esp-idf I want to look into some of the esp hal work too. I briefly explored esp-adf   and skainet while working through on-air. Both focus on a couple boards but seems to have functionality that would be   interesting for a variety of devices. Understanding the HAL and components better seems to be where to start.</li> <li>Data, specifically structured data is going to continue to be a large barrier for open models and for anybody to be   able to train a model for their own want/need. While sources like Kaggle, arvix, data.world and others have worked to   help this there\u2019s still a gulf between what I can get at home and what I can get at work. Additionally many open   datasets are numeric or text datasets while video, audio and other sources are still lacking.</li> <li>Document early, document often. Too many times I got so caught up in writing code, or just getting one more thing done   that by the time I did that getting myself to do a thorough write up of issues I experienced, interesting findings, or   even successful moments was difficult. I know that I put this off sometimes, and different parts of the project are   not as well documented, or details have been lost to the days in between.</li> <li>There\u2019s a lot of fun stuff left to explore here I can see why I\u2019ve heard a lot about esp and look forward to building   more.</li> </ul>"},{"location":"blog/2020/05/28/groupby-fun-with-sql-and-python/","title":"GroupBy Fun with SQL and Python","text":"<p>A few months ago I had the opportunity to collaborate with some Data Scientist porting PySpark queries to raw Python. One of the primary areas of concern was aggregation statements. These were seen as functionality that would be particularly troublesome to write in Python. As an example I was provided a Spark SQL query similar to this:</p> <pre><code>text = ocrdata.filter(col('lvl')==5).filter(f.length(f.trim(col'txt'))) &gt; 0).select(txtcols) \\  \n .withColumn('ctxt' casestd(col('txt'))) \\  \n .drop('txt') \\  \n .withColumn('tkpos', f.struct('wrdnm', 'ctxt')) \\  \n .groupBy(lncols) \\  \n .agg(f.sortarray(f.collectlist('tkpos')).alias('txtarray')) \\  \n .withColum('txtln', f.concatws(' ', col('txtarray.casestd'))) \\  \n .drop('txtarray')This query was transforming token data generated by Tesseract into lines. Beyond the aggregation operation there was also some concern that the operation may be ran against quite large datasets depending on how much [Tesseract](https://github.com/tesseract-ocr) output was being manipulated at once.\n</code></pre> <p>Outside of the raw functionality I was asked if the data could be structured to provide an interface with named columns in a style similar to SQL rather than having to reference positional data.</p> <p>All of this seemed fairly straightforward. Provided with some sample data I pulled in the UDF that was already in Python and set out to apply the transformations first illustrating how we could interact with the data in a way similar to SQL with pipeline transformations and named references.</p>"},{"location":"blog/2020/05/28/groupby-fun-with-sql-and-python/#porting-transformations","title":"Porting Transformations","text":"<pre><code>import itertoolsfrom csv import DictReader  \nfrom collections import namedtupledef casestd(x):  \n if x.isupper():  \n return x.title()  \n elif not x.islower() and not x.isupper():  \n return x.title()  \n else:  \n return xwith open(\"sampledata/export.csv\") as sample:  \n reader = DictReader(sample)  \n data = [row for row in reader]a = filter(lambda x: int(x[\"level\"]) == 5, data)  \nfiltered = filter(lambda x: len(x[\"text\"].strip()) &gt; 0, a)  \nfixed = ({**row, 'text':casestd(row[\"text\"])} for row in filtered)tkpos = namedtuple(\"tkpos\", \"wordnum, text\")  \nresult = (dict(row, **{\"tkpos\":tkpos(row[\"wrdnum\"], row[\"text\"])}) for row in fixed)To start I read the data in with a [DictReader](https://docs.python.org/3.7/library/csv.html#csv.DictReader) which allowed me to reference values by name like \u201clevel\u201d and \u201ctext\u201d. I then applied similar data transformations making use of [filter](https://docs.python.org/3.7/library/functions.html#filter), [comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions), and [unpacking](https://docs.python.org/3/reference/expressions.html) to try and keep a style similar to some PySpark operations.\n</code></pre> <p>Finally I put the rest of the transformations into a generator expression containing a dict of namedtuplevalues so that later operations could continue working on named values in a manner similar to SQL columns.</p>"},{"location":"blog/2020/05/28/groupby-fun-with-sql-and-python/#groupby","title":"GROUPBY","text":"<p>With the transformation and named values part out of the way I moved onto the GROUPBY aggregations. Thinking about GROUPBY the goal is to apply an aggregation function to a unique value. That unique value can be represented multiple ways, but I wanted to show the idea behind what was happening to help with future port efforts. So on my first pass I wrote:</p> <pre><code>grouped = []  \nseen = set()*# Order is known because it represents data generated by tesseract  \n*for row in fixed:  \n key = (row[\"pagenum\"], row[\"blocknum\"], row[\"parnum\"], row[\"linenum\"]) if key in seen:  \n continue seen.add(key) line = [] for r in fixed:  \n rkey = (r[\"pagenum', r[\"blocknum\"], r[\"parnum\"], r[\"linenum\"])  \n if key == rkey:  \n line.append(r[\"ctxt\"]) txt = \" \".join(line)  \n cleantxt = txt.strip() if cleantxt:  \n grouped.append(  \n {  \n \"pagenum\": row[\"pagenum\"],  \n \"blocknum\": row[\"blocknum\"],  \n \"parnum\": row[\"parnum\"],  \n \"lnnum\": row[\"linenum\"],  \n \"text\": cleantxt,  \n }  \n )\n</code></pre> <p>Keeping in mind that this was to conceptualize what could be happening behind the scenes for the GROUPBYand AGG operation here we loop over our rows generating a hash from some values. Once we have this hash we check if we have seen it before by referencing a set. If this is a new value we find all values of the hash in our transformed data, append the tokens, handle empty tokens and finally add the data to our final dataset. At the end we have lines of text (instead of individual tokens) that can be referenced by page, block, paragraph and line number.</p> <p>While this works it\u2019s horribly inefficient. It stands out that we are reiterating our transformed data every time we find a new key. But the goal for this wasn\u2019t to be efficient. It was to show the ideas expressed in SQL with Python. Specifically it was highlighting how to express a GROUPBY/AGG operation manually using hashes of values and tracking what we have and have not seen providing a final dataset that was the same as the output of the SQL statement.</p>"},{"location":"blog/2020/05/28/groupby-fun-with-sql-and-python/#itertools","title":"itertools","text":"<p>Continuing on from that point one of my favorite Python modules is itertools. If you haven't spent much time with it I highly recommend taking some of your existing code and looking over it while scanning the itertools docs. I've used islice, chain and ziplongest innumberable times. Because of that I knew there was a handy groupby function stowed in there too:</p> <p>Make an iterator that returns consecutive keys and groups from the iterable. The key is a function computing a key value for each element. If not specified or is None, key defaults to an identity function and returns the element unchanged.Generally, the iterable needs to already be sorted on the same key function.Replacing the block above:</p> <pre><code>final = []for key, group in itertools.groupby(  \n req, key=lambda x: (x[\"pagenum\"], x[\"blocknum\"], x[\"parnum\"], x[\"linenum\"])  \n):  \n line = \"\".join([row['text'] + \" \" for row in group])  \n final.append({\"pagenum\": key[0],  \n \"blocknum\": key[1],  \n \"parnum\": key[2],  \n \"linenum\": key[3],  \n \"text\": line,  \n })And with that change we have a clean, faster implementation. Additionally since this was a port of Spark SQL if the data was to get truly large it wouldn\u2019t be much work to start iterating through all of the pipeline in batches since we can use generators all the way through.\n</code></pre>"},{"location":"blog/2020/05/28/groupby-fun-with-sql-and-python/#conclusion","title":"Conclusion","text":"<p>So what was the point of sharing that here? Nothing specific. It was a fun exercise at the time, and it made me pause to consider how I would express GROUPBY on my own. The exercise also helped introduce some of my colleagues to the filter expression and in turn map and reduce. Using those they were able to express a lot of their pipeline concepts without a lot of the iteration structures they were used to having abstracted away. If you find yourself doing a lot of pipelining I recommend checking out itertools and functools. Both are built into the Python stdlib and provide a lot of helpful functionality.</p>"},{"location":"blog/2020/10/11/getting-started-with-resharper-global-tools/","title":"Getting started with Resharper Global Tools","text":"<p>For a while now I\u2019ve been interested in build tools, CI and code quality. I think I got a taste for it as a member of the PyMSSQL project and it has continued on from there. Recently I worked on the initial CI setup for a C# project. As part of the setup I took the time to look at what lint and analysis tools we wanted to integrate into our project.</p> <p>For C# some of the more common tools appear to be:</p> <ul> <li>Roslyn Analyzers</li> <li>Sonarsource</li> <li>NDepend</li> <li> <p>Jetbrains Resharper   I won\u2019t go into the full criteria for our choice of Resharper (I\u2019ll update this post if I end up writing that up one   day), instead I\u2019ll summarize that Resharper provided:</p> </li> <li> <p>easy cross platform setup</p> </li> <li>ide/editor and shell agnostic</li> <li>works the same locally and in CI.</li> <li>opinionated by default</li> </ul>"},{"location":"blog/2020/10/11/getting-started-with-resharper-global-tools/#resharper-command-line-tools","title":"Resharper Command Line Tools","text":"<p>From the docs</p> <p>ReSharper Command Line Tools is a set of free cross-platform standalone tools that help you integrate automatic code quality procedures into your CI, version control, or any other server.You can also run coverage analysis from the command line.The Command Line Tools package includes the following tools:- InspectCode, which executes hundreds of ReSharper code inspections</p> <ul> <li>dupFinder, which detects duplicated code in the whole solution or narrower   scope</li> <li>CleanupCode, which instantly eliminates code style violations and ensures a   uniform code base### Install</li> </ul> <p>To get started with Resharper tools (assuming you already have .NET Core installed) run</p> <pre><code>cd &lt;project&gt;\ndotnet new tool-manifest\ndotnet tool install JetBrains.ReSharper.GlobalTools --version 2020.2.4Which installs the [Resharper Global Tools](https://www.nuget.org/packages/JetBrains.ReSharper.GlobalTools/2020.2.4) at the project level. This then allows CI and other contributors to use dotnet tool restore in the future.\n</code></pre>"},{"location":"blog/2020/10/11/getting-started-with-resharper-global-tools/#configuration","title":"Configuration","text":"<p>Out of the box inspect, format, and dupefinder all have default configurations that work well. That said each team has their own needs and preferences you may want these tools to promote. While there are a few ways to configure these tools I found using editorconfig to be the most human readable approach.</p> <p>For additional details on the editorconfig format see the docs and this property index.</p>"},{"location":"blog/2020/10/11/getting-started-with-resharper-global-tools/#running","title":"Running","text":"<p>Running the tools from a shell is relatively easy:</p> <pre><code>jb cleanupcode --verbosity=ERROR --config=./.config/cleanup --settings=./.editorconfig --no-buildin-settings ./Project.sln\njb inspectcode --verbosity=ERROR Project.sln -o=./reports/resharperInspect.xml\njb dupfinder --verbosity=ERROR Project..sln -o=./reports/resharperDupFinder.xmlOne thing to note is that by default the autoformatting will attempt to enforce line endings. If you have a team working across multiple platforms and using git to automatically handle line endings these can come into conflict. It's up to you and your team to decide if you want to handle this by tweaking git behavior,editorconfig or another method.\n</code></pre>"},{"location":"blog/2020/10/11/getting-started-with-resharper-global-tools/#ci","title":"CI","text":"<p>If your using Team City see this doc for details.</p> <p>With everything running in our shell locally we can also set things up to run in our CI pipeline. Running the tools is easy as long as your CI platform has a shell like task/step/operator:</p> <pre><code>- script: |  \n  dotnet tool restore  \n  jb cleanupcode --verbosity=ERROR --config=./.config/cleanup --settings=./.editorconfig --no-buildin-settings ./Project.sln  \n  jb inspectcode --verbosity=ERROR Project.sln -o=./reports/resharperInspect.xml  \n  jb dupfinder --verbosity=ERROR Project..sln -o=./reports/resharperDupFinder.xml  \n  displayName: 'Resharper'\n</code></pre> <p>Of course you will probably break these up for easier maintenance and reporting.</p> <p>Running the tools is easy. The trick is detecting when these tools find an issue. I\u2019ll share what I did in case it\u2019s helpful, but long term it would be great if Jetbrains had the tools exit with documented status codes for different issues. As it stands the tools only exit with an error if the tool fails, not when issues are reported.</p>"},{"location":"blog/2020/10/11/getting-started-with-resharper-global-tools/#cleanupcode","title":"CleanupCode","text":"<p>Since CleanupCode will format our file rewriting it on disk we can use git to detect the change.</p> <pre><code>formatted=$(git status --porcelain=v1 2&gt;/dev/null | wc -l)  \nexit $formatted\n</code></pre>"},{"location":"blog/2020/10/11/getting-started-with-resharper-global-tools/#dupfinder","title":"dupFinder","text":"<p>dupFinder outputs an XML file highlighting any issues found. Powershell's built in XML support makes it easy enough to query this file and see if any issues exist.</p> <pre><code>$Result = Select-Xml -Path $(System.DefaultWorkingDirectory)/reports/resharperDupFinder.xml -XPath \"/DuplicatesReport/Duplicates/*\"\nIf ($Result -eq $null) { [Environment]::Exit(0) } Else { [Environment]::Exit(1) }### InspectCode\n</code></pre> <p>Similar to dupFinder InspectCode documents issues with an XML file, and once again we can use Powershell to detect if there are any issues to fix.</p> <pre><code>$Result = Select-Xml -Path $(System.DefaultWorkingDirectory)/reports/resharperInspect.xml -XPath \"/Report/Issues/Project/*\"\nIf ($Result -eq $null) { [Environment]::Exit(0) } Else { [Environment]::Exit(1) }And since dupFinder and InspectCode output XML it can be useful to save these as CI artifacts for review. In Azure Pipelines this looks like:\n</code></pre> <p><code>yaml - task: PublishPipelineArtifact@1     inputs:     targetPath: '$(System.DefaultWorkingDirectory)/reports/'     artifactName: 'measurements'     condition: always()     displayName: 'Save ReSharper Results For Review.'### Wrapping Up</code></p> <p>We\u2019ve been using the ReSharper tools for a few months now and I have to say they provided what I was looking for in the beginning. The tools have been easy to use, help us maintain our code and haven\u2019t boxed us in or required a lot of extra time on configuration and unseen gotchas. The only criticism I have is cold start time is pretty slow for cleanupcode, and the return exit codes could be better. Both of these would also help with CI, and our git hook setup. Otherwise I think these will continue to serve us well and let us focus on our project delivery.</p>"},{"location":"blog/2020/10/18/roll-your-own-git-hook/","title":"Roll your own git hook","text":"<p>As part of setting up tools to run in our CI pipeline I also setup a git pre-pushhook to run the same tools automatically in the local context. Git provides a variety of hooks as documented in the scm book, and they can be used to reliably automate different parts of your workflow.</p> <p>In addition to the official docs this page has a nice summary</p>"},{"location":"blog/2020/10/18/roll-your-own-git-hook/#code","title":"Code","text":"<p>The pre-push hook I built for our project looks like:</p> <pre><code>#!/bin/sh\nPROJECTROOT=$(git rev-parse --show-toplevel)  \necho \"Running pre-push hook for${PROJECTROOT}\"\ndotnet restore $PROJECTROOTecho \"Running resharper formatter\"  \ndotnet jb cleanupcode --verbosity=ERROR --config=$PROJECTROOT/.config/cleanup --settings=$PROJECTROOT/.editorconfig --no-buildin-settings $PROJECTROOT/AMS.sln\nformatted=$(git status --porcelain=v1 2&gt;/dev/null | wc -l)  \n\n$formatted\necho \"Running dotnet resharper inspector\"  \ndotnet jb inspectcode --verbosity=ERROR AMS.sln -p=$PROJECTROOT/.editorconfig -o=$PROJECTROOT/reports/resharperInspect.xmlpwsh $PROJECTROOT/tools/CheckResharperInspection.ps1  \n\nif [[ $? -eq 0 ]]  \nthen  \n echo \"Running resharper dupe finder\"  \nelse  \n echo \"Inspector Errors Found\"  \n exit $?  \nfi\n\ndotnet jb dupfinder --verbosity=ERROR AMS.sln -o=$PROJECTROOT/reports/resharperDupFinder.xmlpwsh $PROJECTROOT/tools/CheckDupeFinder.ps1  \n\nif [[ $? -eq 0 ]]  \nthen  \n echo \"Running dotnet test\"  \nelse  \n echo \"Dupe Errors Found\"  \n exit $?  \nfi\n\ndotnet cake --target=docker-bg  \ndotnet cake --target=dotnet-test  \n\nif [[ $? -eq 0 ]]  \nthen  \n dotnet cake --target=docker-down  \n echo \"Go go go!\"  \nelse  \n dotnet cake --target=docker-down  \n echo \"Test failed\"  \n exit 1  \nfi\n</code></pre> <p>The first thing that should stand out is that this is just a shell script. Git hooks are just that, making it easy to use shell, python, powershell or other tools with your hook. Write the script, link it to .git/hooks.</p>"},{"location":"blog/2020/10/18/roll-your-own-git-hook/#script-breakdown","title":"Script Breakdown","text":"<p>In this script the first thing I do is find the root of our project. This makes it easy to reference paths in a manner compatible with scripts and tools that are used throughout in other parts of our workflow.</p>"},{"location":"blog/2020/10/18/roll-your-own-git-hook/#install","title":"Install","text":"<p>Since the hook above is just a shell script I like to keep it (and other hooks) in a tools subdirectory in the root project directory. Because git expects hooks to be under .git/hooks we can make it executable with a symlink.</p> <pre><code>ln -s -f ../../tools/pre-push.sh .git/hooks/pre-pushWith this in place we get feedback before each push so that we don\u2019t have to correct linting issues later, and we have can be confident our commit(s) will run through CI successfully.\n</code></pre>"},{"location":"blog/2020/10/18/roll-your-own-git-hook/#wrapping-up","title":"Wrapping Up","text":"<p>While you may have heard of projects like pre-commit or husky rolling your own hook is relatively straight forward. While wrappers may help with complex hook setups I personally like the low amount of indirection and abstraction that helps with debugging when rolling your own.</p>"},{"location":"blog/2020/11/21/self-hosting/","title":"Self Hosting","text":"<p>Over the last few years I built up a sprawling list of dependencies for my home project and blog workflow. Earlier this year I decided it was time to cut down on that list and host my service dependencies locally where I could. While it took me a while I reached a point where I no longer tweak the setup week to week and decided it was time to write up the process.</p> <p>A quick list of the tools I used for orchestration:</p> <ul> <li>shell</li> <li>DNS</li> <li>Traefik2</li> <li>docker/docker-compose</li> <li>alpine linux</li> </ul>"},{"location":"blog/2020/11/21/self-hosting/#ddns","title":"(D)DNS","text":"<p>The first thing I needed to do was make my services easy to reach local and remote. Since this is all running behind my home router that also means that my IP can change from time to time. To handle this I made use of Gandi\u2019s DNS API, and setup a shell script to run with cron on my router to keep my DNS records up to date. With DNS ready I moved on to Traefik.</p>"},{"location":"blog/2020/11/21/self-hosting/#traefik","title":"Traefik","text":"<p>Traefik is a really nice routing/proxy service that can inspect container labels and setup route forwarding while handling certificate management, traffic metrics and more. The main callout (other than what you will find in the docs ) is to keep an eye on what version you are using versus what others used in examples, and that non http based traffic (for instance ssh) requires a little more setup. Beyond that Traefik has been really nice to use and made adding/removing various services easy when coupled with docker.</p>"},{"location":"blog/2020/11/21/self-hosting/#docker-compose","title":"docker-compose","text":"<p>While k8s is the current hot orchestration tool I wanted to keep things simple. I don\u2019t have a need to cluster any of my home tools, and while distributed systems are interesting they also require a lot of work. I left those at my day job and use compose + duplicity for my home setup. This makes service management easy, the labels allow traefik to detect and handle traffic management while my duplicty ensures I won\u2019t lose much work and can quickly restore my data and restart any services in a few minutes on any box with docker.</p>"},{"location":"blog/2020/11/21/self-hosting/#services","title":"Services","text":"<p>A quick list of the services I\u2019m hosting:</p> <ul> <li>git</li> <li>cgit</li> <li>minio</li> <li>teamcity</li> <li>youtrack</li> <li>rust home services API</li> </ul> <p>The service management can be found here.</p>"},{"location":"blog/2020/11/21/self-hosting/#wrap-up","title":"Wrap Up","text":"<p>I\u2019ve started to self host a few times in the past and backed away. This time I think it\u2019s here to stay. With my current setup I\u2019m not worried about what happens when something crashes, certificate management is automated away and everything just works. I\u2019ve linked to my orchestration code above, but if you have any questions, or suggestions send them my way. If you are starting out on your own self hosted setup, good luck, have fun it\u2019s easier now than ever and I imagine it will continue to get better.</p>"},{"location":"blog/2020/12/28/use-data-structures-for-your-business-logic/","title":"Use data structures for your business logic","text":"<p>A few months ago I was reviewing a PR that handled relationships between entities. As I was working through the code I started to notice a pattern that made me go back to the original feature ticket for a quick review of the acceptance criteria. As I suspected there was a list of around 10 \u201cif this then that\u201d scenarios detailed, all of which manifested as conditions in the code. Grabbing a pen and paper I started to draw out the criteria and as I suspected all the scenarios were captured by relationships and operations for a Tree.</p> <p>Going back with this information I paired with the team on an update to the PR where we reduced the amount of conditions tied directly to the business domain, and refactored names so that future maintainers could interact with the code understanding a tree, but maybe not understanding all the business logic around the entities.</p> <p>in case it\u2019s helpful the C5 project has some collections not found in the .NET Standard library for interacting with Trees. In general an interesting project I\u2019m glad I learned about.A similar opportunity emerged on the same project when we needed to make sure a value was unique over a series of operations. In this scenario while working on a collection of objects we were able to use a HashSetto exit if Add returned false instead of setting up a LINQ query. This resulted in less nesting, less code, and a simplified condition.</p>"},{"location":"blog/2020/12/28/use-data-structures-for-your-business-logic/#the-point","title":"The Point","text":"<p>The reason I am writing this is that we should be using data structures to represent the business logic of our applications. This seems obvious, but too often I have seen implementations brute force conditions leaving data structures as an optimization, or a concern for \u201ctechnical\u201d projects. While we can use a series of conditions and predicates to meet requirements in a crude way, using data structures provides an abstraction that can elevate terse business logic to a construct future maintainers can derive extra meaning from.</p>"},{"location":"blog/2021/01/05/org-templates-and-checklist/","title":"Org templates and checklist","text":"<p>Last year I read the \u201cThe Checklist Manifesto\u201d about the outsized impact a checklist can have on an individual and teams.</p> <p>I also started using org-mode to keep a daily journal of what I'm working on, design notes, todos etc. Having spent a few weeks with org-journal I decided it was time to create my own templates. For my first template a checklist seemed like an easy target. I made a few like PR Review, and New Service which can be found in my dotfiles along with their bindings.</p> <p>True to the goal, I\u2019ve got a lot more consistent in my reviews and with capturing review artifacts. The service checklist has been turned into a dotnet template that saves even more time.</p> <p>Yay checklist!</p>"},{"location":"blog/2021/01/14/reading-highlights-from-q4-2020/","title":"Reading highlights from Q4 2020","text":"<p>I read a lot of books this year, but rarely write anything up after finishing them. While I don\u2019t think I have enough to say about any one book after my first read, I want to capture a sentence or two about them to look back on, and to share with others. If I mention a book here that you want to talk about send me a message.</p>"},{"location":"blog/2021/01/14/reading-highlights-from-q4-2020/#q4-2020-list","title":"Q4 2020 List","text":"<p>Zen and the Art of Motorcycle Maintenance</p> <ul> <li>I\u2019ve been really interested in the idea of quality and how we achieve it in what we build. Everybody uses a different   definition of \u201cgood\u201d, and I enjoyed the exploration of the topic in this book.</li> </ul> <p>Blockchain Chicken Farm</p> <ul> <li>Having grown up in rural kentucky and working in industrial chicken farming, then pivoting to writing software after   high school this was a fantastic read. A lot to reflect on, the shared humanity, and the audacity of the software   industry shined beginning to end.</li> </ul> <p>Subprime Attention Crisis</p> <ul> <li>A good exploration of the dangers in the ad based internet economy. While the ad industry has made a lot of tools   available to those who couldn\u2019t afford them outright, I think we can do better than the current ad economy. While   shrinking sectors can hurt, I think we need to be careful not to accidentally lead individuals to believe we need to   maintain the ad economy at the invasive scale we are at today.</li> </ul> <p>Understanding Computation</p> <ul> <li>As advertised. Computational theory using Ruby. I enjoyed the read and will probably revisit Part II sometime. It is a   big book covering a wide range of topics and I don\u2019t think I internalized Part II enough.</li> </ul> <p>The Hardware Hacker</p> <ul> <li>A collection of articles from \u201cbunnie\u201d relaying his experience and some philosophies while manufacturing in the open.   The term shanzhai has popped up here and in other reading over the last few   years.</li> </ul> <p>Angular Development with Typescript, Second Edition</p> <ul> <li>What it sounds like. Reading this for work, and it was helpful as I got going with Angular.</li> </ul> <p>Programming Typescript</p> <ul> <li>What it sounds like. A good read after going through the docs at typescriptlang.org.</li> </ul> <p>Vader Down</p> <ul> <li>Vader being Vader. Fun short read.</li> </ul> <p>Shadowfall</p> <ul> <li>This popped up as new at the library, and I was a few chapters in when I realized I had missed the first book in a   series. So far I like it. It\u2019s in the same vein as rogue squadron, and the author is working to write characters in a   complicated environment. Curious to see how the series wraps up and if the character arcs land.</li> </ul>"},{"location":"blog/2021/02/01/the-joy-of-repair/","title":"The joy of repair","text":"<p>A few weeks ago the Z Upper Right Assembly broke on my Mini 2. At first, I wasn\u2019t quite sure what was wrong I only knew that the tool head couldn\u2019t raise on the right-hand side. In an email to Adrian (at Lulzbot) we figured out the part had a hairline crack. In a year without covid I could have gone down to LVL1 to make a replacement part, but not this year. Luckily Lulzbot was easy to get a print from, and really fast too (kudos to them, and that\u2019s nice to know for the future).</p> <p>With this being my first repair I was a bit nervous. I had never taken my mini apart or tinkered too much instead opting for that with my prints. The good news is Lulzbot has amazing documentation for each printer that make repairs relatively straight forward. Beginning to end taking things apart and getting them back together per the doc took me an hour, and then it was go time. My first print was rocktopus which came out great. Seeing the right-hand axis work as expected was a huge relief, and gives me some confidence that I could do more for in the realm of mods and repairs in the future.</p> <p>Why does this matter? Because if you can\u2019t fix it, you don\u2019t own it, and I was blown away how easy it was to fix my Lulzbot. On top of that it was fun. Outside of gardening I don\u2019t have the opportunity to just fix stuff with my hands that much, and I miss that. Something to look into this year maybe?</p>"},{"location":"blog/2021/02/10/setting-up-a-ci-pipeline-for-rust-in-teamcity/","title":"Setting up a CI pipeline for Rust in Teamcity","text":"<p>Towards the end of last year I started working on a project in rust that would listen to a message queue and send an email. Additionally it used rocket to expose some diagnostic endpoints to check on the health of the service, change log levels, etc. When starting new projects I default to setting up a build pipeline for them to. For this project I setup pipelines in teamcity which was overall pretty easy, but sharing here for anybody else that may go down this path.</p>"},{"location":"blog/2021/02/10/setting-up-a-ci-pipeline-for-rust-in-teamcity/#cargo-make","title":"cargo-make","text":"<p>For new projects I like to capture the build, admin and CI steps in a way that makes it convenient for others to run on their local machine. Make and it\u2019s derivatives (cmake, cake, etc) provide a useful task abstraction and Rust has the powerful cargo-make project that lets us capture task and mix together inline simple commands with scripts, dependencies etc.</p> <p>For this project you can find my cargo make file here. I also experimented with using Powershell for my scripts/wrappers. I\u2019ve been using this in my day job where our projects run on Win, macOS and Linux. Overall I\u2019m pretty happy with the experience, but it is another tool to install and maintain along with various platforms missing support.</p>"},{"location":"blog/2021/02/10/setting-up-a-ci-pipeline-for-rust-in-teamcity/#cargo-test","title":"cargo test","text":"<p>Rust comes with a build tool and test runner built in via cargo. Running test is easy out of the box, but I needed to make use of a couple tools to get the cargo test output into a format that a CI tool parses. I ended getting test and coverage data in the junit and lcov formats that way various tools and platforms can be used across time and projects.</p> <ul> <li>grcov</li> <li>cargo2junit</li> </ul>"},{"location":"blog/2021/02/10/setting-up-a-ci-pipeline-for-rust-in-teamcity/#teamcity","title":"Teamcity","text":"<p>With those tools orchestrated via cargo make it's time to setup the build and test steps in Teamcity. Overall the process was pretty easy, but I ran into a couple bumps I'll highlight.</p> <ul> <li>The cargo step doesn't support custom commands, so I don't use that by default</li> <li>I wrote CI.ps1 as a wrapper to use in   each step.</li> <li>Enable the xml-report-plugin   And with those two things the pipeline is ready   to go. From there you may want to add your own environment variables, plugin,   agent deps etc.</li> </ul>"},{"location":"blog/2021/02/10/setting-up-a-ci-pipeline-for-rust-in-teamcity/#next-steps","title":"Next steps","text":"<p>With this pipeline up an running the next steps are:</p> <ul> <li>Setup build caching with something like sccache</li> <li>Work on local and CI build times</li> <li>This has been written about   a number   of times   I would need to make both of these better before taking the project further. As the project grows these would only get   worse, and make the project unpleasant for others to work on.</li> </ul>"},{"location":"blog/2021/02/10/setting-up-a-ci-pipeline-for-rust-in-teamcity/#done","title":"Done","text":"<p>That\u2019s it for now. I learned a lot along the way about Rust, cargo, and hooking it up with Teamcity. I\u2019m not sure I\u2019ll have a write up on artemis anytime soon. It was a good project, but I ultimately took another path. Hopefully this helps somebody, and as always feel free to reach out.</p>"},{"location":"blog/2021/03/23/finding-good-defaults/","title":"Finding good defaults","text":"<p>At heart many of us are tinkerers. We like to take things apart and see how they work. We enjoy spending hours customizing our tools, scripts and applications. But all of this adds up. It means that our tool works different from all the others. For somebody else coming behind us it may mean piecing together all the flags and tweaks no matter how well we documented or versioned tweaks in our repo, time will bring a divergence between the system and the repo.</p> <p>A lot of this has set in for me over the years teaching programming, speaking with family about their devices, and onboarding to new code bases as I change teams.</p> <p>I want to try out something new over the next few years, and that is finding good defaults. If I feel the need to tweak/change a tool out of the box, I\u2019ll try other options. I have some theories around this.</p> <ul> <li>Good defaults save us time</li> <li>Don\u2019t require extra conversations for team consensus</li> <li>Help manage complexity</li> <li>Build on expertise</li> <li>Teach us to expect good defaults, and to build our software with good defaults</li> <li>Good defaults help others join in</li> </ul> <p>Against this list I also believe there is a counter culture around defaults wrapped up in programmer/hacker/software engineer reputation that drives us to distrust or question anything we haven\u2019t pulled apart and customized. This creates an extra challenge.</p> <p>I know that each domains \u201cgood defaults\u201d will be different, but that doesn\u2019t mean they don\u2019t exist. My hypothesis is that they can save us time, help us build what matters, and help those who are join in, or come after. Lets find out.</p>"},{"location":"blog/2021/03/25/entropy/","title":"Entropy","text":""},{"location":"blog/2021/03/25/entropy/#noun-entropy-plural-noun-entropies-symbol-s","title":"noun: entropy; plural noun: entropies; symbol: S","text":"<ol> <li>a thermodynamic quantity representing the unavailability of a system\u2019s thermal energy for conversion into mechanical    work, often interpreted as the degree of disorder or randomness in the system. \u201cthe second law of thermodynamics says    that entropy always increases with time\u201d</li> <li>lack of order or predictability; gradual decline into disorder. \u201ca marketplace where entropy reigns supreme\u201d</li> <li>(in information theory) a logarithmic measure of the rate of transfer of information in a particular message or    language.</li> </ol> <p>Everything we build and learn requires constant maintenance and labor.</p>"},{"location":"blog/2021/03/29/reading-highlights-from-q1-2021/","title":"Reading Highlights from Q1 2021","text":"<p>I read a lot of books throughout the year, but rarely write anything up after finishing them. While I don\u2019t think I have enough to say about any one book after my first read, I want to capture a sentence or two about them to look back on, and to share with others. If I mention a book here that you want to talk about send me a message.</p>"},{"location":"blog/2021/03/29/reading-highlights-from-q1-2021/#q1-2021-list","title":"Q1 2021 List","text":"<ul> <li>A Philosophy of Software Design \u2014 a good read that will impact how you think about writing your code. Many of these   ideas have permeated out into general software culture (I think, maybe I\u2019m in a bubble), but I would recommend this.</li> <li>Why we make things and why it matters \u2014 an interesting read on crafts and why we should embrace them.</li> <li>Humankind \u2014 good, but long at many points</li> <li>Kubernetes Getting Started \u2014 as advertised</li> <li>The Unix Administrators Handbook \u2014 I had a former manager recommend this book to me. I\u2019ve read it through twice now   and I always learn something new.</li> <li>Fluent Python 2nd Edition \u2014 A really good book on Python exploring areas that are not always tread, and Luciano does a   great job of answering \u201cwhy\u201d as he goes.</li> <li>Django Crash Course \u2014 as advertised, a good alternative or secondary first Django tutorial.</li> <li>A Scoop of Django \u2014 A good read. I don\u2019t feel like the answer of why is always explained to the level I would like.   It\u2019s hit and miss, sometimes it is, sometimes there is a link to a blog that I may get around to reading one day. A   good book none the less.</li> <li>How to Invent Everything \u2014 probably my favorite book so far this year. This is a lot of fun and I look forward to   reading it with my daughter one day.</li> <li>Think Julia \u2014 I\u2019ve heard a bit about Julia and decided to check this out. A pretty good book revisiting a lot of   programming first principles in the context of learning them with Julia.</li> <li>Math for Programmers \u2014 I really enjoyed this. I try to keep math as a regular reading topic, and I like it when math   is demonstrated via programming.</li> </ul>"},{"location":"blog/2021/04/02/an-interlude/","title":"An Interlude","text":"<p>I started collecting notes here almost 3 years ago at my first PyCon. I had been working in Python for 3 years at that point and wanted to share some notes with anybody that might find them useful.</p> <p>Since then I\u2019ve veered into building a homelab, C#, rust, infrastructure, gardening and all kinds of other fun experiences.</p> <p>More importantly my daughter was born, and is turning 3 this year. Over 2020 I became more and more aware of what I spent time on, and started to evaluate if I wanted to keep spending time on these activities. Many things have fallen to the cutting room floor, and writing up a post each month is one of those. I still do a lot of writing for work, and maybe if something from there manifest itself as a good topic I\u2019ll share it, but I am not going to make myself sit down each month as I have in the past.</p> <p>I do plan to have short journal snippets I capture each day that I will link to here eventually. Many of them will be software related as that\u2019s what I spend so much time on each day, but all of them won\u2019t be.</p> <p>So yeah, hopefully the notes here have helped somebody. They will stay up, but I need to give myself permission to let this sit while I spend time elsewhere, maybe to return one day :)</p> <p>As always if you read something interesting, or find a code snippet that could use expounding send me a message.</p> <p>Till the next post surfaces \ud83d\udc4b</p>"},{"location":"blog/2022/01/22/novel-interactions/","title":"Novel Interactions","text":"<p>I started my career as a software engineer working on a lot of data visualization projects. After a couple years I switched to working primarily on backend services, and then after doing that for almost 8 years I had the opportunity to start working on frontend projects again. Since switching back I pay more attention to my digital experiences and notices the ones that surprise me or stand out. I wanted to share some of those experiences from 2021.</p>"},{"location":"blog/2022/01/22/novel-interactions/#apple-pencil-adobe-fresco-watercolors","title":"Apple Pencil + Adobe Fresco + Watercolors","text":"<p>Toward the beginning of last year I started drawing again and came across Fresco on my iPad. While the whole app is impressive the water colors really surprised me. There was something about the first time I chose a water color brush and could see the colors diffusing on the canvas while I was moving my pencil that was really intriguing. Add to that the pressure sensitivity and I continue to find this really interesting.</p>"},{"location":"blog/2022/01/22/novel-interactions/#pokpok","title":"PokPok","text":"<p>This is a game that my daughter likes to play on iPad from time to time and it really feels like a digital toy box. One of the play areas is a town map where there are tons of interesting interactions. You can move cars, people, animals and have little interactions with the mail, car wash etc. It feels really well made, and like it was made to encourage kids to use their imagination. There are no objectives or dark patterns, just play and it\u2019s great.</p>"},{"location":"blog/2022/01/22/novel-interactions/#github-copilot","title":"GitHub CoPilot","text":"<p>I\u2019ve spent a lot of my career building tools and services for ML projects which has lead me to be critical of many \u201cAI\u201d projects. This year when GitHub CoPilot launched I was able to get into the beta and found out it\u2019s actually a pretty powerful tool. Yes you can find examples of how it can be wrong, and you can find plenty of tales of woe about the bugs it will introduce, but I\u2019ve actually found it to be a really useful coding assistant to the point that I miss it (but can still do my work) when I don\u2019t have it. While it does make some useful code recommendations it also does a great job of helping me write the docs which is worth a lot to me and future team members.</p>"},{"location":"blog/2022/01/22/novel-interactions/#garageband-on-iphone","title":"GarageBand on iPhone","text":"<p>I remember getting my first MacBook (white clam shell) and spending a lot of time playing with GarageBand. I was blown away that this was built in for free and could do so much coming from Windows and headless Linux. I had a lot of fun with it, but then slowly I was doing less with music and hadn\u2019t touched GarageBand in years. This year I took a musicianship course with UC Berkeley (through Coursera) which required ear training throughout the week. I used a lot of tools for this, but one that I found to be really fun and interesting was GarageBand on iPhone. After installing it from the AppStore I was able to load up a keyboard that let me practice intervals with some nice sounding samples. From there I went on to explore the various digital instruments and track options. It\u2019s pretty wild just how much is available for creating and interacting with tracks on my phone.</p>"},{"location":"blog/2022/01/22/novel-interactions/#xcloud","title":"XCloud","text":"<p>Does anybody else remember MSN Zone? I do, and I also remember getting kicked off the dial up connection halfway through a match of Star Wars Battlegrounds because somebody would call the house. Fast forward 20 years and I was able to stream games on my iPad while Rachael and I were in Chicago. Game streaming has been a thing for a while but I really was amazed with the overall experience of the XCloud app. Logging in on the go and loading up Halo Wars 2 in HD with no issues for a couple matches was awesome. Add on being able to see a bit of what was going on with Redux when I did the same thing on my desktop browser and I continue to find XCloud to be really neat.</p>"},{"location":"blog/2022/01/22/novel-interactions/#spatial-audio","title":"Spatial Audio","text":"<p>We switched to Apple Music from Spotify last year when they announced the addition of Dolby Atmos/Spatial audio. I remember listening to Hybrid Theory (Linkin Park) first and was blown away. This was an album I had listened to on repeat for years, first with my Sony Walkman disc player and then my RCA MP3 player after that. I felt like I was hearing sounds on tracks for the first time and I continue to go back and check it out week after week. Now I search around for albums I had heard in the past to see what new sounds I might hear while also enjoying what people are doing with spatial audio in games and other mediums.</p> <p>Listen to Jonathan x Friends - Best of Dolby Atmos + Spatial Audio by Jonathan &amp; Friends on Apple Music. So last year had quite a few new and interesting digital experiences. Hopefully this year has just as many for me to share.</p>"},{"location":"blog/2022/03/28/i-realized-something-similar-a-few-years-back/","title":"I realized something similar a few years back.","text":"<p>I realized something similar a few years back. Discovery is arguably easier than ever, but it's also super easy to fall into just listening to what you know from established playlist.</p> <p>I have found Bandcamp and some of their newsletters to be a good way to discover new artist and songs.</p> <p>A few artist from the last 10ish years that you might give a listen to:</p> <ul> <li>LEENALCHI</li> <li>Super Future</li> <li>Japanese Breakfast</li> <li>The Weekend</li> </ul> <p>Have fun, there's a lot of good stuff out there!</p>"},{"location":"blog/2022/03/28/productive-tools-can-be-observed/","title":"Productive tools can be observed","text":"<p>Last year I started working on a new React app. I was late to the React game, having only started using it with React 16 I had experience with some existing React projects, but this was an opportunity to start something new. Additionally, I was starting out small with one focused use case, but if that was successful [it was!] the app would grow to encompass quite a few screens and tools.</p> <p>In the process of determining how state would be managed I wanted to test out using useContext and useReducer to see how far I could get before reaching for a state store. For the initial use case this worked great, and to this day I still make use of context for a few key parts of the app. Eventually though as the app grew, and as I wrote more custom reducers I decided it was time to explore my state store options. Along the way I looked at the latest versions of mobx-state-tree , redux (specifically RTK) , relay and others.</p> <p>Ultimately I ended up choosing Redux Toolkit (for a variety of reasons), because it\u2019s opinionated and easy to observe. The languages we use to solve problems today are not precise and encompassing enough to build systems that cover the universe of execution paths. Because of this it\u2019s important that the tools you use help you understand the system when it behaves in an unexpected manner.</p> <p>This is pretty trivial in Redux when using Redux Dev Tools. Add in using RTK Query and suddenly you might feel like you have superpowers for understanding the state patterns in your app. With the time travel and state sharing capabilities built right into Redux Dev Tools you can snapshot a session, share it and walk back through each dispatched action in a way that almost feels like magic compared to other debugging experiences I\u2019ve had over the years [writing to the console, re-constructing state manually, browser debugger step by step].</p> <p>And that\u2019s one of the primary reasons I ended up using Redux in 2022. There are plenty of valid reasons to use other tools, but after all these years I accept that bugs and edge cases are going to happen. Knowing that I want tools that help me explain and understand them, so I can move on to the next step of determining a fix and shipping it.</p>"},{"location":"blog/2022/03/28/software-engineering-mythology/","title":"Software Engineering Mythology","text":"<p>Over the last few years I\u2019ve had the opportunity to see how a variety of teams and companies build software. Along with that (like many others in the field) I\u2019ve kept up with the content coming through various aggregators. Among the many things that every team has to decide is how they are going to actually build and maintain a project(s). We make decisions like:</p> <ul> <li>what language to use</li> <li>how to manage dependencies</li> <li>how to generate artifacts</li> <li>how to manage artifacts</li> <li>how to instrument our project</li> <li>how to deliver our project</li> <li>how to document our project</li> </ul> <p>Some of these have grown community standards, some platforms make the decision for us, but often times these decisions are made off a mix of experience and a lot of personal preference. Those preferences I imagine are largely impacted by the industry of personality and marketing that has sprung up around:</p> <ul> <li>software education</li> <li>dogma articles</li> <li>self proclaimed experts</li> </ul> <p>Some of the problems with our judgement being so strongly influenced by these voices is that they often lack data for us to place them in our context and judge the merit of what is being offered. Rarely do we know what didn\u2019t work, what came before, the team composition and history, measurements used to determine if something truly was better or more successful. Instead it\u2019s anecdata, stories told through the lens of one reality, comments that evoke strong emotions etc.</p> <p>This has made me more and more uncomfortable over time. So much time and effort is spent without good data, and we churn and churn and churn. Oddly there are resources published with data from academic sources like ACM, IEEE and industry sources like MS Research and Jetbrains (among many many others). These are not perfect, but they do capture a known context and pair that with data. Maybe the findings have distilled out to our industry over time, but I have a suspicion there is data there that raises questions and counterfactuals to what we extrapolate from ones individual anecdata that turns into the latest hot article/talk.</p> <p>This isn\u2019t meant to say that the advice we share and the experiences we live are not important. They are incredibly important. Instead I write about this as something I want to go to as a source of education and learning more often. I want to make sure I spend as much time with these sources as I do with articles in my RSS feed. I\u2019m sure I\u2019ll learn something along the way that I haven\u2019t heard before. I hope to find some research spanning groups, companies and project scopes that provides a data analysis of the results on top of the stories of those followed.</p> <p>ACM IEEE Microsoft Research Jetbrains Research ISO</p>"},{"location":"blog/2022/03/28/without-trust/","title":"Without Trust","text":"<p>There is a lof of talk these days about building systems that don\u2019t require trust. On paper this has some appealing characteristics, and throughout history we have seen the issues that arise from unquestionable centralized authority, but right now I think we are also seeing the impacts of missing trust in the analog (physical) realm.</p> <p>As our physical and digital existence converge and the lines become blurrier I think it\u2019s pertinent to keep in mind the kind of systems and philosophies that we construct in each realm and how they can go on to influence the other.</p> <p>I have a lot of thoughts and feelings on these subjects, and maybe I\u2019ll go on to explore and write them down in the future, but for now I just simply want to say that I don\u2019t want to live in a world without trust.</p>"},{"location":"blog/2022/05/28/interactions-of-interest/","title":"Interactions of Interest","text":"<p>Over at Hackaday there is an ongoing series of articles called Inputs of Interest. Last year I wrote my a post Novel Interactions that will end up being the first in an ongoing collection of articles called Interactions of Interest. I personally enjoy building and interacting with new experiences. For those that catch my interest and stay in my memory I\u2019m going to collect and share them.</p> <p>Sony Linkbuds \u2014 while I ultimately couldn\u2019t find a cushion and ear fit that allowed me to listen for more than half an hour I thought the design around these was really creative. Being able to hear your environment while also listening to music, a podcast or book is really nice in a variety of situations. Additionally moving the earbud interactions from being on device to picking up movement from the area near your ear is something I think we might see more of from future devices.</p> <p>Animoog Z \u2014 There are two synth related items on this list. I never used the original Animoog software, but I recently loaded Animoog Z, and it\u2019s been a lot of fun. My daughter and I can sit down tweaking various parameters while launching new sounds into space just to see what we can create next.</p> <p>Roland 50 \u2014 Roland is celebrating 50 years of making awesome devices and tools. In celebration of that they launched a synth web app that is mind-blowing. While this is a lot of fun to create with it is also inspiring to think that this is all running in the browser meaning they could launch it into the world and make it available across device, OS and app store environments with little friction.</p> <p>Delta \u2014 A couple months ago I traveled for work. Along the way I found out I could head home earlier than planned, but I figured making that happen without it becoming a lot of trouble was unlikely. It\u2019s pretty crazy that I was able to take care of bumping my flight up so I could be home with my family all in the Delta app in under 10 minutes without a change fee. Thinking back 10 years ago when I was traveling as a software consultant it\u2019s wild how easy logistics interactions like this have come.</p> <p>Apple Research App \u2014 For the last year I\u2019ve opted in to a few different research studies available in the Apple Research app. Each week or month my phone reminds me I have some questions to answer, and ever so often even has me review the data that I\u2019ve opted into sharing with these studies. What surprises me is how few studies there seem to be. Maybe this is a good thing. Maybe it means there is a lot of effort going into ensuring the quality of these studies, but the way the app works, how transparent it makes things and prompts you to keep in touch makes me wonder if it\u2019s quality, or a lack of (legit) organizations knowing this is out there.</p>"},{"location":"blog/2022/05/29/tailored-experiences/","title":"Tailored Experiences","text":"<p>A couple of months ago I got to spend a few days hacking on an idea involving client side Tensorflow.js. Having spent much of my career in what I call ML adjacent roles I was really surprised at the opportunities TF.js seem to open up.</p> <p>One of the things that stood out to me is that the full training and deployment cycle can happen in real time client side. As I was using the tool I was able to load my models starting point and start feeding it data seeing the behavior and predictions from the model change immediately. I could even hop into dev tools to patch and tweak different settings of the model just to see what happened. I didn\u2019t have to wait long cycles, I didn\u2019t have to insert a new notebook cell and disrupt the flow. I was able to launch my web app, load in a checkpoint and go. Based on what I did the model was able to learn in real time (and make some admittedly hilarious mistakes along the way).</p> <p>This makes me wonder what kind of experiences this is waiting to unlock. I don\u2019t need to send data back to a centralized service for all of my data to be mixed in with the data of other individuals waiting for a new training cycle or model deployment my data was on my device, the model was on my device the update was immediate. Obviously there are risk here (filter bubble, convergence etc) to address, but the opportunity for useful new experiences appears strong.</p> <p>While I haven\u2019t had much time to explore TF.js since this initial interaction I hope to return to it sometime in the near future. I think that projects like automerge and tensorflow.js represent potential futures where our data is local to us. We can collaborate, share and build all without phoning home or opening the app store if we continue to push what is possible in our browser and devices.</p>"},{"location":"blog/2022/05/30/pokemon-legends-arceus-exploring-hisui-with-my-daughter/","title":"Pokemon Legends Arceus: Exploring Hisui with my daughter","text":"<p>A couple of months ago I had a pile of games built up that were ready to trade in. When I took them to the shop I saw a new Pokemon game was out, and my daughter is now at the age were some games are becoming fun for her to play. Reading up on the open world nature of Arceus I thought it might be something fun for us to enjoy together. What I didn\u2019t know was just how much fun we would end up having.</p> <p>From the moment we got to pick our starter (Cyndaquil) we were having fun. My daughter loves all things monsters, loud and colorful so we were off to a good start. Once we powered through the open dialogue as fast as possible (who needs a story when there are monsters?) we were running through the Obsidian Fieldlands discovering all kinds of new Pokemon along the way. My daughter loved it, I was enjoying the nostalgia of seeing familiar faces from my childhood and we were spending time discovering a new world together.</p> <p>By this point we\u2019ve logged enough hours to explore the far corners of each map, track down alphas and space time distortions, address the rift and we are left tracking down a few lingering Pokedex entries so that we can meet Arceus. It\u2019s been a fun journey around the world, but for me the best part has been seeing the happiness and discovery that my daughter has enjoyed along the way.</p> <p>Along the way there have been a few things she discovered early on that have endured and become a constant part of our exploration. Anytime we see a shaking rock or tree we have to find out what\u2019s in it. Often times this is met with \u201cjust geodude\u201d or \u201canother burmy\u201d, but occasionally it\u2019s an excited shout \u201cWHAT IS THAT!\u201d as Heracross or another unexpected Pokemon pops out.</p> <p>Bubbles (space-time distortions) have become another ongoing source of entertainment. There is a sense of heightened risk as we are constantly being targeted by the Pokemon spawning in the bubble never knowing what will come next. It\u2019s fun to race around picking up the random items while watching for any bubble denizens we might want to engage.</p> <p>But most of all I love seeing the stories and interactions my daughter imagines with the non aggressive Pokemon interactions. Each map has a variety of Pokemon or locations were the Pokemon don\u2019t become aggressive as you approach. Probably the most notable for us has been the Alabaster Icelands hot spring where there is often a Machop, Machoke and other Pokemon relaxing and enjoying the water. My daughter loves to run and jump into the water, share snacks (berries) and follow the other Pokemon as they hop and run around. The stories she makes in these moments are amazing and I can only imagine transcend what the designers were imagining as they opted to have less aggressive Pokemon scattered throughout the map. These moments have easily become my favorite part of the game. Maybe in a future Legends the Pokemon in your party will be able to join in these interactions or have non-combative interactions in the wild.</p> <p>I hadn\u2019t played many games in the last few years, but Legends has been a really fun way to spend time with my daughter. It\u2019s had us sharing ideas, taking turns navigating the world and finding plenty of surprises on the journey to meet Arceus.</p> <p>P.S. Outside of the fun these fun interactions I have found the game soundtrack to be great. I don\u2019t have any other Pokemon tracks in my playlist, but I\u2019ve added many from this game and I think I may have to go check out the music from previous entries that I haven\u2019t played.</p>"},{"location":"blog/2022/06/01/interface-discovery/","title":"Interface Discovery","text":"<p>I spend a lot of my days building new tools that individuals use to power their day to day work. Because of this I always keep an eye out for behavior in the apps that I use which inspire me to consider how my apps work. One of the things that has stood out to me over the last year is how some apps introduce let you discover functionality.</p> <p>Garageband Quick Help \u2014 a feature you can enable in Garageband and Logic Pro is quick help. Once enabled it introduces a short tooltip hover over. Considering the amount of options that these applications provide and the depth of the interface being able to simply hover over a button, knob or other part of the interface and immediately find out what it can do is incredibly useful.</p> <p>Adobe stories \u2014 Stories seem like a nice way to share that new functionality is enabled while also creating an index that lets users return to the a story when they are ready to use a feature. Often times when I was using Fresco I would see a new story introducing a new tool, but it wasn\u2019t something I was ready to use yet. I knew it was there though and often times I would return to the story in the next few weeks as I tried out something new. While plenty of apps offer changelogs the presentation and the fact that stories are always right there available in the app is a nice touch.</p> <p>Emacs/Jetbrains/VS Code and probably your favorite editor \u2014 This one has been around for ages, but is still missing in many tools and web apps. Universal search related to functionality. Emacs has had M-x for who knows how long, Jetbrains added Shift + Shift and VS Code has the command palette (not quite the same, or as powerful but good). Being able to toggle into these universal search places and discover options, settings and commands is really valuable and I\u2019ve found plenty of features I never knew existed just by searching a related term.</p> <p>RTFM \u2014 nothing new here, but having picked up some new hobbies and devices over the last couple of years having some docs is super helpful. We often take this for granted, especially if we are building internal tools, but at the end of the day a user manual goes a long way to enabling somebody to read the instructions and be on their way. Bonus points if your docs are built in, indexed and up to date.</p>"},{"location":"blog/2022/06/07/more-interactions-of-interest/","title":"More Interactions of Interest","text":"<p>Following up on Interaction of Interest here are a few more things I\u2019ve messed with in the last couple of months that I found to be pretty neat.</p> <p>Using a Wacom Stylus in the browser \u2014 did you know that the HTML 5 pointer event has special properties for pens? I didn\u2019t, but a few months back when I was exploring the benefits of using a wacom tablet with a web app I learned about them. Surprisingly ( to me) a pen just kind of works with many apps for simple events, but allow a lot of custom functionality. I think because of the ubiquity of the mouse and keyboard many apps are built without much thought given to what kind of input device might make the most sense. Of course the individual using the web app needs to possess the device, but I think many interactions can be enhanced through alternative input devices. Pens, knobs, touchpads etc.</p> <p>Tensorflow.js \u2014 I wrote a short article on this one, but in general the short amount of time that I can to spend working with Tensorflow.js left me wanting more. I think that ML has a lot of benefits we are only beginning to discover. The prospect of enabling the use of ML in client web apps and pushing the learning cycle to the user device is really interesting to me.</p> <p>Forecastle Cashless Wrist Band \u2014 Rachael and I recently went to Forecastle. The festival was a lot of fun, but a few weeks before we were set to attend we received wristbands for the event in the mail with registration instructions. Inside the band was an NFC chip that was your ticket into the event. You could also register a card with it to use as a form of payment anywhere in the festival. Having attended quite a few concerts, conventions and festivals this was new to me, but I thought it was awesome. For one it didn\u2019t assume the attendee has a smart device to bring with them, and it also didn\u2019t assume that their smart device would have a good connection to download or open an app, site etc at the event (a common source of issues). What I noticed was that lines to get in were way shorter. No shuffling for tickets, no getting your phone out to open an app, no waiting on face id or entering your passcode. You scan and your in. Payment seemed to have the same benefit of not shuffling for wallets, waiting for you phone/watch wallet to load etc. These bands really streamlined a lot of the wasted time at the end of the line. I hope to see more of these in the future.</p> <p>Bluetooth Vinyl \u2014 This sounds like an oxymoron. I recently picked up a record player that was able to connect via bluetooth to my soundbar and\u2026..it\u2019s awesome. There is something enjoyable about placing the record on the plate, and changing the disk side to hear more as one side comes to a close. That said cable management isn\u2019t fun, and worrying about preamps, speakers just for the player etc wasn\u2019t something I wanted to get into. I\u2019ve been surprisingly happy enjoying the ritual of vinyl with the ease of a bluetooth audio connection.</p> <p>Pokemon Legends Arceus \u2014 another interaction I wrote more about in another article. This game reminded me how much fun exploring a game with somebody else is (I used to play primarily multi-player video games) while also driving home the creativity and care of Nintendo (and for this particular game GameFreak).</p>"},{"location":"blog/2025/01/17/notes-from-a-year-of-working-with-jack-audio-connection-kit/","title":"Notes from a year of working with Jack Audio Connection Kit","text":"<p>Last year I became the lead engineer on a new project. After joining the project I spent a lot of time helping users and engineers debug JACK audio behavior (although JACK typically wasn't the cause of the observed issue). While I had used Core Audio in the past I wasn't as familiar with JACK at the time, so I thought I would write down a few of the things I have learned to check first when somebody tells me they are having an issue with JACK. These are specific to running JACK on Linux, in my case Ubuntu.</p> <pre><code>flowchart LR\n    A[Does JACK server start?] --&gt; B{No}\n    B --&gt; C[What is your clock source, and is it valid?]\n    C --&gt; D{Does your device provide JACK a clock?}\n    D --&gt; E{\"Does your device have an internal clock,\\n or does it rely on an external clock\\n (for instance a PCI MADI card setup)?\"}\n    C --&gt; F{Are all of your cables connected?}\n    F --&gt; G{Are they in the right direction?}\n    F --&gt; H{Are they all showing healthy conditions on\\n their LED or other connection health indicator?}\n    B --&gt; I[Does ALSA recognize your sound card/interface\\n as a capture and/or playback device?]\n    I --&gt; J{No}\n    J --&gt; K{\"How is the device connected (USB, PCI, etc),\\n and do you need any additional drivers?\"}\n    J --&gt; L{\"Using the correct tools (lsusb, etc)\\n does the kernel recognize the device is present?\\n If not you're debugging hardware.\"}\n    I --&gt; M{Yes}\n    M --&gt; N{Does ALSA recognize that the device supports\\n the sample rate you want to run the JACK server at?}\n    M --&gt; O{Do you need to customize any channel or other\\n settings with alsa mixer to have the correct IO setup?}\n    M --&gt; P{Can you use alsa utilities to send or\\n receive signal to the device?}\n    P --&gt; Q[\"If your clock source is valid, and ALSA\\n recognizes the devices and can route signal in/out of the device\\n (depending on playback and capture capabilities and requirements)\\n then we probably have a JACK settings issue.\\n If you don't verify the clock and ALSA\\n settings first though you may be looking in the wrong spot for the issue.\"]\n    C --&gt; R{Clock is valid and ALSA can use the device}\n    R --&gt; S{Are you starting JACK in daemon mode or dbus?}\n    S --&gt; T{If daemon mode:}\n    T --&gt; U{Is there anything blocking the daemon from starting?\\n For instance another jack server that is already\\n running via pulseaudio or another process?}\n    R --&gt; V{Are you passing the right hardware identifier\\n to JACK to select the correct playback/capture device\\n that the process will use with the server?}\n    R --&gt; W{Are you starting the server with a sample rate,\\n frame size and period supported by the device?}\n    W --&gt; X{Use ALSA tools or qjackctl to review device settings\\n and configuration options.}\n    R --&gt; Y{What does JACK tell you if you start the process\\n with the `--verbose` flag?}</code></pre> <p>That's a lot to check, and I employ various ALSA cli utilities along with JACK tools like qjackctl to help collect information as I iterate through the items above until I get to a state where the JACK server will start. Once I get the JACK server started if errors are reported it tends to fall into a couple categories (I'm sure there are more, this is just based on my experience so far):</p> <ol> <li>JACK client issues<ol> <li>This is a pretty broad space since really a jack client can represent just about any application/algorithm that you want to wrap as a jack client and have audio or midi in/out port support. A few things I've seen:<ol> <li>The application runs at a fixed rate that isn't compatible with the rate the server is running at.<ol> <li>You will either need to update the client, run the server at a different rate, or do sample rate conversion.</li> </ol> </li> <li>The application parses JACK server output information and doesn't behave correctly when the server runs in verbose mode.<ol> <li>There is probably a better way to get the information the client needs without parsing jack server output.</li> </ol> </li> <li>The MIDI messages that the application receives are not parsed correctly.<ol> <li>Use MIDI utilities to check the message format/structure and either fix the sending or receiving application code.</li> </ol> </li> <li>Resource errors - these tend to be addressable with standard tools (writing tests, profiling the application, static analysis, etc).<ol> <li>Memory errors.</li> <li>Callback code doesn't execute within the allotted time.</li> <li>Improper port management.</li> <li>Logic bugs.</li> </ol> </li> </ol> </li> </ol> </li> <li>Unstable clock<ol> <li>This one is a little tricky. If the jack server starts, but loses the clock source you can check a few things.<ol> <li>Is the device still connected correctly, and if it's external did it lose power?</li> <li>Check syslogs and dbus. Did the hardware disconnect and reconnect?</li> <li>If the device clock is external does the device have any logs that you should review?</li> <li>If none of the points above expose any useful information then you will probably need to do deeper monitoring, and possibly troubleshooting at the driver/device level.<ul> <li>Does the error happens on a set time interval</li> <li>Can you replicate it on a second machine</li> <li>What debug information is available at the driver level</li> </ul> </li> </ol> </li> </ol> </li> </ol> <p>Working with and building JACK applications has been a really interesting experience. Making sure everything aligns as expected from hardware through software has taught me a lot. Maybe some of this will help somebody else if they are debugging JACK workflows for the first time.</p>"},{"location":"lists/books/","title":"Books","text":"Bookshelf <p>This is a collection of books and writing that I have enjoyed or found useful.Let me know if you have         recommendations for my next read.</p> Books <ul> <li>A Different Mirror</li> <li>A Pattern Language</li> <li>The Algorithm Design Manual</li> <li>Blockchain Chicken Farm</li> <li>Computer Organization and Design</li> <li>The Phoenix Project </li> <li>Classic Computer Science             Problems in Python</li> <li>Design Patterns Elements             of Reusable Object Oriented Software</li> <li>Designing Data-Intensive Applications</li> <li> Effective                 Debugging</li> <li>How to Invent Everything</li> <li>Make Electronics 2nd Edition</li> <li>Making Embedded Systems</li> <li>Mazes for Programmers</li> <li>Monstress</li> <li>PoC || GTFO</li> <li>The Pragmatic             Programmer 2nd Edition</li> <li>SICP</li> <li>Test Driven Development for             Embedded C</li> <li>The Linux Command Line 2nd Edition</li> <li>Unix and Unix System             Administration Handbook</li> <li>Saga</li> <li>The Culture</li> <li>Zen and the Art of             Motorcycle Maintenance</li> </ul> Newsletters <ul> <li>Hackaday</li> <li>The Prepared</li> </ul> RSS Feed <ul> <li>OPML Repo</li> <li>Gist</li> </ul>"},{"location":"lists/podcast/","title":"Podcast","text":"Podcasts <p>Below are some of the podcast I have enjoyed.Let me know if you have any recommendations.</p> <ul> <li>Changelog</li> <li>Dev Game Club</li> <li>Embedded FM</li> <li>Podcast Init</li> <li>The Amp Hour</li> </ul>"},{"location":"programming/portfolio/","title":"Portfolio","text":"Programming Projects &amp; Contributions <ul> <li>Professional</li> <li>Personal</li> <li>Open Source</li> </ul>"},{"location":"programming/portfolio/#professional","title":"Professional","text":"FlockSafety <ol> <li>Annotation Platform</li> <p>Summary</p> <p>Design and develop tools to annotate and manage multimedia ML datasets</p> <p>Core Technology</p> <p>Python, Django, TypeScript, React, Postgres, DoltDB, Kubernetes, Docker, Jenkins, OAuth2, REST, AWS,             Auth0</p></ol> RENCI <ol> <li>HeLx</li> <p>Summary</p> <p>HeLx is a digital home for data science communities. RENCI leverages HeLx to empower plant genomics,             biomedical, clinical, and neuroscience researchers to do work with their tools, close to the data, in the             cloud, at scale:</p> <p>Core Technology</p> <p>Python, React, bash, Kubernetes, Docker, Jenkins, OIDC, REST</p></ol> Samtec <ol> <li>Asset Management System</li> <p>Summary</p> <p>Build out an asset management platform to synchronize existing asset data and centralize the ongoing             management of assets in one location.</p> <p>Core Technology</p> <p>C#, .NET Core, Typescript, Angular 11, REST APIs, MongoDB, AWS, SQS, SNS, Fargate, CloudFront, S3, Azure             Pipelines, Docker, bash/PowerShell, git</p> <li>Asset Maintenance System</li> <p>Summary</p> <p>Build an asset maintenance system to support global operations.</p> <p>Core Technology</p> <p>C#, .NET Core, Typescript, Angular 11, Quartz.NET, REST APIs, MongoDB, AWS, SQS, SNS, Fargate, CloudFront,             S3, Azure Pipelines, Docker, bash/PowerShell, git</p></ol> Humana <ol> <li>Provider Fax Routing System</li> <p>Summary</p> <p>Build out OCR as a service for provider patient record fax documents</p> <p>Core Technology</p> <p>Python 3, REST, Tesseract, Jupyter, Docker, docker-compose, Azure Dev Ops, Azure Pipelines, Azure Functions,             Azure Queues, Azure Blob Storage, CosmosDB Artifactory, git, bash</p> <li>Sytrue Middleware</li> <p>Summary</p> <p>Support a middleware layer and rule management for Humana Sytrue initiatives</p> <p>Core Technology</p> <p>Python 3, Django, REST, Jupyter, NLP, Docker, docker-compose, Azure Dev Ops, Azure Pipelines, Azure Blob             Storage, Azure Datalake Storage Gen 2, SQL Server, Databricks, Apache Spark, Artifactory, git</p> <li>Breast Cancer Research Project</li> <p>Summary</p> <p>Research using NLP to assist in the understanding of stage information based on diagnosis markers.</p> <p>Core Technology</p> <p>Python 3, PySpark, NLP, SQL, HDFS, bash</p> <li>Doctor Patient Note OCR</li> <p>Summary</p> <p>Increase OCR post processing data throughput by migrating localized python services to PySpark.</p> <p>Core Technology</p> <p>Python 3, PySpark, SQL, XML, HDFS, flask, REST, bash</p> <li>Potential Fraud Rule Detection</li> <p>Summary</p> <p>Process provider documentation against a set of NLP rules to flag the need for provider rule setup.</p> <p>Core Technology</p> <p>Python 2, SQL, Red Hat Enterprise Linux (RHEL), Netezza, SQL Server</p> <li>Fraud Rule Evaluator</li> <p>Summary</p> <p>Evaluate the effectiveness of provider review rules.</p> <p>Core Technology</p> <p>Python 3, SQL, SQL Server</p> <li>SUI Investigator Reports</li> <p>Summary</p> <p>Build out a library of queries and reports to assist fraud.</p> <p>Core Technology</p> <p>C#, SSIS, SQL, SQL Server, Excel, QuickLogic</p></ol> Elastic <ol> <li>GCP Marketplace</li> <p>Summary</p> <p>Integrate the Elastic Cloud offering with the GCP Marketplace so customers can create clusters from their GCP             dashboard.</p> <p>Core Technology</p> <p>Python 3, GCP, PubSub, Postgres, Elasticsearch, Docker, docker-compose</p> <li>Python 2 to 3 migrations</li> <p>Summary</p> <p>Started the migration of the Python 2 billing system to Python 3</p> <p>Core Technology</p> <p>Python 2 &amp;amp; 3, Tornado, Docker, pytest</p></ol> Aspect Software <ol> <li>PetSafe, Delta, Jet Blue</li> <p>Summary</p> <p>Build out Microsoft SSIS/SSAS analytics infrastructure to support customer service call center             operations.</p> <p>Core Technology</p> <p>C#, SSIS, SSAS, SSRS, SQL, MDX, SQL Server 2008, Excel Power BI, Powershell</p> <li>Data Visualization</li> <p>Summary</p> <p>Build out web-based data visualizations to support various application development teams focused on             healthcare projects.</p> <p>Core Technology</p> <p>C#, Razor Pages, KendoUI, JavaScript, JQuery, REST Apis, SQL Server 2008</p></ol> All Safe Industries <ol> <li>Product Catalog ETL</li> <p>Summary</p> <p>Built an application to consolidate various sources of product data into our web CMS.</p> <p>Core Technology</p> <p>C#, .NET Framework 3, Razor Pages, REST</p></ol> Owensboro Catholic High School <ol> <li>Printer Fleet Management</li> <p>Summary</p> <p>Scripted out the install and management of printers across computer labs.</p> <p>Core Technology</p> <p>VB6, COM</p> <li>Active Directory Group Policy Management and Deployment</li> <p>Summary</p> <p>Develop Active Directory group policies and role them out across school groups</p> <p>Core Technology</p> <p>Windows XP, Active Directory 2008</p></ol>"},{"location":"programming/portfolio/#personal","title":"Personal","text":"Circuit Roomba <ol><p>Summary</p> <p>Setup SMS interaction with home roomba to be able to text commands the roomba would process and respond             to.</p> <p>Core Technology</p> <p>CircuitPython, SMS, Twilio, Raspberry Pi, LoRa</p></ol> On Air <ol><p>Summary</p> <p>Trained an NLP model to run on an ESP32 responding to a wake word and command do toggle a status indicator             display.</p> <p>Core Technology</p> <p>C++, Tensorflow Lite, ESP-IDF, CircuitPython, Rust, SledDB, REST API, bash</p></ol> Rings <ol><p>Summary</p> <p>A react app that can take an image and transform it into various patterns using paper.js</p> <p>Core Technology</p> <p>TypeScript, React, Paper.js</p></ol> Valentine <ol><p>Summary</p> <p>A bluetooth sensor that changes board LED colors based on the count of devices in local proximity.</p> <p>Core Technology</p> <p>CircuitPython, Bluetooth</p></ol> Self Hosted Home Server <ol><p>Summary</p> <p>A home server used to run my website, git repos, build pipelines and more.</p> <p>Core Technology</p> <p>Docker, docker-compose, traefik2, Minio, Postgres, bash, TeamCity, nginx</p></ol>"},{"location":"programming/portfolio/#oss","title":"Open Source Contributions","text":"aioodbc <ol><p>Summary</p> <p>Documentation updates based on using the library.</p> <p>PR</p> <p> Configuration tuning documentation </p></ol> Apache Arrow <ol><p>Summary</p> <p>Documentation and minor behavior updates based on using the library.</p> <p>PR</p> <p> Add Hash Path Documentation updates Memory subpool allocation </p></ol> Code Louisville <ol><p>Summary</p> <p>Volunteer Instructor and content creator for Python web and data analysis tracks.</p> <p>PR</p> <p> Python                 Course </p></ol> Firefox Mobile (Android) <ol><p>Summary</p> <p>Mobile browser update for a bug I and others experienced.</p> <p>PR</p> <p> Orientation Bug Fix </p></ol> PyMSSQL <ol><p>Summary</p> <p>Help get the library update to cut a new release addressing several bugs and issues users encountered.</p> <p>PR</p> <p> 2.1.4 release coordinator Build updates Assist others as they onboard and contribute to the             project etc </p></ol> wavesurfer.js <ol><p>Summary</p> <p>Update region event broadcasting during teardown</p> <p>PR</p> <p> Region plugin event fix </p></ol>"},{"location":"programming/resume/","title":"Resume","text":"Alexander Hagerman alexander@burningdaylight.io Portfolios: burningdaylight\u00a0|\u00a0github <p>I am a software engineer with over a decade of experience. In that time             I have worked across a variety of domains, stacks and teams building frontend web and mobile interfaces,             distributed backend services while managing legacy systems. I enjoy working in environments that require             continuous learning and collaboration to solve challenging problems. These days I prefer working on tools             that empower individuals to create.</p> Professional Experience <ol> <li> Lead ML Tooling Engineer <p>06/2021 - Current | Flock                         Safety</p> <ul> <li>Design and implement audio, object tracking and device health annotation tools. </li> <li>Responsible for identifying candidates to grow the team, onboarding and training new engineers, and managing the team's technical roadmap. </li> <li>Lead the designed and implementation of image annotation tools. </li> <li> Set up and maintain frontend build and testing tools.</li> <li>Designed and implemented a data versioning tool to support annotation lineage and management. </li> <li>Lead the design and implementation of an annotation campaign process to streamline the collection and validation of data across tools. </li> <li>Responsible for supporting and securing data interfaces allowing service to service, frontend and other ad hoc integrations. </li> <li>Mentor other engineers and collaborate across teams for new product features. </li> </ul> </li> <li> Senior Software Engineer <p>02/2021 - 05/2021 | RENCI</p> <ul> <li>Worked to develop the HeLx Platform to support NIH HEAL research. </li> <li>Refactor HeLx platform Django application to surface data via REST endpoints. </li> <li>Collaborated on a new react based frontend for the HeLx Appstore. </li> <li>Instrument Kubernetes pod utilization and surface data through service endpoints. </li> <li>Refactor application packaging and update continuous integration practices. </li> </ul> </li> <li> Lead Software Engineer <p>06/2020 - 02/2021 | Samtec </p> <ul> <li>Lead/manage the development of new asset management system to synchronize asset data and streamline existing assets. </li> <li>Created an improved asset maintenance system to support global operations. </li> <li>Collaborate with engineers and internal stakeholders to execute feature implementations and process improvement. </li> <li>Provide key insights for organizational planning on data management and optimization. </li> <li>Mentor, coach, and train engineers in new practices/tools/technology. </li> <li>Develop and oversee continuous integration and deployment infrastructure to increase overall productivity. </li> </ul> </li> <li> Senior Software Engineer <p>08/2019 - 06/2020; 07-2015 - 03/2019 | Humana</p> <ul> <li>Spearheaded the creation of a provider fax routing system by building out OCR as a service for patient record documents. </li> <li>Facilitated the implementation of middleware layer/rule management for company Sytrue initiatives. </li> <li>Setup, deployed, and managed first real time NLP services on Azure to strengthen job progression and computer capabilities. </li> <li>Collaborated on breast cancer research project by utilizing NLP to research stage information based on diagnosis markers. </li> <li>Increased Doctor Patient Note OCR post processing data throughput by migrating localized python services to pyspark. </li> <li>Monitored potential fraud rule detection by processing provider documentation a set of NLP rules. </li> <li>Built/managed a library of queries and reports to assist fraud investigators. </li> <li>Assisted NLP development team in the transition to Agile methodologies through change management and team leadership skills. </li> <li>Foster continuous process improvement by implementing Azure identity service (MSAL/AAD) into C# and Python services. </li> <li>Develop prem to Azure Databricks deployment service, ADLS Generation 2 C# library, and CLI. </li> <li>Served as architect and senior developer of the Retail Data Science Research and Development platform. </li> <li>Introduced and streamlined multiple software development practices like version control, continuous integration/deployment, code review, and dependency management. </li> </ul> </li> <li> Senior Software Engineer <p>04/2019 - 08/2019 | Elastic </p> <ul> <li>Worked across teams to develop an end-to-end testing framework for the customer journey through GCP marketplace to Elastic. </li> <li>Migration of backend services from Python 2 to Python 3.7. </li> <li>Expanded automated testing practices for Python 2 and 3 code bases. </li> <li>Built a tool that enabled data migration from Elasticsearch to Postgres. </li> <li>Delivered troubleshooting and production incident response for billing services and clusters. </li> </ul> </li> <li> Senior Analytic Consultant | Analytic Consultant | Developer <p>01/2012 - 07/2015 | Aspect </p> <ul> <li>Built out Microsoft SSIS/SSAS analytics infrastructure to support customer service call center operations for PetSafe, Delta, and Jet Blue. </li> <li>Created enhanced web-based data visualizations to facilitate cross-functional application development teams on healthcare projects. </li> <li>Delivered on-site consulting and guidance to clients by evaluating call center analytic needs. </li> <li>Developed new productivity KPIs for call center clients via Microsoft BI stack to transform overall day-to-day operations and facilitate process improvement. </li> <li>Headed client training programs on business intelligence tools/concepts to assist in future BI projects and process improvement identification. </li> <li>Served as developer on SharePoint 2013 C# Applications, C# MVP Applications, and custom C# CLI applications to handle token management. </li> </ul> </li> <li> Junior Developer <p>03/2012 - 11/2012 | All                         Safe Industries</p> <ul> <li>Built a product catalog ETL to consolidate product data into a single CMS. </li> <li>Analyzed historical sales trends to improve decision making for web store strategies. </li> </ul> </li> <li> Intern <p>01/2011 - 05/2011 | Owensboro Catholic High School</p> <ul> <li>Developed VB6 scripts for printer fleet management by scripting out the install/management for printers across all computer labs. </li> <li>Administered active directory group policy/deployment by developing policies and implementing across all school groups. </li> </ul> </li> </ol> Education <p>08/2011 | Bachelor of Science in Computer Information Technologies | Western Kentucky University</p> Certificates <ul> <li>The Technology of Music Production (Coursera, January 2021)</li> <li>Developing your Musicianship (Coursera, December 2020)</li> <li>CSS for JavaScript Developers (Workshop, October 2020)</li> <li>UT.6.10x: Embedded Systems - Shape the World: Microcontroller Input/Output (edX, November 2019)</li> <li>Triplebyte Certified Generalist Software Engineer (Triplebyte August 2019)</li> <li>Data Visualization (Dataquest.io April 2016)</li> <li>Data Analysis with Pandas: Intermediate Course (Dataquest.io September 2015)</li> <li>MCSD: Web Applications (Microsoft, June 2014)</li> <li>Developing Microsoft Azure and Web Services (Microsoft, June 2014)</li> <li>Developing ASP.NET MVC 4 Web Applications (Microsoft, February 2013)</li> <li>Programming in HTML5, CSS#, JavaScript 70-480 (Microsoft, January 2013)</li> </ul> Awards <ul> <li>Hackaday Connected World Contest Award - Connected Roomba</li> <li>2018 Humana Star Award - Data Engineering</li> </ul> Technical Skills &amp; Competencies <p>Python, C#, TypeScript, Rust, C++, .NET Core, Django, React, Bash, SQLPostgres, SQL Server, SQLite,                 Elasticsearch, MongoDB, Redis, Netezza, CosmosDBSQS, PubSub, Azure Queues, Kafka, RabbitMQHDFS,                 Azure Data Lake Storage Gen 2, S3AWS, Azure, GCPAzure Pipelines, Azure DevOps, Circle CI, GitHub                 Actions, JenkinsLinux, Docker, Kubernetes, Fargate, TerraformSoftware Architecture, Software                 Testing, Pair Programming, CI/CDMentoring, Leadership, Team Building</p> Talks <ul> <li>Python for Embedded Hardware                     (DerbyPy, Louisville, KY) - June 2019                 </li> <li>What is ODBC (DerbyPy, Louisville, KY) - March                     2019                 </li> <li>Intro to PySpark (DerbyPy, Louisville, KY)                     - October 2018                 </li> <li>Python Modules and Packages                     (DerbyPy, Louisville, KY) - September 2018                 </li> <li>Column Oriented Data (DerbyPy, Louisville, KY) - June 2018</li> </ul> Volunteer &amp; Open-Source Experience <ul> <li>aioodbc                     - configuration tuning documentation                 </li> <li>Annotorious                     - docs and gitter chat help                 </li> <li>Apache Arrow -                     setup.py and API documentation updates, Subpool implementation, and add has capabilities for scalar                     values in Python                 </li> <li>Code                     Louisville - taught a range of topics including Python, debugging, databases, and Django                 </li> <li>Firefox Mobile - bug fix for incorrect axis locking                 </li> <li>PyMSSQL - mentor                     contributors, updated CI and platform builds, release manager for 2.1.4                 </li> <li>wavesurfer.js -                     region plugin update for event broadcasting                 </li> </ul> Memberships <ul> <li>ACM</li> <li>Hardware Happy Hour                     Louisville</li> <li>DerbyPy</li> </ul>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/archive/2021/","title":"2021","text":""},{"location":"blog/archive/2020/","title":"2020","text":""},{"location":"blog/archive/2019/","title":"2019","text":""},{"location":"blog/archive/2018/","title":"2018","text":""},{"location":"blog/page/2/","title":"Index","text":""},{"location":"blog/page/3/","title":"Index","text":""},{"location":"blog/page/4/","title":"Index","text":""},{"location":"blog/page/5/","title":"Index","text":""},{"location":"blog/page/6/","title":"Index","text":""},{"location":"blog/page/7/","title":"Index","text":""},{"location":"blog/archive/2020/page/2/","title":"2020","text":""},{"location":"blog/archive/2020/page/3/","title":"2020","text":""},{"location":"blog/archive/2019/page/2/","title":"2019","text":""}]}